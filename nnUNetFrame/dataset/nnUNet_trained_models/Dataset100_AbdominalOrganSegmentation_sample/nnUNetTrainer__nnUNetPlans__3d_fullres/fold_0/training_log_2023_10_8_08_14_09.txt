
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [96, 160, 160], 'median_image_size_in_voxels': [341.0, 512.0, 512.0], 'spacing': [0.800000011920929, 0.7910159826278687, 0.7910159826278687], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [4, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset100_AbdominalOrganSegmentation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.7910159826278687, 0.7910159826278687], 'original_median_shape_after_transp': [103, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5475.0, 'mean': 108.54532623291016, 'median': 108.0, 'min': -1024.0, 'percentile_00_5': -36.0, 'percentile_99_5': 270.0, 'std': 50.83189010620117}}} 
 
2023-10-08 08:14:11.555836: unpacking dataset... 
2023-10-08 08:14:17.564816: unpacking done... 
2023-10-08 08:14:17.573359: do_dummy_2d_data_aug: False 
2023-10-08 08:14:17.590351: Using splits from existing split file: /home/late/nnUNetFrame/dataset/nnUNet_preprocessed/Dataset100_AbdominalOrganSegmentation/splits_final.json 
2023-10-08 08:14:17.596790: The split file contains 5 splits. 
2023-10-08 08:14:17.599874: Desired fold for training: 0 
2023-10-08 08:14:17.602724: This split has 798 training and 200 validation cases. 
2023-10-08 08:14:17.780790: Unable to plot network architecture: 
2023-10-08 08:14:17.784327: No module named 'IPython' 
2023-10-08 08:14:17.870175:  
2023-10-08 08:14:17.874377: Epoch 0 
2023-10-08 08:14:17.877716: Current learning rate: 0.01 
2023-10-08 08:19:28.902624: train_loss 0.3175 
2023-10-08 08:19:28.913950: val_loss 0.1373 
2023-10-08 08:19:28.919084: Pseudo dice [0.6961, 0.2302, 0.4583, 0.0] 
2023-10-08 08:19:28.924870: Epoch time: 311.04 s 
2023-10-08 08:19:28.930668: Yayy! New best EMA pseudo Dice: 0.3462 
2023-10-08 08:19:31.136236:  
2023-10-08 08:19:31.142146: Epoch 1 
2023-10-08 08:19:31.147378: Current learning rate: 0.00999 
2023-10-08 08:22:54.128243: train_loss 0.0862 
2023-10-08 08:22:54.136358: val_loss 0.0221 
2023-10-08 08:22:54.141606: Pseudo dice [0.7404, 0.4947, 0.4349, 0.0] 
2023-10-08 08:22:54.146064: Epoch time: 202.99 s 
2023-10-08 08:22:54.149807: Yayy! New best EMA pseudo Dice: 0.3533 
2023-10-08 08:22:56.312011:  
2023-10-08 08:22:56.317344: Epoch 2 
2023-10-08 08:22:56.320704: Current learning rate: 0.00998 
2023-10-08 08:25:52.928054: train_loss -0.0008 
2023-10-08 08:25:52.936162: val_loss -0.0973 
2023-10-08 08:25:52.941780: Pseudo dice [0.803, 0.6137, 0.4375, 0.0] 
2023-10-08 08:25:52.947104: Epoch time: 176.62 s 
2023-10-08 08:25:52.952485: Yayy! New best EMA pseudo Dice: 0.3643 
2023-10-08 08:25:55.320296:  
2023-10-08 08:25:55.325579: Epoch 3 
2023-10-08 08:25:55.330622: Current learning rate: 0.00997 
2023-10-08 08:28:45.200635: train_loss -0.1184 
2023-10-08 08:28:45.211425: val_loss -0.1354 
2023-10-08 08:28:45.217060: Pseudo dice [0.7785, 0.7487, 0.2154, 0.0] 
2023-10-08 08:28:45.223317: Epoch time: 169.88 s 
2023-10-08 08:28:45.229051: Yayy! New best EMA pseudo Dice: 0.3714 
2023-10-08 08:28:47.311242:  
2023-10-08 08:28:47.316450: Epoch 4 
2023-10-08 08:28:47.321200: Current learning rate: 0.00996 
2023-10-08 08:31:24.535896: train_loss -0.1645 
2023-10-08 08:31:24.546635: val_loss -0.2608 
2023-10-08 08:31:24.551159: Pseudo dice [0.8143, 0.8103, 0.5584, 0.0] 
2023-10-08 08:31:24.557582: Epoch time: 157.23 s 
2023-10-08 08:31:24.562950: Yayy! New best EMA pseudo Dice: 0.3889 
2023-10-08 08:31:26.741741:  
2023-10-08 08:31:26.746863: Epoch 5 
2023-10-08 08:31:26.751877: Current learning rate: 0.00995 
2023-10-08 08:33:54.643217: train_loss -0.2 
2023-10-08 08:33:54.654018: val_loss -0.2934 
2023-10-08 08:33:54.666290: Pseudo dice [0.8407, 0.8366, 0.6542, 0.0193] 
2023-10-08 08:33:54.670754: Epoch time: 147.9 s 
2023-10-08 08:33:54.674940: Yayy! New best EMA pseudo Dice: 0.4088 
2023-10-08 08:33:56.980619:  
2023-10-08 08:33:56.984796: Epoch 6 
2023-10-08 08:33:56.988480: Current learning rate: 0.00995 
2023-10-08 08:36:16.356395: train_loss -0.245 
2023-10-08 08:36:16.364845: val_loss -0.3061 
2023-10-08 08:36:16.368781: Pseudo dice [0.8483, 0.8299, 0.6466, 0.238] 
2023-10-08 08:36:16.372853: Epoch time: 139.38 s 
2023-10-08 08:36:16.377016: Yayy! New best EMA pseudo Dice: 0.432 
2023-10-08 08:36:18.461819:  
2023-10-08 08:36:18.466335: Epoch 7 
2023-10-08 08:36:18.470023: Current learning rate: 0.00994 
2023-10-08 08:38:38.542270: train_loss -0.3059 
2023-10-08 08:38:38.550035: val_loss -0.3244 
2023-10-08 08:38:38.553479: Pseudo dice [0.8153, 0.8307, 0.6897, 0.3541] 
2023-10-08 08:38:38.558424: Epoch time: 140.08 s 
2023-10-08 08:38:38.561830: Yayy! New best EMA pseudo Dice: 0.456 
2023-10-08 08:38:40.712687:  
2023-10-08 08:38:40.717227: Epoch 8 
2023-10-08 08:38:40.721340: Current learning rate: 0.00993 
2023-10-08 08:40:57.717143: train_loss -0.3066 
2023-10-08 08:40:57.725017: val_loss -0.3261 
2023-10-08 08:40:57.728730: Pseudo dice [0.8415, 0.8773, 0.6417, 0.3157] 
2023-10-08 08:40:57.732665: Epoch time: 137.01 s 
2023-10-08 08:40:57.736393: Yayy! New best EMA pseudo Dice: 0.4773 
2023-10-08 08:40:59.877352:  
2023-10-08 08:40:59.881348: Epoch 9 
2023-10-08 08:40:59.884865: Current learning rate: 0.00992 
2023-10-08 08:43:12.239680: train_loss -0.3833 
2023-10-08 08:43:12.248789: val_loss -0.4423 
2023-10-08 08:43:12.252953: Pseudo dice [0.8821, 0.8864, 0.8097, 0.3613] 
2023-10-08 08:43:12.257178: Epoch time: 132.37 s 
2023-10-08 08:43:12.261188: Yayy! New best EMA pseudo Dice: 0.5031 
2023-10-08 08:43:14.343869:  
2023-10-08 08:43:14.348296: Epoch 10 
2023-10-08 08:43:14.351963: Current learning rate: 0.00991 
2023-10-08 08:45:32.415506: train_loss -0.3821 
2023-10-08 08:45:32.423257: val_loss -0.4005 
2023-10-08 08:45:32.426638: Pseudo dice [0.8787, 0.8789, 0.7951, 0.3352] 
2023-10-08 08:45:32.430386: Epoch time: 138.08 s 
2023-10-08 08:45:32.433616: Yayy! New best EMA pseudo Dice: 0.5249 
2023-10-08 08:45:34.763235:  
2023-10-08 08:45:34.766762: Epoch 11 
2023-10-08 08:45:34.770220: Current learning rate: 0.0099 
2023-10-08 08:47:51.984102: train_loss -0.4124 
2023-10-08 08:47:51.992346: val_loss -0.4529 
2023-10-08 08:47:51.996673: Pseudo dice [0.8604, 0.8853, 0.7686, 0.3917] 
2023-10-08 08:47:52.000900: Epoch time: 137.22 s 
2023-10-08 08:47:52.004641: Yayy! New best EMA pseudo Dice: 0.5451 
2023-10-08 08:47:54.167923:  
2023-10-08 08:47:54.171526: Epoch 12 
2023-10-08 08:47:54.175627: Current learning rate: 0.00989 
2023-10-08 08:49:58.943305: train_loss -0.401 
2023-10-08 08:49:58.950402: val_loss -0.4584 
2023-10-08 08:49:58.954427: Pseudo dice [0.8807, 0.9114, 0.7903, 0.4532] 
2023-10-08 08:49:58.958431: Epoch time: 124.78 s 
2023-10-08 08:49:58.961948: Yayy! New best EMA pseudo Dice: 0.5665 
2023-10-08 08:50:01.049501:  
2023-10-08 08:50:01.053099: Epoch 13 
2023-10-08 08:50:01.056411: Current learning rate: 0.00988 
2023-10-08 08:52:04.336198: train_loss -0.4346 
2023-10-08 08:52:04.345923: val_loss -0.4777 
2023-10-08 08:52:04.349062: Pseudo dice [0.8747, 0.8825, 0.7489, 0.4828] 
2023-10-08 08:52:04.351792: Epoch time: 123.29 s 
2023-10-08 08:52:04.354705: Yayy! New best EMA pseudo Dice: 0.5846 
2023-10-08 08:52:06.516390:  
2023-10-08 08:52:06.520365: Epoch 14 
2023-10-08 08:52:06.524068: Current learning rate: 0.00987 
2023-10-08 08:54:12.081135: train_loss -0.4642 
2023-10-08 08:54:12.088824: val_loss -0.4465 
2023-10-08 08:54:12.092952: Pseudo dice [0.8955, 0.8827, 0.7369, 0.4499] 
2023-10-08 08:54:12.096840: Epoch time: 125.57 s 
2023-10-08 08:54:12.100114: Yayy! New best EMA pseudo Dice: 0.6002 
2023-10-08 08:54:14.283860:  
2023-10-08 08:54:14.289035: Epoch 15 
2023-10-08 08:54:14.293831: Current learning rate: 0.00986 
2023-10-08 08:56:20.519565: train_loss -0.4321 
2023-10-08 08:56:20.526106: val_loss -0.4573 
2023-10-08 08:56:20.530122: Pseudo dice [0.8697, 0.9036, 0.8121, 0.4194] 
2023-10-08 08:56:20.532993: Epoch time: 126.24 s 
2023-10-08 08:56:20.536312: Yayy! New best EMA pseudo Dice: 0.6153 
2023-10-08 08:56:22.855687:  
2023-10-08 08:56:22.860061: Epoch 16 
2023-10-08 08:56:22.864247: Current learning rate: 0.00986 
2023-10-08 08:58:22.777081: train_loss -0.4738 
2023-10-08 08:58:22.784155: val_loss -0.4907 
2023-10-08 08:58:22.787435: Pseudo dice [0.9051, 0.8846, 0.8545, 0.5465] 
2023-10-08 08:58:22.790846: Epoch time: 119.92 s 
2023-10-08 08:58:22.794345: Yayy! New best EMA pseudo Dice: 0.6336 
2023-10-08 08:58:24.938982:  
2023-10-08 08:58:24.943760: Epoch 17 
2023-10-08 08:58:24.953322: Current learning rate: 0.00985 
2023-10-08 09:00:35.030502: train_loss -0.472 
2023-10-08 09:00:35.037907: val_loss -0.4951 
2023-10-08 09:00:35.042194: Pseudo dice [0.9044, 0.8528, 0.893, 0.4742] 
2023-10-08 09:00:35.045886: Epoch time: 130.1 s 
2023-10-08 09:00:35.050234: Yayy! New best EMA pseudo Dice: 0.6483 
2023-10-08 09:00:37.194089:  
2023-10-08 09:00:37.197979: Epoch 18 
2023-10-08 09:00:37.201383: Current learning rate: 0.00984 
2023-10-08 09:02:38.155986: train_loss -0.4811 
2023-10-08 09:02:38.163303: val_loss -0.5518 
2023-10-08 09:02:38.166864: Pseudo dice [0.9243, 0.8855, 0.9129, 0.566] 
2023-10-08 09:02:38.170460: Epoch time: 120.97 s 
2023-10-08 09:02:38.174249: Yayy! New best EMA pseudo Dice: 0.6657 
2023-10-08 09:02:40.335038:  
2023-10-08 09:02:40.339155: Epoch 19 
2023-10-08 09:02:40.342849: Current learning rate: 0.00983 
2023-10-08 09:04:41.670438: train_loss -0.4975 
2023-10-08 09:04:41.677418: val_loss -0.5577 
2023-10-08 09:04:41.681145: Pseudo dice [0.9072, 0.9038, 0.815, 0.5759] 
2023-10-08 09:04:41.684422: Epoch time: 121.34 s 
2023-10-08 09:04:41.687533: Yayy! New best EMA pseudo Dice: 0.6792 
2023-10-08 09:04:43.829754:  
2023-10-08 09:04:43.833889: Epoch 20 
2023-10-08 09:04:43.837373: Current learning rate: 0.00982 
2023-10-08 09:06:42.065571: train_loss -0.5211 
2023-10-08 09:06:42.073295: val_loss -0.5783 
2023-10-08 09:06:42.077955: Pseudo dice [0.9157, 0.9343, 0.8841, 0.5605] 
2023-10-08 09:06:42.082482: Epoch time: 118.24 s 
2023-10-08 09:06:42.086150: Yayy! New best EMA pseudo Dice: 0.6936 
2023-10-08 09:06:44.392344:  
2023-10-08 09:06:44.398344: Epoch 21 
2023-10-08 09:06:44.402169: Current learning rate: 0.00981 
2023-10-08 09:08:47.133235: train_loss -0.5075 
2023-10-08 09:08:47.140376: val_loss -0.5543 
2023-10-08 09:08:47.143838: Pseudo dice [0.9216, 0.9133, 0.891, 0.5042] 
2023-10-08 09:08:47.147344: Epoch time: 122.74 s 
2023-10-08 09:08:47.150682: Yayy! New best EMA pseudo Dice: 0.705 
2023-10-08 09:08:49.143053:  
2023-10-08 09:08:49.147075: Epoch 22 
2023-10-08 09:08:49.150736: Current learning rate: 0.0098 
2023-10-08 09:11:01.048039: train_loss -0.5279 
2023-10-08 09:11:01.056122: val_loss -0.5024 
2023-10-08 09:11:01.060203: Pseudo dice [0.8901, 0.9051, 0.8129, 0.5083] 
2023-10-08 09:11:01.064110: Epoch time: 131.91 s 
2023-10-08 09:11:01.067492: Yayy! New best EMA pseudo Dice: 0.7124 
2023-10-08 09:11:03.163946:  
2023-10-08 09:11:03.167658: Epoch 23 
2023-10-08 09:11:03.171535: Current learning rate: 0.00979 
2023-10-08 09:13:10.447582: train_loss -0.5293 
2023-10-08 09:13:10.454582: val_loss -0.5552 
2023-10-08 09:13:10.458454: Pseudo dice [0.8903, 0.9313, 0.8363, 0.5719] 
2023-10-08 09:13:10.461998: Epoch time: 127.29 s 
2023-10-08 09:13:10.465957: Yayy! New best EMA pseudo Dice: 0.7219 
2023-10-08 09:13:12.479082:  
2023-10-08 09:13:12.483302: Epoch 24 
2023-10-08 09:13:12.486607: Current learning rate: 0.00978 
2023-10-08 09:15:12.159235: train_loss -0.5609 
2023-10-08 09:15:12.166767: val_loss -0.586 
2023-10-08 09:15:12.169944: Pseudo dice [0.9111, 0.9306, 0.8869, 0.5573] 
2023-10-08 09:15:12.173437: Epoch time: 119.68 s 
2023-10-08 09:15:12.177124: Yayy! New best EMA pseudo Dice: 0.7319 
2023-10-08 09:15:14.252687:  
2023-10-08 09:15:14.257168: Epoch 25 
2023-10-08 09:15:14.263248: Current learning rate: 0.00977 
2023-10-08 09:17:18.617786: train_loss -0.581 
2023-10-08 09:17:18.625540: val_loss -0.5707 
2023-10-08 09:17:18.628782: Pseudo dice [0.9153, 0.9022, 0.8497, 0.5487] 
2023-10-08 09:17:18.632079: Epoch time: 124.37 s 
2023-10-08 09:17:18.635206: Yayy! New best EMA pseudo Dice: 0.7391 
2023-10-08 09:17:20.803086:  
2023-10-08 09:17:20.806800: Epoch 26 
2023-10-08 09:17:20.810837: Current learning rate: 0.00977 
2023-10-08 09:19:22.722636: train_loss -0.5693 
2023-10-08 09:19:22.729042: val_loss -0.5994 
2023-10-08 09:19:22.732360: Pseudo dice [0.9203, 0.9133, 0.9024, 0.5671] 
2023-10-08 09:19:22.735286: Epoch time: 121.92 s 
2023-10-08 09:19:22.738536: Yayy! New best EMA pseudo Dice: 0.7478 
2023-10-08 09:19:24.797795:  
2023-10-08 09:19:24.801564: Epoch 27 
2023-10-08 09:19:24.805456: Current learning rate: 0.00976 
2023-10-08 09:21:26.514588: train_loss -0.5763 
2023-10-08 09:21:26.521468: val_loss -0.6614 
2023-10-08 09:21:26.524953: Pseudo dice [0.924, 0.9231, 0.915, 0.6345] 
2023-10-08 09:21:26.528778: Epoch time: 121.72 s 
2023-10-08 09:21:26.531622: Yayy! New best EMA pseudo Dice: 0.7579 
2023-10-08 09:21:28.583655:  
2023-10-08 09:21:28.587790: Epoch 28 
2023-10-08 09:21:28.591606: Current learning rate: 0.00975 
2023-10-08 09:23:25.493150: train_loss -0.5723 
2023-10-08 09:23:25.500646: val_loss -0.5963 
2023-10-08 09:23:25.504746: Pseudo dice [0.9259, 0.9091, 0.8947, 0.5725] 
2023-10-08 09:23:25.508731: Epoch time: 116.91 s 
2023-10-08 09:23:25.512691: Yayy! New best EMA pseudo Dice: 0.7647 
2023-10-08 09:23:27.559738:  
2023-10-08 09:23:27.563675: Epoch 29 
2023-10-08 09:23:27.567211: Current learning rate: 0.00974 
2023-10-08 09:25:32.955014: train_loss -0.5903 
2023-10-08 09:25:32.973211: val_loss -0.5722 
2023-10-08 09:25:32.977504: Pseudo dice [0.8929, 0.9216, 0.8196, 0.6551] 
2023-10-08 09:25:32.980883: Epoch time: 125.4 s 
2023-10-08 09:25:32.983302: Yayy! New best EMA pseudo Dice: 0.7704 
2023-10-08 09:25:35.142414:  
2023-10-08 09:25:35.146472: Epoch 30 
2023-10-08 09:25:35.150243: Current learning rate: 0.00973 
2023-10-08 09:27:36.506475: train_loss -0.5939 
2023-10-08 09:27:36.513767: val_loss -0.6688 
2023-10-08 09:27:36.517768: Pseudo dice [0.9406, 0.9325, 0.9151, 0.6026] 
2023-10-08 09:27:36.521512: Epoch time: 121.37 s 
2023-10-08 09:27:36.524939: Yayy! New best EMA pseudo Dice: 0.7782 
2023-10-08 09:27:38.636482:  
2023-10-08 09:27:38.641364: Epoch 31 
2023-10-08 09:27:38.646153: Current learning rate: 0.00972 
2023-10-08 09:29:41.342360: train_loss -0.5843 
2023-10-08 09:29:41.349642: val_loss -0.6142 
2023-10-08 09:29:41.353601: Pseudo dice [0.9414, 0.9247, 0.9072, 0.6408] 
2023-10-08 09:29:41.356688: Epoch time: 122.71 s 
2023-10-08 09:29:41.360437: Yayy! New best EMA pseudo Dice: 0.7857 
2023-10-08 09:29:43.469486:  
2023-10-08 09:29:43.473833: Epoch 32 
2023-10-08 09:29:43.477526: Current learning rate: 0.00971 
2023-10-08 09:31:46.625701: train_loss -0.611 
2023-10-08 09:31:46.633417: val_loss -0.7025 
2023-10-08 09:31:46.636958: Pseudo dice [0.9294, 0.9331, 0.9224, 0.7246] 
2023-10-08 09:31:46.640488: Epoch time: 123.16 s 
2023-10-08 09:31:46.643574: Yayy! New best EMA pseudo Dice: 0.7949 
2023-10-08 09:31:48.785992:  
2023-10-08 09:31:48.789880: Epoch 33 
2023-10-08 09:31:48.793694: Current learning rate: 0.0097 
2023-10-08 09:33:46.939499: train_loss -0.5693 
2023-10-08 09:33:46.946190: val_loss -0.633 
2023-10-08 09:33:46.948893: Pseudo dice [0.9248, 0.8912, 0.9265, 0.622] 
2023-10-08 09:33:46.952235: Epoch time: 118.16 s 
2023-10-08 09:33:46.955401: Yayy! New best EMA pseudo Dice: 0.7995 
2023-10-08 09:33:49.023318:  
2023-10-08 09:33:49.027411: Epoch 34 
2023-10-08 09:33:49.030972: Current learning rate: 0.00969 
2023-10-08 09:35:52.085930: train_loss -0.6002 
2023-10-08 09:35:52.092944: val_loss -0.6429 
2023-10-08 09:35:52.096004: Pseudo dice [0.9383, 0.8855, 0.935, 0.6868] 
2023-10-08 09:35:52.099177: Epoch time: 123.07 s 
2023-10-08 09:35:52.102408: Yayy! New best EMA pseudo Dice: 0.8057 
2023-10-08 09:35:54.269110:  
2023-10-08 09:35:54.273075: Epoch 35 
2023-10-08 09:35:54.276880: Current learning rate: 0.00968 
2023-10-08 09:37:54.997480: train_loss -0.5852 
2023-10-08 09:37:55.004771: val_loss -0.5782 
2023-10-08 09:37:55.008146: Pseudo dice [0.9418, 0.8995, 0.8966, 0.5898] 
2023-10-08 09:37:55.011781: Epoch time: 120.73 s 
2023-10-08 09:37:55.015196: Yayy! New best EMA pseudo Dice: 0.8083 
2023-10-08 09:37:57.163874:  
2023-10-08 09:37:57.168760: Epoch 36 
2023-10-08 09:37:57.173009: Current learning rate: 0.00968 
2023-10-08 09:40:01.016738: train_loss -0.6263 
2023-10-08 09:40:01.025190: val_loss -0.675 
2023-10-08 09:40:01.029114: Pseudo dice [0.9213, 0.9219, 0.9123, 0.7282] 
2023-10-08 09:40:01.032783: Epoch time: 123.86 s 
2023-10-08 09:40:01.036864: Yayy! New best EMA pseudo Dice: 0.8146 
2023-10-08 09:40:03.191742:  
2023-10-08 09:40:03.195311: Epoch 37 
2023-10-08 09:40:03.198530: Current learning rate: 0.00967 
2023-10-08 09:42:04.921948: train_loss -0.6131 
2023-10-08 09:42:04.928634: val_loss -0.6393 
2023-10-08 09:42:04.932569: Pseudo dice [0.9402, 0.9382, 0.9158, 0.6204] 
2023-10-08 09:42:04.936166: Epoch time: 121.73 s 
2023-10-08 09:42:04.939716: Yayy! New best EMA pseudo Dice: 0.8185 
2023-10-08 09:42:07.130592:  
2023-10-08 09:42:07.134638: Epoch 38 
2023-10-08 09:42:07.138182: Current learning rate: 0.00966 
2023-10-08 09:44:07.991930: train_loss -0.6341 
2023-10-08 09:44:07.998890: val_loss -0.6746 
2023-10-08 09:44:08.002339: Pseudo dice [0.9417, 0.9371, 0.888, 0.6865] 
2023-10-08 09:44:08.005986: Epoch time: 120.86 s 
2023-10-08 09:44:08.009234: Yayy! New best EMA pseudo Dice: 0.823 
2023-10-08 09:44:10.123302:  
2023-10-08 09:44:10.128832: Epoch 39 
2023-10-08 09:44:10.133307: Current learning rate: 0.00965 
2023-10-08 09:46:16.860224: train_loss -0.6127 
2023-10-08 09:46:16.866834: val_loss -0.6702 
2023-10-08 09:46:16.869886: Pseudo dice [0.9479, 0.9118, 0.9202, 0.6569] 
2023-10-08 09:46:16.873572: Epoch time: 126.74 s 
2023-10-08 09:46:16.876980: Yayy! New best EMA pseudo Dice: 0.8266 
2023-10-08 09:46:19.262400:  
2023-10-08 09:46:19.266378: Epoch 40 
2023-10-08 09:46:19.269853: Current learning rate: 0.00964 
2023-10-08 09:48:18.830920: train_loss -0.6401 
2023-10-08 09:48:18.837857: val_loss -0.6451 
2023-10-08 09:48:18.841801: Pseudo dice [0.9439, 0.9393, 0.9341, 0.6659] 
2023-10-08 09:48:18.845362: Epoch time: 119.57 s 
2023-10-08 09:48:18.849281: Yayy! New best EMA pseudo Dice: 0.831 
2023-10-08 09:48:21.025652:  
2023-10-08 09:48:21.029782: Epoch 41 
2023-10-08 09:48:21.032634: Current learning rate: 0.00963 
2023-10-08 09:50:23.485996: train_loss -0.6623 
2023-10-08 09:50:23.492658: val_loss -0.6922 
2023-10-08 09:50:23.496015: Pseudo dice [0.961, 0.9282, 0.9291, 0.6628] 
2023-10-08 09:50:23.499074: Epoch time: 122.46 s 
2023-10-08 09:50:23.502356: Yayy! New best EMA pseudo Dice: 0.8349 
2023-10-08 09:50:25.546952:  
2023-10-08 09:50:25.550881: Epoch 42 
2023-10-08 09:50:25.554480: Current learning rate: 0.00962 
2023-10-08 09:52:23.861246: train_loss -0.6477 
2023-10-08 09:52:23.868508: val_loss -0.7019 
2023-10-08 09:52:23.875359: Pseudo dice [0.9484, 0.9408, 0.9152, 0.7216] 
2023-10-08 09:52:23.879107: Epoch time: 118.32 s 
2023-10-08 09:52:23.882467: Yayy! New best EMA pseudo Dice: 0.8396 
2023-10-08 09:52:25.921608:  
2023-10-08 09:52:25.925796: Epoch 43 
2023-10-08 09:52:25.929888: Current learning rate: 0.00961 
2023-10-08 09:54:30.034691: train_loss -0.6543 
2023-10-08 09:54:30.041570: val_loss -0.6365 
2023-10-08 09:54:30.044512: Pseudo dice [0.9337, 0.9311, 0.8741, 0.6863] 
2023-10-08 09:54:30.047534: Epoch time: 124.12 s 
2023-10-08 09:54:30.050361: Yayy! New best EMA pseudo Dice: 0.8413 
2023-10-08 09:54:32.081344:  
2023-10-08 09:54:32.085409: Epoch 44 
2023-10-08 09:54:32.089041: Current learning rate: 0.0096 
2023-10-08 09:56:31.309980: train_loss -0.6645 
2023-10-08 09:56:31.316885: val_loss -0.673 
2023-10-08 09:56:31.320346: Pseudo dice [0.9257, 0.9383, 0.9123, 0.7102] 
2023-10-08 09:56:31.325921: Epoch time: 119.23 s 
2023-10-08 09:56:31.329400: Yayy! New best EMA pseudo Dice: 0.8443 
2023-10-08 09:56:33.349402:  
2023-10-08 09:56:33.353523: Epoch 45 
2023-10-08 09:56:33.357431: Current learning rate: 0.00959 
2023-10-08 09:58:37.040703: train_loss -0.6267 
2023-10-08 09:58:37.045587: val_loss -0.6336 
2023-10-08 09:58:37.047784: Pseudo dice [0.9477, 0.9194, 0.9002, 0.6753] 
2023-10-08 09:58:37.050242: Epoch time: 123.69 s 
2023-10-08 09:58:37.053030: Yayy! New best EMA pseudo Dice: 0.8459 
2023-10-08 09:58:39.113226:  
2023-10-08 09:58:39.117099: Epoch 46 
2023-10-08 09:58:39.121400: Current learning rate: 0.00959 
2023-10-08 10:00:38.709502: train_loss -0.6388 
2023-10-08 10:00:38.716306: val_loss -0.6338 
2023-10-08 10:00:38.719689: Pseudo dice [0.9512, 0.9191, 0.9043, 0.5876] 
2023-10-08 10:00:38.722934: Epoch time: 119.6 s 
2023-10-08 10:00:40.037972:  
2023-10-08 10:00:40.041818: Epoch 47 
2023-10-08 10:00:40.045468: Current learning rate: 0.00958 
2023-10-08 10:02:39.565610: train_loss -0.6412 
2023-10-08 10:02:39.573224: val_loss -0.641 
2023-10-08 10:02:39.576569: Pseudo dice [0.9129, 0.9396, 0.8734, 0.6934] 
2023-10-08 10:02:39.579906: Epoch time: 119.53 s 
2023-10-08 10:02:39.582830: Yayy! New best EMA pseudo Dice: 0.8463 
2023-10-08 10:02:41.640572:  
2023-10-08 10:02:41.644807: Epoch 48 
2023-10-08 10:02:41.649304: Current learning rate: 0.00957 
2023-10-08 10:04:43.424060: train_loss -0.6567 
2023-10-08 10:04:43.431012: val_loss -0.7119 
2023-10-08 10:04:43.434220: Pseudo dice [0.9514, 0.9372, 0.951, 0.7108] 
2023-10-08 10:04:43.437306: Epoch time: 121.79 s 
2023-10-08 10:04:43.440127: Yayy! New best EMA pseudo Dice: 0.8505 
2023-10-08 10:04:45.527224:  
2023-10-08 10:04:45.532906: Epoch 49 
2023-10-08 10:04:45.537217: Current learning rate: 0.00956 
2023-10-08 10:06:41.522301: train_loss -0.6635 
2023-10-08 10:06:41.530931: val_loss -0.6746 
2023-10-08 10:06:41.534725: Pseudo dice [0.937, 0.9181, 0.8854, 0.6976] 
2023-10-08 10:06:41.538475: Epoch time: 116.0 s 
2023-10-08 10:06:42.254578: Yayy! New best EMA pseudo Dice: 0.8514 
2023-10-08 10:06:44.345836:  
2023-10-08 10:06:44.349972: Epoch 50 
2023-10-08 10:06:44.353544: Current learning rate: 0.00955 
2023-10-08 10:08:44.531507: train_loss -0.6499 
2023-10-08 10:08:44.538362: val_loss -0.7008 
2023-10-08 10:08:44.541552: Pseudo dice [0.945, 0.9382, 0.9443, 0.7281] 
2023-10-08 10:08:44.544967: Epoch time: 120.19 s 
2023-10-08 10:08:44.548069: Yayy! New best EMA pseudo Dice: 0.8551 
2023-10-08 10:08:46.809852:  
2023-10-08 10:08:46.814244: Epoch 51 
2023-10-08 10:08:46.818212: Current learning rate: 0.00954 
2023-10-08 10:10:47.338054: train_loss -0.6684 
2023-10-08 10:10:47.345055: val_loss -0.6289 
2023-10-08 10:10:47.348333: Pseudo dice [0.942, 0.9244, 0.9048, 0.7063] 
2023-10-08 10:10:47.351809: Epoch time: 120.53 s 
2023-10-08 10:10:47.355564: Yayy! New best EMA pseudo Dice: 0.8565 
2023-10-08 10:10:49.413431:  
2023-10-08 10:10:49.417728: Epoch 52 
2023-10-08 10:10:49.421426: Current learning rate: 0.00953 
2023-10-08 10:12:43.076652: train_loss -0.6709 
2023-10-08 10:12:43.083582: val_loss -0.6683 
2023-10-08 10:12:43.086737: Pseudo dice [0.94, 0.9347, 0.9121, 0.6884] 
2023-10-08 10:12:43.089966: Epoch time: 113.67 s 
2023-10-08 10:12:43.092806: Yayy! New best EMA pseudo Dice: 0.8578 
2023-10-08 10:12:45.153938:  
2023-10-08 10:12:45.158145: Epoch 53 
2023-10-08 10:12:45.161822: Current learning rate: 0.00952 
2023-10-08 10:14:43.361026: train_loss -0.6574 
2023-10-08 10:14:43.368181: val_loss -0.6384 
2023-10-08 10:14:43.371453: Pseudo dice [0.936, 0.9048, 0.9197, 0.6706] 
2023-10-08 10:14:43.374854: Epoch time: 118.21 s 
2023-10-08 10:14:43.377801: Yayy! New best EMA pseudo Dice: 0.8578 
2023-10-08 10:14:45.447866:  
2023-10-08 10:14:45.454264: Epoch 54 
2023-10-08 10:14:45.457598: Current learning rate: 0.00951 
2023-10-08 10:16:47.694621: train_loss -0.6396 
2023-10-08 10:16:47.701358: val_loss -0.6747 
2023-10-08 10:16:47.704155: Pseudo dice [0.9347, 0.9354, 0.8915, 0.719] 
2023-10-08 10:16:47.707698: Epoch time: 122.25 s 
2023-10-08 10:16:47.710734: Yayy! New best EMA pseudo Dice: 0.859 
2023-10-08 10:16:49.822105:  
2023-10-08 10:16:49.826623: Epoch 55 
2023-10-08 10:16:49.830343: Current learning rate: 0.0095 
2023-10-08 10:18:54.297928: train_loss -0.6676 
2023-10-08 10:18:54.305611: val_loss -0.7084 
2023-10-08 10:18:54.309749: Pseudo dice [0.9497, 0.9351, 0.9261, 0.7345] 
2023-10-08 10:18:54.313818: Epoch time: 124.48 s 
2023-10-08 10:18:54.317782: Yayy! New best EMA pseudo Dice: 0.8617 
2023-10-08 10:18:56.562322:  
2023-10-08 10:18:56.566864: Epoch 56 
2023-10-08 10:18:56.571108: Current learning rate: 0.00949 
2023-10-08 10:20:57.138254: train_loss -0.6647 
2023-10-08 10:20:57.145119: val_loss -0.6552 
2023-10-08 10:20:57.149135: Pseudo dice [0.9272, 0.8915, 0.8933, 0.6785] 
2023-10-08 10:20:57.152876: Epoch time: 120.58 s 
2023-10-08 10:20:58.525558:  
2023-10-08 10:20:58.530219: Epoch 57 
2023-10-08 10:20:58.535633: Current learning rate: 0.00949 
2023-10-08 10:23:01.986244: train_loss -0.6877 
2023-10-08 10:23:01.994352: val_loss -0.734 
2023-10-08 10:23:01.998227: Pseudo dice [0.9589, 0.9373, 0.9285, 0.7017] 
2023-10-08 10:23:02.002090: Epoch time: 123.46 s 
2023-10-08 10:23:02.005687: Yayy! New best EMA pseudo Dice: 0.8625 
2023-10-08 10:23:04.130555:  
2023-10-08 10:23:04.134323: Epoch 58 
2023-10-08 10:23:04.137818: Current learning rate: 0.00948 
2023-10-08 10:25:06.948632: train_loss -0.6574 
2023-10-08 10:25:06.956695: val_loss -0.6944 
2023-10-08 10:25:06.960791: Pseudo dice [0.9351, 0.9303, 0.9092, 0.7473] 
2023-10-08 10:25:06.964679: Epoch time: 122.82 s 
2023-10-08 10:25:06.968376: Yayy! New best EMA pseudo Dice: 0.8643 
2023-10-08 10:25:09.083639:  
2023-10-08 10:25:09.087844: Epoch 59 
2023-10-08 10:25:09.090480: Current learning rate: 0.00947 
2023-10-08 10:27:08.543362: train_loss -0.6868 
2023-10-08 10:27:08.550332: val_loss -0.7009 
2023-10-08 10:27:08.554026: Pseudo dice [0.9548, 0.9449, 0.9208, 0.7269] 
2023-10-08 10:27:08.557676: Epoch time: 119.46 s 
2023-10-08 10:27:08.561189: Yayy! New best EMA pseudo Dice: 0.8665 
2023-10-08 10:27:10.662670:  
2023-10-08 10:27:10.667268: Epoch 60 
2023-10-08 10:27:10.672159: Current learning rate: 0.00946 
2023-10-08 10:29:11.926403: train_loss -0.6547 
2023-10-08 10:29:11.934306: val_loss -0.7016 
2023-10-08 10:29:11.938603: Pseudo dice [0.9444, 0.9417, 0.9436, 0.7387] 
2023-10-08 10:29:11.942513: Epoch time: 121.27 s 
2023-10-08 10:29:11.946421: Yayy! New best EMA pseudo Dice: 0.8691 
2023-10-08 10:29:14.208798:  
2023-10-08 10:29:14.213142: Epoch 61 
2023-10-08 10:29:14.217140: Current learning rate: 0.00945 
2023-10-08 10:31:07.621977: train_loss -0.6817 
2023-10-08 10:31:07.628644: val_loss -0.658 
2023-10-08 10:31:07.633798: Pseudo dice [0.9362, 0.9148, 0.8929, 0.6637] 
2023-10-08 10:31:07.637433: Epoch time: 113.42 s 
2023-10-08 10:31:09.015383:  
2023-10-08 10:31:09.020057: Epoch 62 
2023-10-08 10:31:09.024516: Current learning rate: 0.00944 
2023-10-08 10:33:10.902682: train_loss -0.6785 
2023-10-08 10:33:10.909836: val_loss -0.7031 
2023-10-08 10:33:10.913423: Pseudo dice [0.9494, 0.9318, 0.9008, 0.7576] 
2023-10-08 10:33:10.916895: Epoch time: 121.89 s 
2023-10-08 10:33:10.920231: Yayy! New best EMA pseudo Dice: 0.8691 
2023-10-08 10:33:13.054502:  
2023-10-08 10:33:13.058948: Epoch 63 
2023-10-08 10:33:13.062926: Current learning rate: 0.00943 
2023-10-08 10:35:12.550753: train_loss -0.6939 
2023-10-08 10:35:12.558178: val_loss -0.725 
2023-10-08 10:35:12.561589: Pseudo dice [0.9578, 0.9538, 0.9384, 0.7453] 
2023-10-08 10:35:12.565213: Epoch time: 119.5 s 
2023-10-08 10:35:12.568654: Yayy! New best EMA pseudo Dice: 0.8721 
2023-10-08 10:35:14.734922:  
2023-10-08 10:35:14.739387: Epoch 64 
2023-10-08 10:35:14.743735: Current learning rate: 0.00942 
2023-10-08 10:37:13.190035: train_loss -0.7026 
2023-10-08 10:37:13.196532: val_loss -0.6798 
2023-10-08 10:37:13.200500: Pseudo dice [0.9471, 0.9291, 0.9494, 0.6688] 
2023-10-08 10:37:13.203759: Epoch time: 118.46 s 
2023-10-08 10:37:13.207026: Yayy! New best EMA pseudo Dice: 0.8722 
2023-10-08 10:37:15.329317:  
2023-10-08 10:37:15.334220: Epoch 65 
2023-10-08 10:37:15.338449: Current learning rate: 0.00941 
2023-10-08 10:39:14.928270: train_loss -0.7073 
2023-10-08 10:39:14.934846: val_loss -0.6918 
2023-10-08 10:39:14.937805: Pseudo dice [0.9459, 0.9272, 0.9296, 0.6742] 
2023-10-08 10:39:14.941254: Epoch time: 119.6 s 
2023-10-08 10:39:16.529675:  
2023-10-08 10:39:16.533431: Epoch 66 
2023-10-08 10:39:16.537089: Current learning rate: 0.0094 
2023-10-08 10:41:13.010626: train_loss -0.6943 
2023-10-08 10:41:13.017835: val_loss -0.6802 
2023-10-08 10:41:13.021501: Pseudo dice [0.9512, 0.9358, 0.952, 0.6967] 
2023-10-08 10:41:13.025152: Epoch time: 116.48 s 
2023-10-08 10:41:13.028235: Yayy! New best EMA pseudo Dice: 0.8731 
2023-10-08 10:41:15.228537:  
2023-10-08 10:41:15.233925: Epoch 67 
2023-10-08 10:41:15.237764: Current learning rate: 0.00939 
2023-10-08 10:43:13.181927: train_loss -0.6859 
2023-10-08 10:43:13.189678: val_loss -0.7782 
2023-10-08 10:43:13.193282: Pseudo dice [0.9629, 0.952, 0.9554, 0.7825] 
2023-10-08 10:43:13.196712: Epoch time: 117.96 s 
2023-10-08 10:43:13.200093: Yayy! New best EMA pseudo Dice: 0.8771 
2023-10-08 10:43:15.381689:  
2023-10-08 10:43:15.386249: Epoch 68 
2023-10-08 10:43:15.390379: Current learning rate: 0.00939 
2023-10-08 10:45:13.348541: train_loss -0.7075 
2023-10-08 10:45:13.355805: val_loss -0.6581 
2023-10-08 10:45:13.359220: Pseudo dice [0.9267, 0.9512, 0.8358, 0.771] 
2023-10-08 10:45:13.364982: Epoch time: 117.97 s 
2023-10-08 10:45:14.786863:  
2023-10-08 10:45:14.791252: Epoch 69 
2023-10-08 10:45:14.794956: Current learning rate: 0.00938 
2023-10-08 10:47:14.303462: train_loss -0.671 
2023-10-08 10:47:14.310728: val_loss -0.6803 
2023-10-08 10:47:14.314374: Pseudo dice [0.9436, 0.9116, 0.9013, 0.7534] 
2023-10-08 10:47:14.318135: Epoch time: 119.52 s 
2023-10-08 10:47:15.789358:  
2023-10-08 10:47:15.793935: Epoch 70 
2023-10-08 10:47:15.798045: Current learning rate: 0.00937 
2023-10-08 10:49:15.065072: train_loss -0.6196 
2023-10-08 10:49:15.073640: val_loss -0.706 
2023-10-08 10:49:15.076610: Pseudo dice [0.949, 0.9478, 0.9224, 0.7204] 
2023-10-08 10:49:15.080882: Epoch time: 119.28 s 
2023-10-08 10:49:15.084342: Yayy! New best EMA pseudo Dice: 0.8775 
2023-10-08 10:49:17.376961:  
2023-10-08 10:49:17.381655: Epoch 71 
2023-10-08 10:49:17.385889: Current learning rate: 0.00936 
2023-10-08 10:51:16.332569: train_loss -0.6784 
2023-10-08 10:51:16.340487: val_loss -0.6826 
2023-10-08 10:51:16.344325: Pseudo dice [0.9393, 0.937, 0.9007, 0.7164] 
2023-10-08 10:51:16.348515: Epoch time: 118.96 s 
2023-10-08 10:51:17.795448:  
2023-10-08 10:51:17.799556: Epoch 72 
2023-10-08 10:51:17.803149: Current learning rate: 0.00935 
2023-10-08 10:53:13.275560: train_loss -0.7065 
2023-10-08 10:53:13.282028: val_loss -0.7024 
2023-10-08 10:53:13.285451: Pseudo dice [0.9487, 0.9477, 0.9064, 0.6941] 
2023-10-08 10:53:13.289023: Epoch time: 115.48 s 
2023-10-08 10:53:14.722418:  
2023-10-08 10:53:14.726944: Epoch 73 
2023-10-08 10:53:14.730864: Current learning rate: 0.00934 
2023-10-08 10:55:08.858396: train_loss -0.7041 
2023-10-08 10:55:08.865165: val_loss -0.7174 
2023-10-08 10:55:08.868513: Pseudo dice [0.9541, 0.9295, 0.9337, 0.7597] 
2023-10-08 10:55:08.871859: Epoch time: 114.14 s 
2023-10-08 10:55:08.875131: Yayy! New best EMA pseudo Dice: 0.8785 
2023-10-08 10:55:11.004107:  
2023-10-08 10:55:11.009184: Epoch 74 
2023-10-08 10:55:11.013702: Current learning rate: 0.00933 
2023-10-08 10:57:11.228947: train_loss -0.7094 
2023-10-08 10:57:11.236273: val_loss -0.7492 
2023-10-08 10:57:11.240166: Pseudo dice [0.9654, 0.9362, 0.9565, 0.7447] 
2023-10-08 10:57:11.243773: Epoch time: 120.23 s 
2023-10-08 10:57:11.246958: Yayy! New best EMA pseudo Dice: 0.8807 
2023-10-08 10:57:13.399790:  
2023-10-08 10:57:13.404078: Epoch 75 
2023-10-08 10:57:13.407648: Current learning rate: 0.00932 
2023-10-08 10:59:13.157201: train_loss -0.7287 
2023-10-08 10:59:13.165004: val_loss -0.6989 
2023-10-08 10:59:13.168781: Pseudo dice [0.958, 0.9484, 0.9074, 0.7301] 
2023-10-08 10:59:13.172365: Epoch time: 119.76 s 
2023-10-08 10:59:13.175929: Yayy! New best EMA pseudo Dice: 0.8813 
2023-10-08 10:59:15.500254:  
2023-10-08 10:59:15.504564: Epoch 76 
2023-10-08 10:59:15.508090: Current learning rate: 0.00931 
2023-10-08 11:01:17.223354: train_loss -0.7112 
2023-10-08 11:01:17.229494: val_loss -0.6832 
2023-10-08 11:01:17.232892: Pseudo dice [0.9468, 0.9134, 0.934, 0.7476] 
2023-10-08 11:01:17.236015: Epoch time: 121.73 s 
2023-10-08 11:01:17.238858: Yayy! New best EMA pseudo Dice: 0.8817 
2023-10-08 11:01:19.405800:  
2023-10-08 11:01:19.409920: Epoch 77 
2023-10-08 11:01:19.413492: Current learning rate: 0.0093 
2023-10-08 11:03:15.961044: train_loss -0.7094 
2023-10-08 11:03:15.968233: val_loss -0.7273 
2023-10-08 11:03:15.972019: Pseudo dice [0.9535, 0.946, 0.9268, 0.7471] 
2023-10-08 11:03:15.975535: Epoch time: 116.56 s 
2023-10-08 11:03:15.979023: Yayy! New best EMA pseudo Dice: 0.8828 
2023-10-08 11:03:18.148288:  
2023-10-08 11:03:18.153807: Epoch 78 
2023-10-08 11:03:18.157810: Current learning rate: 0.0093 
2023-10-08 11:05:13.276315: train_loss -0.6893 
2023-10-08 11:05:13.286764: val_loss -0.6833 
2023-10-08 11:05:13.290895: Pseudo dice [0.949, 0.9374, 0.8964, 0.7397] 
2023-10-08 11:05:13.294416: Epoch time: 115.13 s 
2023-10-08 11:05:14.771406:  
2023-10-08 11:05:14.775820: Epoch 79 
2023-10-08 11:05:14.779811: Current learning rate: 0.00929 
2023-10-08 11:07:14.190311: train_loss -0.7221 
2023-10-08 11:07:14.197180: val_loss -0.7441 
2023-10-08 11:07:14.200458: Pseudo dice [0.9631, 0.9556, 0.9524, 0.7512] 
2023-10-08 11:07:14.203826: Epoch time: 119.42 s 
2023-10-08 11:07:14.211362: Yayy! New best EMA pseudo Dice: 0.8849 
2023-10-08 11:07:16.399436:  
2023-10-08 11:07:16.403942: Epoch 80 
2023-10-08 11:07:16.407579: Current learning rate: 0.00928 
2023-10-08 11:09:14.480628: train_loss -0.7001 
2023-10-08 11:09:14.488272: val_loss -0.7153 
2023-10-08 11:09:14.491667: Pseudo dice [0.9576, 0.9119, 0.9392, 0.7655] 
2023-10-08 11:09:14.495028: Epoch time: 118.08 s 
2023-10-08 11:09:14.498498: Yayy! New best EMA pseudo Dice: 0.8858 
2023-10-08 11:09:16.844307:  
2023-10-08 11:09:16.849204: Epoch 81 
2023-10-08 11:09:16.853342: Current learning rate: 0.00927 
2023-10-08 11:11:16.921643: train_loss -0.7171 
2023-10-08 11:11:16.929654: val_loss -0.7227 
2023-10-08 11:11:16.933456: Pseudo dice [0.9515, 0.928, 0.9181, 0.7559] 
2023-10-08 11:11:16.937176: Epoch time: 120.08 s 
2023-10-08 11:11:16.940795: Yayy! New best EMA pseudo Dice: 0.886 
2023-10-08 11:11:19.134582:  
2023-10-08 11:11:19.139341: Epoch 82 
2023-10-08 11:11:19.143271: Current learning rate: 0.00926 
2023-10-08 11:13:15.366048: train_loss -0.7198 
2023-10-08 11:13:15.373540: val_loss -0.6851 
2023-10-08 11:13:15.377065: Pseudo dice [0.9194, 0.9043, 0.8914, 0.719] 
2023-10-08 11:13:15.381042: Epoch time: 116.23 s 
2023-10-08 11:13:16.723680:  
2023-10-08 11:13:16.728312: Epoch 83 
2023-10-08 11:13:16.732310: Current learning rate: 0.00925 
2023-10-08 11:15:15.881700: train_loss -0.7103 
2023-10-08 11:15:15.889979: val_loss -0.7167 
2023-10-08 11:15:15.893861: Pseudo dice [0.9443, 0.9421, 0.934, 0.7358] 
2023-10-08 11:15:15.897712: Epoch time: 119.16 s 
2023-10-08 11:15:17.248646:  
2023-10-08 11:15:17.252556: Epoch 84 
2023-10-08 11:15:17.255907: Current learning rate: 0.00924 
2023-10-08 11:17:14.508079: train_loss -0.6814 
2023-10-08 11:17:14.515597: val_loss -0.7228 
2023-10-08 11:17:14.519378: Pseudo dice [0.9519, 0.9379, 0.8954, 0.7556] 
2023-10-08 11:17:14.523112: Epoch time: 117.26 s 
2023-10-08 11:17:15.943994:  
2023-10-08 11:17:15.948200: Epoch 85 
2023-10-08 11:17:15.951933: Current learning rate: 0.00923 
2023-10-08 11:19:16.337154: train_loss -0.7113 
2023-10-08 11:19:16.344582: val_loss -0.7098 
2023-10-08 11:19:16.348005: Pseudo dice [0.9431, 0.9575, 0.8943, 0.6988] 
2023-10-08 11:19:16.351168: Epoch time: 120.4 s 
2023-10-08 11:19:17.691517:  
2023-10-08 11:19:17.696128: Epoch 86 
2023-10-08 11:19:17.700308: Current learning rate: 0.00922 
2023-10-08 11:21:14.164364: train_loss -0.7115 
2023-10-08 11:21:14.172445: val_loss -0.7475 
2023-10-08 11:21:14.176275: Pseudo dice [0.9399, 0.9372, 0.9466, 0.7824] 
2023-10-08 11:21:14.180277: Epoch time: 116.48 s 
2023-10-08 11:21:15.745864:  
2023-10-08 11:21:15.753422: Epoch 87 
2023-10-08 11:21:15.757157: Current learning rate: 0.00921 
2023-10-08 11:23:14.730988: train_loss -0.7239 
2023-10-08 11:23:14.738735: val_loss -0.7356 
2023-10-08 11:23:14.742130: Pseudo dice [0.9548, 0.9459, 0.9096, 0.7568] 
2023-10-08 11:23:14.745465: Epoch time: 118.99 s 
2023-10-08 11:23:16.133506:  
2023-10-08 11:23:16.137583: Epoch 88 
2023-10-08 11:23:16.141403: Current learning rate: 0.0092 
2023-10-08 11:25:12.325830: train_loss -0.7046 
2023-10-08 11:25:12.333365: val_loss -0.7657 
2023-10-08 11:25:12.337245: Pseudo dice [0.9645, 0.9523, 0.9504, 0.7838] 
2023-10-08 11:25:12.340770: Epoch time: 116.2 s 
2023-10-08 11:25:12.344121: Yayy! New best EMA pseudo Dice: 0.8882 
2023-10-08 11:25:14.609650:  
2023-10-08 11:25:14.613802: Epoch 89 
2023-10-08 11:25:14.617862: Current learning rate: 0.0092 
2023-10-08 11:27:12.459813: train_loss -0.7177 
2023-10-08 11:27:12.467254: val_loss -0.7621 
2023-10-08 11:27:12.470647: Pseudo dice [0.9576, 0.949, 0.9428, 0.7948] 
2023-10-08 11:27:12.474597: Epoch time: 117.85 s 
2023-10-08 11:27:12.478131: Yayy! New best EMA pseudo Dice: 0.8905 
2023-10-08 11:27:14.517583:  
2023-10-08 11:27:14.524196: Epoch 90 
2023-10-08 11:27:14.529016: Current learning rate: 0.00919 
2023-10-08 11:29:14.055036: train_loss -0.7078 
2023-10-08 11:29:14.062459: val_loss -0.7362 
2023-10-08 11:29:14.067638: Pseudo dice [0.9436, 0.9416, 0.9381, 0.7734] 
2023-10-08 11:29:14.071320: Epoch time: 119.54 s 
2023-10-08 11:29:14.074892: Yayy! New best EMA pseudo Dice: 0.8914 
2023-10-08 11:29:16.302773:  
2023-10-08 11:29:16.308751: Epoch 91 
2023-10-08 11:29:16.313012: Current learning rate: 0.00918 
2023-10-08 11:31:11.270391: train_loss -0.7006 
2023-10-08 11:31:11.278066: val_loss -0.7276 
2023-10-08 11:31:11.281889: Pseudo dice [0.9566, 0.9521, 0.9232, 0.7625] 
2023-10-08 11:31:11.285200: Epoch time: 114.97 s 
2023-10-08 11:31:11.288677: Yayy! New best EMA pseudo Dice: 0.8921 
2023-10-08 11:31:13.400013:  
2023-10-08 11:31:13.405298: Epoch 92 
2023-10-08 11:31:13.409789: Current learning rate: 0.00917 
2023-10-08 11:33:09.503729: train_loss -0.7035 
2023-10-08 11:33:09.514479: val_loss -0.7109 
2023-10-08 11:33:09.518597: Pseudo dice [0.9506, 0.9469, 0.9226, 0.791] 
2023-10-08 11:33:09.522532: Epoch time: 116.11 s 
2023-10-08 11:33:09.526922: Yayy! New best EMA pseudo Dice: 0.8932 
2023-10-08 11:33:11.624641:  
2023-10-08 11:33:11.631559: Epoch 93 
2023-10-08 11:33:11.635507: Current learning rate: 0.00916 
2023-10-08 11:35:09.750381: train_loss -0.7059 
2023-10-08 11:35:09.758073: val_loss -0.7364 
2023-10-08 11:35:09.761835: Pseudo dice [0.9521, 0.9423, 0.9275, 0.7506] 
2023-10-08 11:35:09.765753: Epoch time: 118.13 s 
2023-10-08 11:35:11.135228:  
2023-10-08 11:35:11.139535: Epoch 94 
2023-10-08 11:35:11.145555: Current learning rate: 0.00915 
2023-10-08 11:37:08.406979: train_loss -0.7188 
2023-10-08 11:37:08.418551: val_loss -0.7082 
2023-10-08 11:37:08.422323: Pseudo dice [0.9547, 0.9331, 0.9307, 0.7155] 
2023-10-08 11:37:08.425741: Epoch time: 117.28 s 
2023-10-08 11:37:09.773966:  
2023-10-08 11:37:09.778177: Epoch 95 
2023-10-08 11:37:09.781943: Current learning rate: 0.00914 
2023-10-08 11:39:09.369156: train_loss -0.7306 
2023-10-08 11:39:09.377650: val_loss -0.7196 
2023-10-08 11:39:09.381956: Pseudo dice [0.9456, 0.9043, 0.9361, 0.7609] 
2023-10-08 11:39:09.385626: Epoch time: 119.6 s 
2023-10-08 11:39:10.751230:  
2023-10-08 11:39:10.755560: Epoch 96 
2023-10-08 11:39:10.759471: Current learning rate: 0.00913 
2023-10-08 11:41:11.565800: train_loss -0.7226 
2023-10-08 11:41:11.573643: val_loss -0.7631 
2023-10-08 11:41:11.577764: Pseudo dice [0.9558, 0.9536, 0.9328, 0.7601] 
2023-10-08 11:41:11.581943: Epoch time: 120.82 s 
2023-10-08 11:41:13.130968:  
2023-10-08 11:41:13.135441: Epoch 97 
2023-10-08 11:41:13.139423: Current learning rate: 0.00912 
2023-10-08 11:43:08.887086: train_loss -0.706 
2023-10-08 11:43:08.895400: val_loss -0.7272 
2023-10-08 11:43:08.899697: Pseudo dice [0.963, 0.951, 0.8917, 0.7798] 
2023-10-08 11:43:08.903697: Epoch time: 115.76 s 
2023-10-08 11:43:10.291388:  
2023-10-08 11:43:10.295867: Epoch 98 
2023-10-08 11:43:10.300313: Current learning rate: 0.00911 
2023-10-08 11:45:07.488760: train_loss -0.715 
2023-10-08 11:45:07.497074: val_loss -0.7391 
2023-10-08 11:45:07.500715: Pseudo dice [0.9559, 0.924, 0.9246, 0.7928] 
2023-10-08 11:45:07.504494: Epoch time: 117.2 s 
2023-10-08 11:45:07.508270: Yayy! New best EMA pseudo Dice: 0.8936 
2023-10-08 11:45:09.569465:  
2023-10-08 11:45:09.575343: Epoch 99 
2023-10-08 11:45:09.580337: Current learning rate: 0.0091 
2023-10-08 11:47:06.618806: train_loss -0.7003 
2023-10-08 11:47:06.625879: val_loss -0.7423 
2023-10-08 11:47:06.629455: Pseudo dice [0.9551, 0.9516, 0.9518, 0.7606] 
2023-10-08 11:47:06.633100: Epoch time: 117.05 s 
2023-10-08 11:47:07.400176: Yayy! New best EMA pseudo Dice: 0.8947 
2023-10-08 11:47:09.415954:  
2023-10-08 11:47:09.421172: Epoch 100 
2023-10-08 11:47:09.425581: Current learning rate: 0.0091 
2023-10-08 11:49:08.710121: train_loss -0.7077 
2023-10-08 11:49:08.717021: val_loss -0.7405 
2023-10-08 11:49:08.720427: Pseudo dice [0.9603, 0.9257, 0.9394, 0.8018] 
2023-10-08 11:49:08.723781: Epoch time: 119.3 s 
2023-10-08 11:49:08.727122: Yayy! New best EMA pseudo Dice: 0.8959 
2023-10-08 11:49:10.816828:  
2023-10-08 11:49:10.820827: Epoch 101 
2023-10-08 11:49:10.824618: Current learning rate: 0.00909 
2023-10-08 11:51:13.457989: train_loss -0.7222 
2023-10-08 11:51:13.465284: val_loss -0.743 
2023-10-08 11:51:13.468824: Pseudo dice [0.973, 0.9454, 0.9633, 0.7842] 
2023-10-08 11:51:13.472418: Epoch time: 122.64 s 
2023-10-08 11:51:13.475921: Yayy! New best EMA pseudo Dice: 0.898 
2023-10-08 11:51:15.757225:  
2023-10-08 11:51:15.761265: Epoch 102 
2023-10-08 11:51:15.764776: Current learning rate: 0.00908 
2023-10-08 11:53:13.577935: train_loss -0.7181 
2023-10-08 11:53:13.585449: val_loss -0.7339 
2023-10-08 11:53:13.589314: Pseudo dice [0.9653, 0.9267, 0.9324, 0.7717] 
2023-10-08 11:53:13.593289: Epoch time: 117.82 s 
2023-10-08 11:53:13.597170: Yayy! New best EMA pseudo Dice: 0.8981 
2023-10-08 11:53:15.692764:  
2023-10-08 11:53:15.697079: Epoch 103 
2023-10-08 11:53:15.700974: Current learning rate: 0.00907 
2023-10-08 11:55:13.726852: train_loss -0.7362 
2023-10-08 11:55:13.733604: val_loss -0.7473 
2023-10-08 11:55:13.736946: Pseudo dice [0.9538, 0.9379, 0.9475, 0.7529] 
2023-10-08 11:55:13.740112: Epoch time: 118.04 s 
2023-10-08 11:55:15.121050:  
2023-10-08 11:55:15.125353: Epoch 104 
2023-10-08 11:55:15.129206: Current learning rate: 0.00906 
2023-10-08 11:57:14.376293: train_loss -0.714 
2023-10-08 11:57:14.383088: val_loss -0.7342 
2023-10-08 11:57:14.386482: Pseudo dice [0.9629, 0.947, 0.9622, 0.7769] 
2023-10-08 11:57:14.390239: Epoch time: 119.26 s 
2023-10-08 11:57:14.394287: Yayy! New best EMA pseudo Dice: 0.8995 
2023-10-08 11:57:16.491653:  
2023-10-08 11:57:16.495613: Epoch 105 
2023-10-08 11:57:16.499521: Current learning rate: 0.00905 
2023-10-08 11:59:11.935607: train_loss -0.716 
2023-10-08 11:59:11.942142: val_loss -0.7631 
2023-10-08 11:59:11.945066: Pseudo dice [0.9641, 0.9421, 0.947, 0.8178] 
2023-10-08 11:59:11.948190: Epoch time: 115.45 s 
2023-10-08 11:59:11.951017: Yayy! New best EMA pseudo Dice: 0.9013 
2023-10-08 11:59:13.988250:  
2023-10-08 11:59:13.992418: Epoch 106 
2023-10-08 11:59:13.997303: Current learning rate: 0.00904 
2023-10-08 12:01:13.492843: train_loss -0.7254 
2023-10-08 12:01:13.499388: val_loss -0.7711 
2023-10-08 12:01:13.502838: Pseudo dice [0.9663, 0.9488, 0.9659, 0.8114] 
2023-10-08 12:01:13.506328: Epoch time: 119.51 s 
2023-10-08 12:01:13.509177: Yayy! New best EMA pseudo Dice: 0.9035 
2023-10-08 12:01:15.766144:  
2023-10-08 12:01:15.770883: Epoch 107 
2023-10-08 12:01:15.774909: Current learning rate: 0.00903 
2023-10-08 12:03:14.300832: train_loss -0.7312 
2023-10-08 12:03:14.314558: val_loss -0.7262 
2023-10-08 12:03:14.318505: Pseudo dice [0.9679, 0.9335, 0.9551, 0.7423] 
2023-10-08 12:03:14.322225: Epoch time: 118.54 s 
2023-10-08 12:03:15.674204:  
2023-10-08 12:03:15.678777: Epoch 108 
2023-10-08 12:03:15.682961: Current learning rate: 0.00902 
2023-10-08 12:05:15.168462: train_loss -0.7194 
2023-10-08 12:05:15.177218: val_loss -0.7541 
2023-10-08 12:05:15.181032: Pseudo dice [0.9637, 0.945, 0.9583, 0.7557] 
2023-10-08 12:05:15.184163: Epoch time: 119.5 s 
2023-10-08 12:05:16.577948:  
2023-10-08 12:05:16.581659: Epoch 109 
2023-10-08 12:05:16.585663: Current learning rate: 0.00901 
2023-10-08 12:07:13.017744: train_loss -0.7265 
2023-10-08 12:07:13.032107: val_loss -0.7061 
2023-10-08 12:07:13.035098: Pseudo dice [0.939, 0.9547, 0.9197, 0.7193] 
2023-10-08 12:07:13.037650: Epoch time: 116.44 s 
2023-10-08 12:07:14.450522:  
2023-10-08 12:07:14.453811: Epoch 110 
2023-10-08 12:07:14.456903: Current learning rate: 0.009 
2023-10-08 12:09:13.806854: train_loss -0.7419 
2023-10-08 12:09:13.813918: val_loss -0.7356 
2023-10-08 12:09:13.817455: Pseudo dice [0.9533, 0.9281, 0.9361, 0.7657] 
2023-10-08 12:09:13.820734: Epoch time: 119.36 s 
2023-10-08 12:09:15.191268:  
2023-10-08 12:09:15.196558: Epoch 111 
2023-10-08 12:09:15.201226: Current learning rate: 0.009 
2023-10-08 12:11:12.385933: train_loss -0.7503 
2023-10-08 12:11:12.394032: val_loss -0.7646 
2023-10-08 12:11:12.398280: Pseudo dice [0.9582, 0.9553, 0.9486, 0.7891] 
2023-10-08 12:11:12.402396: Epoch time: 117.2 s 
2023-10-08 12:11:13.794745:  
2023-10-08 12:11:13.799308: Epoch 112 
2023-10-08 12:11:13.803418: Current learning rate: 0.00899 
2023-10-08 12:13:15.182644: train_loss -0.7703 
2023-10-08 12:13:15.192006: val_loss -0.7411 
2023-10-08 12:13:15.195976: Pseudo dice [0.9623, 0.9384, 0.9375, 0.778] 
2023-10-08 12:13:15.199597: Epoch time: 121.39 s 
2023-10-08 12:13:16.760521:  
2023-10-08 12:13:16.764756: Epoch 113 
2023-10-08 12:13:16.768949: Current learning rate: 0.00898 
2023-10-08 12:15:14.662233: train_loss -0.7232 
2023-10-08 12:15:14.670229: val_loss -0.7615 
2023-10-08 12:15:14.673918: Pseudo dice [0.9727, 0.9536, 0.9666, 0.7959] 
2023-10-08 12:15:14.677724: Epoch time: 117.91 s 
2023-10-08 12:15:14.681394: Yayy! New best EMA pseudo Dice: 0.9042 
2023-10-08 12:15:16.727695:  
2023-10-08 12:15:16.732076: Epoch 114 
2023-10-08 12:15:16.736060: Current learning rate: 0.00897 
2023-10-08 12:17:14.296843: train_loss -0.754 
2023-10-08 12:17:14.303990: val_loss -0.7797 
2023-10-08 12:17:14.307518: Pseudo dice [0.9676, 0.9458, 0.9707, 0.785] 
2023-10-08 12:17:14.310913: Epoch time: 117.57 s 
2023-10-08 12:17:14.314677: Yayy! New best EMA pseudo Dice: 0.9055 
2023-10-08 12:17:16.401830:  
2023-10-08 12:17:16.406229: Epoch 115 
2023-10-08 12:17:16.410323: Current learning rate: 0.00896 
2023-10-08 12:19:08.873872: train_loss -0.7522 
2023-10-08 12:19:08.881278: val_loss -0.7513 
2023-10-08 12:19:08.884651: Pseudo dice [0.9598, 0.9575, 0.9283, 0.7929] 
2023-10-08 12:19:08.887822: Epoch time: 112.48 s 
2023-10-08 12:19:08.891031: Yayy! New best EMA pseudo Dice: 0.9059 
2023-10-08 12:19:10.983206:  
2023-10-08 12:19:10.987374: Epoch 116 
2023-10-08 12:19:10.991107: Current learning rate: 0.00895 
2023-10-08 12:21:13.408692: train_loss -0.7067 
2023-10-08 12:21:13.416527: val_loss -0.7144 
2023-10-08 12:21:13.420487: Pseudo dice [0.9538, 0.9529, 0.8839, 0.7175] 
2023-10-08 12:21:13.424393: Epoch time: 122.43 s 
2023-10-08 12:21:14.812300:  
2023-10-08 12:21:14.816589: Epoch 117 
2023-10-08 12:21:14.824054: Current learning rate: 0.00894 
2023-10-08 12:23:15.997677: train_loss -0.7364 
2023-10-08 12:23:16.004189: val_loss -0.7374 
2023-10-08 12:23:16.007681: Pseudo dice [0.961, 0.9494, 0.9352, 0.691] 
2023-10-08 12:23:16.010764: Epoch time: 121.19 s 
2023-10-08 12:23:17.616507:  
2023-10-08 12:23:17.620694: Epoch 118 
2023-10-08 12:23:17.624810: Current learning rate: 0.00893 
2023-10-08 12:25:19.580415: train_loss -0.7419 
2023-10-08 12:25:19.587042: val_loss -0.7994 
2023-10-08 12:25:19.590364: Pseudo dice [0.9652, 0.9581, 0.9548, 0.7818] 
2023-10-08 12:25:19.593667: Epoch time: 121.97 s 
2023-10-08 12:25:20.994490:  
2023-10-08 12:25:20.997871: Epoch 119 
2023-10-08 12:25:21.001495: Current learning rate: 0.00892 
2023-10-08 12:27:16.639132: train_loss -0.7387 
2023-10-08 12:27:16.646487: val_loss -0.7262 
2023-10-08 12:27:16.651446: Pseudo dice [0.9547, 0.9156, 0.9433, 0.8] 
2023-10-08 12:27:16.655403: Epoch time: 115.65 s 
2023-10-08 12:27:18.059203:  
2023-10-08 12:27:18.063418: Epoch 120 
2023-10-08 12:27:18.066971: Current learning rate: 0.00891 
2023-10-08 12:29:16.128417: train_loss -0.7324 
2023-10-08 12:29:16.138536: val_loss -0.7166 
2023-10-08 12:29:16.142774: Pseudo dice [0.9548, 0.9117, 0.9358, 0.7767] 
2023-10-08 12:29:16.147241: Epoch time: 118.07 s 
2023-10-08 12:29:17.630863:  
2023-10-08 12:29:17.635586: Epoch 121 
2023-10-08 12:29:17.639394: Current learning rate: 0.0089 
2023-10-08 12:31:14.744574: train_loss -0.7554 
2023-10-08 12:31:14.752211: val_loss -0.7477 
2023-10-08 12:31:14.756303: Pseudo dice [0.9632, 0.9392, 0.9446, 0.7841] 
2023-10-08 12:31:14.759963: Epoch time: 117.12 s 
2023-10-08 12:31:16.161527:  
2023-10-08 12:31:16.165720: Epoch 122 
2023-10-08 12:31:16.170075: Current learning rate: 0.00889 
2023-10-08 12:33:14.866212: train_loss -0.7343 
2023-10-08 12:33:14.874090: val_loss -0.7165 
2023-10-08 12:33:14.877404: Pseudo dice [0.9633, 0.9572, 0.9506, 0.726] 
2023-10-08 12:33:14.881261: Epoch time: 118.71 s 
2023-10-08 12:33:16.510489:  
2023-10-08 12:33:16.515031: Epoch 123 
2023-10-08 12:33:16.519094: Current learning rate: 0.00889 
2023-10-08 12:35:11.233526: train_loss -0.735 
2023-10-08 12:35:11.241186: val_loss -0.7545 
2023-10-08 12:35:11.245483: Pseudo dice [0.9561, 0.9611, 0.9439, 0.728] 
2023-10-08 12:35:11.249684: Epoch time: 114.73 s 
2023-10-08 12:35:12.644454:  
2023-10-08 12:35:12.649055: Epoch 124 
2023-10-08 12:35:12.652903: Current learning rate: 0.00888 
2023-10-08 12:37:16.340970: train_loss -0.7228 
2023-10-08 12:37:16.348115: val_loss -0.7445 
2023-10-08 12:37:16.351582: Pseudo dice [0.9613, 0.9493, 0.9409, 0.7637] 
2023-10-08 12:37:16.356054: Epoch time: 123.7 s 
2023-10-08 12:37:17.722935:  
2023-10-08 12:37:17.727333: Epoch 125 
2023-10-08 12:37:17.731282: Current learning rate: 0.00887 
2023-10-08 12:39:16.732721: train_loss -0.7497 
2023-10-08 12:39:16.740392: val_loss -0.7904 
2023-10-08 12:39:16.744204: Pseudo dice [0.9618, 0.9619, 0.9503, 0.7714] 
2023-10-08 12:39:16.747610: Epoch time: 119.01 s 
2023-10-08 12:39:18.136405:  
2023-10-08 12:39:18.140522: Epoch 126 
2023-10-08 12:39:18.144135: Current learning rate: 0.00886 
2023-10-08 12:41:18.769928: train_loss -0.7601 
2023-10-08 12:41:18.776243: val_loss -0.7564 
2023-10-08 12:41:18.779500: Pseudo dice [0.9615, 0.9396, 0.9451, 0.7676] 
2023-10-08 12:41:18.782843: Epoch time: 120.64 s 
2023-10-08 12:41:20.209842:  
2023-10-08 12:41:20.213870: Epoch 127 
2023-10-08 12:41:20.217719: Current learning rate: 0.00885 
2023-10-08 12:43:19.874978: train_loss -0.7462 
2023-10-08 12:43:19.882315: val_loss -0.7681 
2023-10-08 12:43:19.886209: Pseudo dice [0.9692, 0.9485, 0.9618, 0.7971] 
2023-10-08 12:43:19.889691: Epoch time: 119.67 s 
2023-10-08 12:43:21.483956:  
2023-10-08 12:43:21.487740: Epoch 128 
2023-10-08 12:43:21.491085: Current learning rate: 0.00884 
2023-10-08 12:45:20.253084: train_loss -0.7412 
2023-10-08 12:45:20.260020: val_loss -0.7991 
2023-10-08 12:45:20.263163: Pseudo dice [0.9661, 0.949, 0.9579, 0.7638] 
2023-10-08 12:45:20.266388: Epoch time: 118.77 s 
2023-10-08 12:45:21.688690:  
2023-10-08 12:45:21.693375: Epoch 129 
2023-10-08 12:45:21.697128: Current learning rate: 0.00883 
2023-10-08 12:47:21.737709: train_loss -0.7095 
2023-10-08 12:47:21.744475: val_loss -0.7101 
2023-10-08 12:47:21.748034: Pseudo dice [0.9504, 0.9412, 0.9287, 0.7525] 
2023-10-08 12:47:21.751391: Epoch time: 120.05 s 
2023-10-08 12:47:23.133440:  
2023-10-08 12:47:23.138227: Epoch 130 
2023-10-08 12:47:23.142054: Current learning rate: 0.00882 
2023-10-08 12:49:24.759269: train_loss -0.7248 
2023-10-08 12:49:24.767412: val_loss -0.7573 
2023-10-08 12:49:24.771557: Pseudo dice [0.9622, 0.9605, 0.9539, 0.7217] 
2023-10-08 12:49:24.775372: Epoch time: 121.63 s 
2023-10-08 12:49:26.170214:  
2023-10-08 12:49:26.176285: Epoch 131 
2023-10-08 12:49:26.181377: Current learning rate: 0.00881 
2023-10-08 12:51:29.831909: train_loss -0.7247 
2023-10-08 12:51:29.842507: val_loss -0.7358 
2023-10-08 12:51:29.849181: Pseudo dice [0.9522, 0.951, 0.924, 0.785] 
2023-10-08 12:51:29.853155: Epoch time: 123.66 s 
2023-10-08 12:51:31.288851:  
2023-10-08 12:51:31.292881: Epoch 132 
2023-10-08 12:51:31.296813: Current learning rate: 0.0088 
2023-10-08 12:53:35.124297: train_loss -0.7203 
2023-10-08 12:53:35.132097: val_loss -0.7355 
2023-10-08 12:53:35.135845: Pseudo dice [0.9558, 0.9527, 0.9479, 0.7494] 
2023-10-08 12:53:35.139651: Epoch time: 123.84 s 
2023-10-08 12:53:36.569240:  
2023-10-08 12:53:36.573454: Epoch 133 
2023-10-08 12:53:36.577727: Current learning rate: 0.00879 
2023-10-08 12:55:38.163897: train_loss -0.7212 
2023-10-08 12:55:38.172661: val_loss -0.7315 
2023-10-08 12:55:38.176558: Pseudo dice [0.958, 0.9503, 0.9437, 0.71] 
2023-10-08 12:55:38.180448: Epoch time: 121.6 s 
2023-10-08 12:55:39.891387:  
2023-10-08 12:55:39.895521: Epoch 134 
2023-10-08 12:55:39.899464: Current learning rate: 0.00879 
2023-10-08 12:57:33.614791: train_loss -0.7168 
2023-10-08 12:57:33.622136: val_loss -0.736 
2023-10-08 12:57:33.626143: Pseudo dice [0.9624, 0.9564, 0.9532, 0.7767] 
2023-10-08 12:57:33.630242: Epoch time: 113.73 s 
2023-10-08 12:57:35.077911:  
2023-10-08 12:57:35.082026: Epoch 135 
2023-10-08 12:57:35.085998: Current learning rate: 0.00878 
2023-10-08 12:59:31.536836: train_loss -0.7385 
2023-10-08 12:59:31.544796: val_loss -0.7261 
2023-10-08 12:59:31.548181: Pseudo dice [0.9511, 0.9508, 0.9135, 0.7994] 
2023-10-08 12:59:31.551793: Epoch time: 116.46 s 
2023-10-08 12:59:32.964514:  
2023-10-08 12:59:32.968658: Epoch 136 
2023-10-08 12:59:32.972378: Current learning rate: 0.00877 
2023-10-08 13:01:30.168352: train_loss -0.734 
2023-10-08 13:01:30.176366: val_loss -0.7758 
2023-10-08 13:01:30.180418: Pseudo dice [0.9674, 0.929, 0.9432, 0.8019] 
2023-10-08 13:01:30.184453: Epoch time: 117.21 s 
2023-10-08 13:01:31.621349:  
2023-10-08 13:01:31.625946: Epoch 137 
2023-10-08 13:01:31.629948: Current learning rate: 0.00876 
2023-10-08 13:03:31.773322: train_loss -0.7316 
2023-10-08 13:03:31.781288: val_loss -0.7725 
2023-10-08 13:03:31.785219: Pseudo dice [0.9548, 0.9574, 0.9227, 0.7903] 
2023-10-08 13:03:31.789020: Epoch time: 120.15 s 
2023-10-08 13:03:33.222150:  
2023-10-08 13:03:33.226366: Epoch 138 
2023-10-08 13:03:33.230323: Current learning rate: 0.00875 
2023-10-08 13:05:30.941957: train_loss -0.7465 
2023-10-08 13:05:30.950480: val_loss -0.74 
2023-10-08 13:05:30.954667: Pseudo dice [0.9559, 0.9424, 0.9404, 0.7751] 
2023-10-08 13:05:30.958194: Epoch time: 117.72 s 
2023-10-08 13:05:32.595712:  
2023-10-08 13:05:32.600060: Epoch 139 
2023-10-08 13:05:32.603824: Current learning rate: 0.00874 
2023-10-08 13:07:27.164848: train_loss -0.7439 
2023-10-08 13:07:27.172800: val_loss -0.7722 
2023-10-08 13:07:27.176729: Pseudo dice [0.9707, 0.9556, 0.9551, 0.8066] 
2023-10-08 13:07:27.180426: Epoch time: 114.57 s 
2023-10-08 13:07:28.610188:  
2023-10-08 13:07:28.616222: Epoch 140 
2023-10-08 13:07:28.620970: Current learning rate: 0.00873 
2023-10-08 13:09:24.656359: train_loss -0.7456 
2023-10-08 13:09:24.663399: val_loss -0.717 
2023-10-08 13:09:24.667045: Pseudo dice [0.9617, 0.9567, 0.9223, 0.6577] 
2023-10-08 13:09:24.671559: Epoch time: 116.05 s 
2023-10-08 13:09:26.246496:  
2023-10-08 13:09:26.252429: Epoch 141 
2023-10-08 13:09:26.260996: Current learning rate: 0.00872 
2023-10-08 13:11:29.736276: train_loss -0.7476 
2023-10-08 13:11:29.743452: val_loss -0.7346 
2023-10-08 13:11:29.746921: Pseudo dice [0.9355, 0.9382, 0.9094, 0.7918] 
2023-10-08 13:11:29.750198: Epoch time: 123.49 s 
2023-10-08 13:11:31.228940:  
2023-10-08 13:11:31.232978: Epoch 142 
2023-10-08 13:11:31.236994: Current learning rate: 0.00871 
2023-10-08 13:13:29.897635: train_loss -0.7415 
2023-10-08 13:13:29.904725: val_loss -0.786 
2023-10-08 13:13:29.912935: Pseudo dice [0.97, 0.9601, 0.9557, 0.8097] 
2023-10-08 13:13:29.916974: Epoch time: 118.67 s 
2023-10-08 13:13:31.435712:  
2023-10-08 13:13:31.439513: Epoch 143 
2023-10-08 13:13:31.443451: Current learning rate: 0.0087 
2023-10-08 13:15:28.688750: train_loss -0.7211 
2023-10-08 13:15:28.700655: val_loss -0.7457 
2023-10-08 13:15:28.708784: Pseudo dice [0.9559, 0.9462, 0.9302, 0.782] 
2023-10-08 13:15:28.712550: Epoch time: 117.26 s 
2023-10-08 13:15:30.441149:  
2023-10-08 13:15:30.456430: Epoch 144 
2023-10-08 13:15:30.464551: Current learning rate: 0.00869 
2023-10-08 13:17:30.698769: train_loss -0.7161 
2023-10-08 13:17:30.706490: val_loss -0.716 
2023-10-08 13:17:30.709991: Pseudo dice [0.9392, 0.9486, 0.9131, 0.7435] 
2023-10-08 13:17:30.713618: Epoch time: 120.26 s 
2023-10-08 13:17:32.262915:  
2023-10-08 13:17:32.274057: Epoch 145 
2023-10-08 13:17:32.278155: Current learning rate: 0.00868 
2023-10-08 13:19:28.803034: train_loss -0.7463 
2023-10-08 13:19:28.812021: val_loss -0.7339 
2023-10-08 13:19:28.815772: Pseudo dice [0.953, 0.9402, 0.921, 0.7761] 
2023-10-08 13:19:28.819728: Epoch time: 116.54 s 
2023-10-08 13:19:30.333920:  
2023-10-08 13:19:30.338804: Epoch 146 
2023-10-08 13:19:30.342853: Current learning rate: 0.00868 
2023-10-08 13:21:29.432987: train_loss -0.7448 
2023-10-08 13:21:29.440747: val_loss -0.7877 
2023-10-08 13:21:29.445033: Pseudo dice [0.9689, 0.9585, 0.9553, 0.7451] 
2023-10-08 13:21:29.449163: Epoch time: 119.1 s 
2023-10-08 13:21:30.883129:  
2023-10-08 13:21:30.888610: Epoch 147 
2023-10-08 13:21:30.892880: Current learning rate: 0.00867 
2023-10-08 13:23:27.901315: train_loss -0.7235 
2023-10-08 13:23:27.908886: val_loss -0.755 
2023-10-08 13:23:27.912804: Pseudo dice [0.9585, 0.9527, 0.9432, 0.7861] 
2023-10-08 13:23:27.916978: Epoch time: 117.02 s 
2023-10-08 13:23:29.369234:  
2023-10-08 13:23:29.374289: Epoch 148 
2023-10-08 13:23:29.379183: Current learning rate: 0.00866 
2023-10-08 13:25:28.524313: train_loss -0.7163 
2023-10-08 13:25:28.532393: val_loss -0.7373 
2023-10-08 13:25:28.536660: Pseudo dice [0.9551, 0.9273, 0.9652, 0.7452] 
2023-10-08 13:25:28.540854: Epoch time: 119.16 s 
2023-10-08 13:25:30.137116:  
2023-10-08 13:25:30.141556: Epoch 149 
2023-10-08 13:25:30.145730: Current learning rate: 0.00865 
2023-10-08 13:27:30.636424: train_loss -0.7451 
2023-10-08 13:27:30.644025: val_loss -0.7641 
2023-10-08 13:27:30.647892: Pseudo dice [0.9596, 0.9523, 0.9102, 0.7853] 
2023-10-08 13:27:30.652184: Epoch time: 120.5 s 
2023-10-08 13:27:32.801778:  
2023-10-08 13:27:32.805912: Epoch 150 
2023-10-08 13:27:32.809865: Current learning rate: 0.00864 
2023-10-08 13:29:28.676196: train_loss -0.7405 
2023-10-08 13:29:28.685056: val_loss -0.7521 
2023-10-08 13:29:28.689031: Pseudo dice [0.9558, 0.9545, 0.9083, 0.8126] 
2023-10-08 13:29:28.692643: Epoch time: 115.88 s 
2023-10-08 13:29:30.114159:  
2023-10-08 13:29:30.118811: Epoch 151 
2023-10-08 13:29:30.123401: Current learning rate: 0.00863 
2023-10-08 13:31:30.789901: train_loss -0.7275 
2023-10-08 13:31:30.799050: val_loss -0.7485 
2023-10-08 13:31:30.802662: Pseudo dice [0.9553, 0.9414, 0.9362, 0.7941] 
2023-10-08 13:31:30.806586: Epoch time: 120.68 s 
2023-10-08 13:31:32.266804:  
2023-10-08 13:31:32.272586: Epoch 152 
2023-10-08 13:31:32.277235: Current learning rate: 0.00862 
2023-10-08 13:33:31.051958: train_loss -0.7106 
2023-10-08 13:33:31.059927: val_loss -0.7419 
2023-10-08 13:33:31.063936: Pseudo dice [0.9681, 0.9285, 0.9511, 0.8144] 
2023-10-08 13:33:31.067714: Epoch time: 118.79 s 
2023-10-08 13:33:32.484851:  
2023-10-08 13:33:32.490560: Epoch 153 
2023-10-08 13:33:32.495231: Current learning rate: 0.00861 
2023-10-08 13:35:28.207231: train_loss -0.7475 
2023-10-08 13:35:28.214522: val_loss -0.7818 
2023-10-08 13:35:28.217985: Pseudo dice [0.9663, 0.9574, 0.9491, 0.7866] 
2023-10-08 13:35:28.221416: Epoch time: 115.73 s 
2023-10-08 13:35:29.891201:  
2023-10-08 13:35:29.895720: Epoch 154 
2023-10-08 13:35:29.900157: Current learning rate: 0.0086 
2023-10-08 13:37:28.065848: train_loss -0.7607 
2023-10-08 13:37:28.074011: val_loss -0.7212 
2023-10-08 13:37:28.078209: Pseudo dice [0.9661, 0.9373, 0.944, 0.7845] 
2023-10-08 13:37:28.081977: Epoch time: 118.18 s 
2023-10-08 13:37:29.544616:  
2023-10-08 13:37:29.549592: Epoch 155 
2023-10-08 13:37:29.554311: Current learning rate: 0.00859 
2023-10-08 13:39:24.727742: train_loss -0.7678 
2023-10-08 13:39:24.737063: val_loss -0.7496 
2023-10-08 13:39:24.741000: Pseudo dice [0.9564, 0.9316, 0.9545, 0.8126] 
2023-10-08 13:39:24.745783: Epoch time: 115.19 s 
2023-10-08 13:39:24.749897: Yayy! New best EMA pseudo Dice: 0.9066 
2023-10-08 13:39:26.929403:  
2023-10-08 13:39:26.934093: Epoch 156 
2023-10-08 13:39:26.938233: Current learning rate: 0.00858 
2023-10-08 13:41:30.393623: train_loss -0.7388 
2023-10-08 13:41:30.401493: val_loss -0.7442 
2023-10-08 13:41:30.405758: Pseudo dice [0.9633, 0.9472, 0.9332, 0.7585] 
2023-10-08 13:41:30.409729: Epoch time: 123.47 s 
2023-10-08 13:41:31.981712:  
2023-10-08 13:41:31.986532: Epoch 157 
2023-10-08 13:41:31.991773: Current learning rate: 0.00858 
2023-10-08 13:43:27.127129: train_loss -0.7533 
2023-10-08 13:43:27.134999: val_loss -0.786 
2023-10-08 13:43:27.139124: Pseudo dice [0.96, 0.9516, 0.9578, 0.815] 
2023-10-08 13:43:27.142923: Epoch time: 115.15 s 
2023-10-08 13:43:27.146636: Yayy! New best EMA pseudo Dice: 0.9075 
2023-10-08 13:43:29.313414:  
2023-10-08 13:43:29.317808: Epoch 158 
2023-10-08 13:43:29.322279: Current learning rate: 0.00857 
2023-10-08 13:45:25.100975: train_loss -0.7434 
2023-10-08 13:45:25.108772: val_loss -0.764 
2023-10-08 13:45:25.112349: Pseudo dice [0.9721, 0.9474, 0.9659, 0.7582] 
2023-10-08 13:45:25.116204: Epoch time: 115.79 s 
2023-10-08 13:45:25.122326: Yayy! New best EMA pseudo Dice: 0.9079 
2023-10-08 13:45:27.445180:  
2023-10-08 13:45:27.449658: Epoch 159 
2023-10-08 13:45:27.453548: Current learning rate: 0.00856 
2023-10-08 13:47:19.676314: train_loss -0.75 
2023-10-08 13:47:19.684598: val_loss -0.7692 
2023-10-08 13:47:19.688437: Pseudo dice [0.9691, 0.9618, 0.948, 0.7834] 
2023-10-08 13:47:19.692489: Epoch time: 112.23 s 
2023-10-08 13:47:19.696324: Yayy! New best EMA pseudo Dice: 0.9086 
2023-10-08 13:47:21.870733:  
2023-10-08 13:47:21.875533: Epoch 160 
2023-10-08 13:47:21.879295: Current learning rate: 0.00855 
2023-10-08 13:49:17.194497: train_loss -0.7585 
2023-10-08 13:49:17.202008: val_loss -0.7841 
2023-10-08 13:49:17.205733: Pseudo dice [0.9703, 0.9544, 0.9575, 0.8002] 
2023-10-08 13:49:17.209651: Epoch time: 115.33 s 
2023-10-08 13:49:17.213364: Yayy! New best EMA pseudo Dice: 0.9098 
2023-10-08 13:49:19.389570:  
2023-10-08 13:49:19.394274: Epoch 161 
2023-10-08 13:49:19.398294: Current learning rate: 0.00854 
2023-10-08 13:51:17.904361: train_loss -0.7307 
2023-10-08 13:51:17.912392: val_loss -0.7362 
2023-10-08 13:51:17.916443: Pseudo dice [0.945, 0.9576, 0.9351, 0.7569] 
2023-10-08 13:51:17.922936: Epoch time: 118.52 s 
2023-10-08 13:51:19.427716:  
2023-10-08 13:51:19.432543: Epoch 162 
2023-10-08 13:51:19.436806: Current learning rate: 0.00853 
2023-10-08 13:53:16.037544: train_loss -0.7432 
2023-10-08 13:53:16.045499: val_loss -0.7463 
2023-10-08 13:53:16.049256: Pseudo dice [0.9664, 0.9444, 0.9401, 0.7707] 
2023-10-08 13:53:16.052925: Epoch time: 116.61 s 
2023-10-08 13:53:17.567576:  
2023-10-08 13:53:17.571176: Epoch 163 
2023-10-08 13:53:17.574349: Current learning rate: 0.00852 
2023-10-08 13:55:15.641963: train_loss -0.7646 
2023-10-08 13:55:15.649957: val_loss -0.736 
2023-10-08 13:55:15.654048: Pseudo dice [0.9486, 0.9466, 0.9227, 0.8027] 
2023-10-08 13:55:15.658058: Epoch time: 118.08 s 
2023-10-08 13:55:17.329675:  
2023-10-08 13:55:17.335041: Epoch 164 
2023-10-08 13:55:17.339619: Current learning rate: 0.00851 
2023-10-08 13:57:14.115555: train_loss -0.744 
2023-10-08 13:57:14.123125: val_loss -0.7276 
2023-10-08 13:57:14.126572: Pseudo dice [0.955, 0.8929, 0.9339, 0.773] 
2023-10-08 13:57:14.129956: Epoch time: 116.79 s 
2023-10-08 13:57:15.526249:  
2023-10-08 13:57:15.533569: Epoch 165 
2023-10-08 13:57:15.537867: Current learning rate: 0.0085 
2023-10-08 13:59:10.788612: train_loss -0.7681 
2023-10-08 13:59:10.796536: val_loss -0.752 
2023-10-08 13:59:10.800741: Pseudo dice [0.9558, 0.9424, 0.9389, 0.7989] 
2023-10-08 13:59:10.804499: Epoch time: 115.27 s 
2023-10-08 13:59:12.202234:  
2023-10-08 13:59:12.207667: Epoch 166 
2023-10-08 13:59:12.212061: Current learning rate: 0.00849 
2023-10-08 14:01:10.510840: train_loss -0.7378 
2023-10-08 14:01:10.519316: val_loss -0.7827 
2023-10-08 14:01:10.523087: Pseudo dice [0.9717, 0.942, 0.9638, 0.8103] 
2023-10-08 14:01:10.527161: Epoch time: 118.31 s 
2023-10-08 14:01:11.925257:  
2023-10-08 14:01:11.929712: Epoch 167 
2023-10-08 14:01:11.933824: Current learning rate: 0.00848 
2023-10-08 14:03:08.250852: train_loss -0.7565 
2023-10-08 14:03:08.259027: val_loss -0.7998 
2023-10-08 14:03:08.262681: Pseudo dice [0.9654, 0.9567, 0.9444, 0.8286] 
2023-10-08 14:03:08.266482: Epoch time: 116.33 s 
2023-10-08 14:03:09.697482:  
2023-10-08 14:03:09.701968: Epoch 168 
2023-10-08 14:03:09.705939: Current learning rate: 0.00847 
2023-10-08 14:05:05.595212: train_loss -0.7542 
2023-10-08 14:05:05.602753: val_loss -0.7603 
2023-10-08 14:05:05.607150: Pseudo dice [0.948, 0.9581, 0.9164, 0.8351] 
2023-10-08 14:05:05.610905: Epoch time: 115.9 s 
2023-10-08 14:05:05.614510: Yayy! New best EMA pseudo Dice: 0.91 
2023-10-08 14:05:07.894193:  
2023-10-08 14:05:07.899020: Epoch 169 
2023-10-08 14:05:07.902896: Current learning rate: 0.00847 
2023-10-08 14:07:06.219651: train_loss -0.7186 
2023-10-08 14:07:06.228688: val_loss -0.7726 
2023-10-08 14:07:06.233970: Pseudo dice [0.9625, 0.9076, 0.95, 0.8011] 
2023-10-08 14:07:06.237880: Epoch time: 118.33 s 
2023-10-08 14:07:07.693683:  
2023-10-08 14:07:07.697929: Epoch 170 
2023-10-08 14:07:07.701897: Current learning rate: 0.00846 
2023-10-08 14:09:04.279930: train_loss -0.7431 
2023-10-08 14:09:04.287323: val_loss -0.7512 
2023-10-08 14:09:04.291170: Pseudo dice [0.9627, 0.9491, 0.9424, 0.8149] 
2023-10-08 14:09:04.295065: Epoch time: 116.59 s 
2023-10-08 14:09:04.298603: Yayy! New best EMA pseudo Dice: 0.9103 
2023-10-08 14:09:06.415523:  
2023-10-08 14:09:06.419510: Epoch 171 
2023-10-08 14:09:06.423352: Current learning rate: 0.00845 
2023-10-08 14:11:03.329974: train_loss -0.7445 
2023-10-08 14:11:03.337704: val_loss -0.7574 
2023-10-08 14:11:03.341827: Pseudo dice [0.9642, 0.9286, 0.9515, 0.7596] 
2023-10-08 14:11:03.345215: Epoch time: 116.92 s 
2023-10-08 14:11:04.795462:  
2023-10-08 14:11:04.799990: Epoch 172 
2023-10-08 14:11:04.804217: Current learning rate: 0.00844 
2023-10-08 14:13:05.343887: train_loss -0.7413 
2023-10-08 14:13:05.358318: val_loss -0.7931 
2023-10-08 14:13:05.362041: Pseudo dice [0.9715, 0.9541, 0.9686, 0.7887] 
2023-10-08 14:13:05.365907: Epoch time: 120.55 s 
2023-10-08 14:13:05.369859: Yayy! New best EMA pseudo Dice: 0.9105 
2023-10-08 14:13:07.498408:  
2023-10-08 14:13:07.503168: Epoch 173 
2023-10-08 14:13:07.509789: Current learning rate: 0.00843 
2023-10-08 14:15:02.764822: train_loss -0.7663 
2023-10-08 14:15:02.772695: val_loss -0.7439 
2023-10-08 14:15:02.776355: Pseudo dice [0.9649, 0.9552, 0.9314, 0.7874] 
2023-10-08 14:15:02.780130: Epoch time: 115.27 s 
2023-10-08 14:15:04.430024:  
2023-10-08 14:15:04.435346: Epoch 174 
2023-10-08 14:15:04.439155: Current learning rate: 0.00842 
2023-10-08 14:17:00.501835: train_loss -0.7731 
2023-10-08 14:17:00.509984: val_loss -0.7639 
2023-10-08 14:17:00.516819: Pseudo dice [0.9619, 0.9485, 0.9673, 0.7783] 
2023-10-08 14:17:00.520837: Epoch time: 116.07 s 
2023-10-08 14:17:00.525136: Yayy! New best EMA pseudo Dice: 0.9108 
2023-10-08 14:17:02.673429:  
2023-10-08 14:17:02.677734: Epoch 175 
2023-10-08 14:17:02.681885: Current learning rate: 0.00841 
2023-10-08 14:18:54.970689: train_loss -0.7626 
2023-10-08 14:18:54.979451: val_loss -0.7605 
2023-10-08 14:18:54.983433: Pseudo dice [0.966, 0.9587, 0.9529, 0.7819] 
2023-10-08 14:18:54.987176: Epoch time: 112.3 s 
2023-10-08 14:18:54.991184: Yayy! New best EMA pseudo Dice: 0.9112 
2023-10-08 14:18:57.188812:  
2023-10-08 14:18:57.193419: Epoch 176 
2023-10-08 14:18:57.197925: Current learning rate: 0.0084 
2023-10-08 14:20:54.271732: train_loss -0.7486 
2023-10-08 14:20:54.279958: val_loss -0.757 
2023-10-08 14:20:54.283780: Pseudo dice [0.9571, 0.9534, 0.9416, 0.7888] 
2023-10-08 14:20:54.287614: Epoch time: 117.09 s 
2023-10-08 14:20:55.767045:  
2023-10-08 14:20:55.772481: Epoch 177 
2023-10-08 14:20:55.777269: Current learning rate: 0.00839 
2023-10-08 14:22:56.110048: train_loss -0.7221 
2023-10-08 14:22:56.118011: val_loss -0.7519 
2023-10-08 14:22:56.121913: Pseudo dice [0.9659, 0.9427, 0.9484, 0.7843] 
2023-10-08 14:22:56.125758: Epoch time: 120.35 s 
2023-10-08 14:22:57.547062:  
2023-10-08 14:22:57.551132: Epoch 178 
2023-10-08 14:22:57.555047: Current learning rate: 0.00838 
2023-10-08 14:24:55.678349: train_loss -0.7473 
2023-10-08 14:24:55.685825: val_loss -0.7378 
2023-10-08 14:24:55.690210: Pseudo dice [0.9638, 0.9172, 0.9457, 0.7717] 
2023-10-08 14:24:55.694361: Epoch time: 118.13 s 
2023-10-08 14:24:57.321389:  
2023-10-08 14:24:57.326819: Epoch 179 
2023-10-08 14:24:57.332431: Current learning rate: 0.00837 
2023-10-08 14:26:54.011743: train_loss -0.7374 
2023-10-08 14:26:54.018770: val_loss -0.7723 
2023-10-08 14:26:54.024132: Pseudo dice [0.9653, 0.9445, 0.944, 0.7759] 
2023-10-08 14:26:54.027511: Epoch time: 116.69 s 
2023-10-08 14:26:55.441672:  
2023-10-08 14:26:55.446448: Epoch 180 
2023-10-08 14:26:55.450421: Current learning rate: 0.00836 
2023-10-08 14:28:53.225702: train_loss -0.7489 
2023-10-08 14:28:53.233158: val_loss -0.7569 
2023-10-08 14:28:53.237293: Pseudo dice [0.9447, 0.9584, 0.9285, 0.7419] 
2023-10-08 14:28:53.241146: Epoch time: 117.79 s 
2023-10-08 14:28:54.699811:  
2023-10-08 14:28:54.705168: Epoch 181 
2023-10-08 14:28:54.709601: Current learning rate: 0.00836 
2023-10-08 14:30:52.318205: train_loss -0.741 
2023-10-08 14:30:52.335507: val_loss -0.7455 
2023-10-08 14:30:52.339123: Pseudo dice [0.9672, 0.9286, 0.9148, 0.7888] 
2023-10-08 14:30:52.343163: Epoch time: 117.62 s 
2023-10-08 14:30:53.813727:  
2023-10-08 14:30:53.817898: Epoch 182 
2023-10-08 14:30:53.821828: Current learning rate: 0.00835 
2023-10-08 14:32:50.503691: train_loss -0.7438 
2023-10-08 14:32:50.512239: val_loss -0.7281 
2023-10-08 14:32:50.516134: Pseudo dice [0.9652, 0.9239, 0.9272, 0.8117] 
2023-10-08 14:32:50.519986: Epoch time: 116.69 s 
2023-10-08 14:32:51.960171:  
2023-10-08 14:32:51.966876: Epoch 183 
2023-10-08 14:32:51.971285: Current learning rate: 0.00834 
2023-10-08 14:34:44.732270: train_loss -0.749 
2023-10-08 14:34:44.740624: val_loss -0.7653 
2023-10-08 14:34:44.744580: Pseudo dice [0.9653, 0.9594, 0.9443, 0.813] 
2023-10-08 14:34:44.749087: Epoch time: 112.78 s 
2023-10-08 14:34:46.372739:  
2023-10-08 14:34:46.377240: Epoch 184 
2023-10-08 14:34:46.381791: Current learning rate: 0.00833 
2023-10-08 14:36:42.189916: train_loss -0.7543 
2023-10-08 14:36:42.197760: val_loss -0.7084 
2023-10-08 14:36:42.201461: Pseudo dice [0.9622, 0.9407, 0.9469, 0.7293] 
2023-10-08 14:36:42.204784: Epoch time: 115.82 s 
2023-10-08 14:36:43.632472:  
2023-10-08 14:36:43.636611: Epoch 185 
2023-10-08 14:36:43.640229: Current learning rate: 0.00832 
2023-10-08 14:38:39.633423: train_loss -0.7601 
2023-10-08 14:38:39.640416: val_loss -0.7899 
2023-10-08 14:38:39.644515: Pseudo dice [0.9594, 0.954, 0.973, 0.8031] 
2023-10-08 14:38:39.647795: Epoch time: 116.0 s 
2023-10-08 14:38:41.074268:  
2023-10-08 14:38:41.078687: Epoch 186 
2023-10-08 14:38:41.082552: Current learning rate: 0.00831 
2023-10-08 14:40:38.537424: train_loss -0.7587 
2023-10-08 14:40:38.545207: val_loss -0.7944 
2023-10-08 14:40:38.548827: Pseudo dice [0.9674, 0.9556, 0.9702, 0.8124] 
2023-10-08 14:40:38.552703: Epoch time: 117.47 s 
2023-10-08 14:40:40.053392:  
2023-10-08 14:40:40.058350: Epoch 187 
2023-10-08 14:40:40.062368: Current learning rate: 0.0083 
2023-10-08 14:42:36.270459: train_loss -0.7246 
2023-10-08 14:42:36.277725: val_loss -0.7398 
2023-10-08 14:42:36.281716: Pseudo dice [0.9669, 0.9264, 0.9606, 0.779] 
2023-10-08 14:42:36.285658: Epoch time: 116.22 s 
2023-10-08 14:42:37.803761:  
2023-10-08 14:42:37.808692: Epoch 188 
2023-10-08 14:42:37.813197: Current learning rate: 0.00829 
2023-10-08 14:44:34.082814: train_loss -0.7527 
2023-10-08 14:44:34.090151: val_loss -0.735 
2023-10-08 14:44:34.093545: Pseudo dice [0.9577, 0.9464, 0.947, 0.7566] 
2023-10-08 14:44:34.096868: Epoch time: 116.28 s 
2023-10-08 14:44:35.513744:  
2023-10-08 14:44:35.519221: Epoch 189 
2023-10-08 14:44:35.524343: Current learning rate: 0.00828 
2023-10-08 14:46:35.892364: train_loss -0.7517 
2023-10-08 14:46:35.900778: val_loss -0.7651 
2023-10-08 14:46:35.904753: Pseudo dice [0.9627, 0.9221, 0.9635, 0.7923] 
2023-10-08 14:46:35.908825: Epoch time: 120.38 s 
2023-10-08 14:46:37.548612:  
2023-10-08 14:46:37.553042: Epoch 190 
2023-10-08 14:46:37.560475: Current learning rate: 0.00827 
2023-10-08 14:48:35.103500: train_loss -0.7508 
2023-10-08 14:48:35.111619: val_loss -0.7305 
2023-10-08 14:48:35.115548: Pseudo dice [0.9481, 0.9512, 0.9337, 0.7343] 
2023-10-08 14:48:35.119179: Epoch time: 117.56 s 
2023-10-08 14:48:36.554336:  
2023-10-08 14:48:36.559529: Epoch 191 
2023-10-08 14:48:36.564322: Current learning rate: 0.00826 
2023-10-08 14:50:37.944778: train_loss -0.7535 
2023-10-08 14:50:37.952360: val_loss -0.7557 
2023-10-08 14:50:37.956094: Pseudo dice [0.9591, 0.9254, 0.9635, 0.7945] 
2023-10-08 14:50:37.959708: Epoch time: 121.39 s 
2023-10-08 14:50:39.415309:  
2023-10-08 14:50:39.419892: Epoch 192 
2023-10-08 14:50:39.423877: Current learning rate: 0.00825 
2023-10-08 14:52:37.475923: train_loss -0.757 
2023-10-08 14:52:37.484181: val_loss -0.801 
2023-10-08 14:52:37.488081: Pseudo dice [0.9657, 0.9452, 0.9738, 0.8069] 
2023-10-08 14:52:37.492151: Epoch time: 118.06 s 
2023-10-08 14:52:38.956376:  
2023-10-08 14:52:38.961623: Epoch 193 
2023-10-08 14:52:38.966247: Current learning rate: 0.00824 
2023-10-08 14:54:36.867213: train_loss -0.7538 
2023-10-08 14:54:36.878738: val_loss -0.7451 
2023-10-08 14:54:36.882520: Pseudo dice [0.9596, 0.9563, 0.8881, 0.8097] 
2023-10-08 14:54:36.885990: Epoch time: 117.91 s 
2023-10-08 14:54:38.380727:  
2023-10-08 14:54:38.385362: Epoch 194 
2023-10-08 14:54:38.389552: Current learning rate: 0.00824 
2023-10-08 14:56:35.994676: train_loss -0.7573 
2023-10-08 14:56:36.003041: val_loss -0.7871 
2023-10-08 14:56:36.007165: Pseudo dice [0.9699, 0.9512, 0.9718, 0.7918] 
2023-10-08 14:56:36.011526: Epoch time: 117.62 s 
2023-10-08 14:56:37.645470:  
2023-10-08 14:56:37.653154: Epoch 195 
2023-10-08 14:56:37.657115: Current learning rate: 0.00823 
2023-10-08 14:58:32.461324: train_loss -0.768 
2023-10-08 14:58:32.469265: val_loss -0.7852 
2023-10-08 14:58:32.473188: Pseudo dice [0.9696, 0.953, 0.9567, 0.8027] 
2023-10-08 14:58:32.477478: Epoch time: 114.82 s 
2023-10-08 14:58:34.056877:  
2023-10-08 14:58:34.061150: Epoch 196 
2023-10-08 14:58:34.064919: Current learning rate: 0.00822 
2023-10-08 15:00:33.995529: train_loss -0.7694 
2023-10-08 15:00:34.004937: val_loss -0.7854 
2023-10-08 15:00:34.008792: Pseudo dice [0.9695, 0.9553, 0.9529, 0.7831] 
2023-10-08 15:00:34.012110: Epoch time: 119.94 s 
2023-10-08 15:00:34.014810: Yayy! New best EMA pseudo Dice: 0.9116 
2023-10-08 15:00:36.406935:  
2023-10-08 15:00:36.411316: Epoch 197 
2023-10-08 15:00:36.415518: Current learning rate: 0.00821 
2023-10-08 15:02:33.219924: train_loss -0.7837 
2023-10-08 15:02:33.227646: val_loss -0.8103 
2023-10-08 15:02:33.231425: Pseudo dice [0.9738, 0.9618, 0.9722, 0.8274] 
2023-10-08 15:02:33.235240: Epoch time: 116.82 s 
2023-10-08 15:02:33.238962: Yayy! New best EMA pseudo Dice: 0.9138 
2023-10-08 15:02:35.381654:  
2023-10-08 15:02:35.385796: Epoch 198 
2023-10-08 15:02:35.390225: Current learning rate: 0.0082 
2023-10-08 15:04:31.903495: train_loss -0.7829 
2023-10-08 15:04:31.911782: val_loss -0.8069 
2023-10-08 15:04:31.915658: Pseudo dice [0.9736, 0.9595, 0.9689, 0.7971] 
2023-10-08 15:04:31.919498: Epoch time: 116.52 s 
2023-10-08 15:04:31.923365: Yayy! New best EMA pseudo Dice: 0.9149 
2023-10-08 15:04:34.079887:  
2023-10-08 15:04:34.084281: Epoch 199 
2023-10-08 15:04:34.087858: Current learning rate: 0.00819 
2023-10-08 15:06:35.447484: train_loss -0.7426 
2023-10-08 15:06:35.456248: val_loss -0.7455 
2023-10-08 15:06:35.460470: Pseudo dice [0.9567, 0.8942, 0.9591, 0.794] 
2023-10-08 15:06:35.464931: Epoch time: 121.37 s 
2023-10-08 15:06:37.659561:  
2023-10-08 15:06:37.663607: Epoch 200 
2023-10-08 15:06:37.672710: Current learning rate: 0.00818 
2023-10-08 15:08:32.702244: train_loss -0.7527 
2023-10-08 15:08:32.709871: val_loss -0.7792 
2023-10-08 15:08:32.714141: Pseudo dice [0.9617, 0.9463, 0.9498, 0.791] 
2023-10-08 15:08:32.718445: Epoch time: 115.05 s 
2023-10-08 15:08:34.167522:  
2023-10-08 15:08:34.172275: Epoch 201 
2023-10-08 15:08:34.176483: Current learning rate: 0.00817 
2023-10-08 15:10:28.384553: train_loss -0.7358 
2023-10-08 15:10:28.391996: val_loss -0.7698 
2023-10-08 15:10:28.396002: Pseudo dice [0.9683, 0.9556, 0.9657, 0.7591] 
2023-10-08 15:10:28.399697: Epoch time: 114.22 s 
2023-10-08 15:10:29.862569:  
2023-10-08 15:10:29.867349: Epoch 202 
2023-10-08 15:10:29.872877: Current learning rate: 0.00816 
2023-10-08 15:12:30.071021: train_loss -0.754 
2023-10-08 15:12:30.079159: val_loss -0.7847 
2023-10-08 15:12:30.083245: Pseudo dice [0.9748, 0.9506, 0.9551, 0.8004] 
2023-10-08 15:12:30.087167: Epoch time: 120.21 s 
2023-10-08 15:12:31.530430:  
2023-10-08 15:12:31.535116: Epoch 203 
2023-10-08 15:12:31.539573: Current learning rate: 0.00815 
2023-10-08 15:14:25.131881: train_loss -0.7581 
2023-10-08 15:14:25.144482: val_loss -0.8024 
2023-10-08 15:14:25.148500: Pseudo dice [0.9722, 0.9624, 0.952, 0.8049] 
2023-10-08 15:14:25.152664: Epoch time: 113.6 s 
2023-10-08 15:14:26.790925:  
2023-10-08 15:14:26.796014: Epoch 204 
2023-10-08 15:14:26.801454: Current learning rate: 0.00814 
2023-10-08 15:16:26.219791: train_loss -0.7584 
2023-10-08 15:16:26.227466: val_loss -0.7471 
2023-10-08 15:16:26.231204: Pseudo dice [0.963, 0.9359, 0.9475, 0.7873] 
2023-10-08 15:16:26.235312: Epoch time: 119.43 s 
2023-10-08 15:16:27.676486:  
2023-10-08 15:16:27.681427: Epoch 205 
2023-10-08 15:16:27.687766: Current learning rate: 0.00813 
2023-10-08 15:18:25.550876: train_loss -0.7567 
2023-10-08 15:18:25.558234: val_loss -0.7353 
2023-10-08 15:18:25.562920: Pseudo dice [0.9655, 0.9283, 0.9462, 0.8105] 
2023-10-08 15:18:25.566379: Epoch time: 117.88 s 
2023-10-08 15:18:26.906216:  
2023-10-08 15:18:26.910436: Epoch 206 
2023-10-08 15:18:26.914076: Current learning rate: 0.00813 
2023-10-08 15:20:21.216265: train_loss -0.7534 
2023-10-08 15:20:21.223467: val_loss -0.7655 
2023-10-08 15:20:21.226811: Pseudo dice [0.9655, 0.9359, 0.926, 0.8365] 
2023-10-08 15:20:21.230268: Epoch time: 114.31 s 
2023-10-08 15:20:22.565214:  
2023-10-08 15:20:22.569530: Epoch 207 
2023-10-08 15:20:22.574286: Current learning rate: 0.00812 
2023-10-08 15:22:19.863278: train_loss -0.7701 
2023-10-08 15:22:19.871422: val_loss -0.7568 
2023-10-08 15:22:19.875118: Pseudo dice [0.9619, 0.9408, 0.9436, 0.7937] 
2023-10-08 15:22:19.878825: Epoch time: 117.3 s 
2023-10-08 15:22:21.233790:  
2023-10-08 15:22:21.237697: Epoch 208 
2023-10-08 15:22:21.241613: Current learning rate: 0.00811 
2023-10-08 15:24:16.731494: train_loss -0.7793 
2023-10-08 15:24:16.739112: val_loss -0.7643 
2023-10-08 15:24:16.743059: Pseudo dice [0.9738, 0.9434, 0.9511, 0.7893] 
2023-10-08 15:24:16.746686: Epoch time: 115.5 s 
2023-10-08 15:24:18.144660:  
2023-10-08 15:24:18.149129: Epoch 209 
2023-10-08 15:24:18.153299: Current learning rate: 0.0081 
2023-10-08 15:26:13.643132: train_loss -0.7511 
2023-10-08 15:26:13.648675: val_loss -0.7165 
2023-10-08 15:26:13.651190: Pseudo dice [0.9466, 0.9389, 0.9113, 0.7441] 
2023-10-08 15:26:13.653437: Epoch time: 115.5 s 
2023-10-08 15:26:15.180655:  
2023-10-08 15:26:15.185698: Epoch 210 
2023-10-08 15:26:15.189750: Current learning rate: 0.00809 
2023-10-08 15:28:12.033031: train_loss -0.7591 
2023-10-08 15:28:12.040685: val_loss -0.7695 
2023-10-08 15:28:12.044198: Pseudo dice [0.9651, 0.9493, 0.9525, 0.7858] 
2023-10-08 15:28:12.048050: Epoch time: 116.85 s 
2023-10-08 15:28:13.394224:  
2023-10-08 15:28:13.400404: Epoch 211 
2023-10-08 15:28:13.405544: Current learning rate: 0.00808 
2023-10-08 15:30:11.231511: train_loss -0.7489 
2023-10-08 15:30:11.240065: val_loss -0.7311 
2023-10-08 15:30:11.243918: Pseudo dice [0.9416, 0.9245, 0.9245, 0.7929] 
2023-10-08 15:30:11.247393: Epoch time: 117.84 s 
2023-10-08 15:30:12.593831:  
2023-10-08 15:30:12.598305: Epoch 212 
2023-10-08 15:30:12.602303: Current learning rate: 0.00807 
2023-10-08 15:32:07.360157: train_loss -0.7306 
2023-10-08 15:32:07.367457: val_loss -0.746 
2023-10-08 15:32:07.371200: Pseudo dice [0.9581, 0.9244, 0.966, 0.7953] 
2023-10-08 15:32:07.375566: Epoch time: 114.77 s 
2023-10-08 15:32:08.735606:  
2023-10-08 15:32:08.740148: Epoch 213 
2023-10-08 15:32:08.743907: Current learning rate: 0.00806 
2023-10-08 15:34:13.421140: train_loss -0.7518 
2023-10-08 15:34:13.428651: val_loss -0.7625 
2023-10-08 15:34:13.432672: Pseudo dice [0.9624, 0.9492, 0.9367, 0.7989] 
2023-10-08 15:34:13.436667: Epoch time: 124.69 s 
2023-10-08 15:34:14.845452:  
2023-10-08 15:34:14.850487: Epoch 214 
2023-10-08 15:34:14.854434: Current learning rate: 0.00805 
2023-10-08 15:36:09.926051: train_loss -0.7588 
2023-10-08 15:36:09.939717: val_loss -0.7654 
2023-10-08 15:36:09.943819: Pseudo dice [0.9481, 0.9253, 0.9347, 0.7987] 
2023-10-08 15:36:09.947343: Epoch time: 115.08 s 
2023-10-08 15:36:11.508932:  
2023-10-08 15:36:11.514466: Epoch 215 
2023-10-08 15:36:11.518595: Current learning rate: 0.00804 
2023-10-08 15:38:11.945131: train_loss -0.7644 
2023-10-08 15:38:11.953354: val_loss -0.7888 
2023-10-08 15:38:11.957738: Pseudo dice [0.9655, 0.9432, 0.9465, 0.8227] 
2023-10-08 15:38:11.962194: Epoch time: 120.44 s 
2023-10-08 15:38:13.317161:  
2023-10-08 15:38:13.322307: Epoch 216 
2023-10-08 15:38:13.326859: Current learning rate: 0.00803 
2023-10-08 15:40:09.546688: train_loss -0.7745 
2023-10-08 15:40:09.555219: val_loss -0.8167 
2023-10-08 15:40:09.559625: Pseudo dice [0.9708, 0.9556, 0.9701, 0.8328] 
2023-10-08 15:40:09.563367: Epoch time: 116.23 s 
2023-10-08 15:40:10.936973:  
2023-10-08 15:40:10.942251: Epoch 217 
2023-10-08 15:40:10.946470: Current learning rate: 0.00802 
2023-10-08 15:42:05.808570: train_loss -0.7708 
2023-10-08 15:42:05.816945: val_loss -0.7731 
2023-10-08 15:42:05.821172: Pseudo dice [0.9715, 0.9586, 0.9526, 0.7739] 
2023-10-08 15:42:05.825211: Epoch time: 114.88 s 
2023-10-08 15:42:07.201854:  
2023-10-08 15:42:07.206563: Epoch 218 
2023-10-08 15:42:07.210860: Current learning rate: 0.00801 
2023-10-08 15:44:09.971823: train_loss -0.7346 
2023-10-08 15:44:09.979220: val_loss -0.7251 
2023-10-08 15:44:09.983309: Pseudo dice [0.9419, 0.943, 0.9287, 0.7505] 
2023-10-08 15:44:09.987218: Epoch time: 122.77 s 
2023-10-08 15:44:11.351563:  
2023-10-08 15:44:11.357287: Epoch 219 
2023-10-08 15:44:11.361640: Current learning rate: 0.00801 
2023-10-08 15:46:11.014498: train_loss -0.7534 
2023-10-08 15:46:11.021944: val_loss -0.753 
2023-10-08 15:46:11.026869: Pseudo dice [0.9611, 0.9481, 0.95, 0.8062] 
2023-10-08 15:46:11.030534: Epoch time: 119.66 s 
2023-10-08 15:46:12.405094:  
2023-10-08 15:46:12.409087: Epoch 220 
2023-10-08 15:46:12.412975: Current learning rate: 0.008 
2023-10-08 15:48:13.338895: train_loss -0.7263 
2023-10-08 15:48:13.345959: val_loss -0.7621 
2023-10-08 15:48:13.349364: Pseudo dice [0.9685, 0.9601, 0.9535, 0.7956] 
2023-10-08 15:48:13.352954: Epoch time: 120.94 s 
2023-10-08 15:48:14.930224:  
2023-10-08 15:48:14.934467: Epoch 221 
2023-10-08 15:48:14.938266: Current learning rate: 0.00799 
2023-10-08 15:50:12.552224: train_loss -0.73 
2023-10-08 15:50:12.559677: val_loss -0.7888 
2023-10-08 15:50:12.563361: Pseudo dice [0.9736, 0.9586, 0.9639, 0.8098] 
2023-10-08 15:50:12.567443: Epoch time: 117.62 s 
2023-10-08 15:50:13.916771:  
2023-10-08 15:50:13.921311: Epoch 222 
2023-10-08 15:50:13.925291: Current learning rate: 0.00798 
2023-10-08 15:52:11.336190: train_loss -0.7669 
2023-10-08 15:52:11.343940: val_loss -0.765 
2023-10-08 15:52:11.348017: Pseudo dice [0.9648, 0.9475, 0.9478, 0.7745] 
2023-10-08 15:52:11.352166: Epoch time: 117.42 s 
2023-10-08 15:52:12.694022:  
2023-10-08 15:52:12.698095: Epoch 223 
2023-10-08 15:52:12.701699: Current learning rate: 0.00797 
2023-10-08 15:54:10.376777: train_loss -0.7543 
2023-10-08 15:54:10.385796: val_loss -0.7576 
2023-10-08 15:54:10.390177: Pseudo dice [0.9609, 0.9497, 0.9317, 0.7648] 
2023-10-08 15:54:10.394357: Epoch time: 117.69 s 
2023-10-08 15:54:11.760170:  
2023-10-08 15:54:11.765437: Epoch 224 
2023-10-08 15:54:11.769881: Current learning rate: 0.00796 
2023-10-08 15:56:13.616771: train_loss -0.7621 
2023-10-08 15:56:13.624740: val_loss -0.7592 
2023-10-08 15:56:13.628637: Pseudo dice [0.9576, 0.9224, 0.9596, 0.8362] 
2023-10-08 15:56:13.632588: Epoch time: 121.86 s 
2023-10-08 15:56:15.001380:  
2023-10-08 15:56:15.006638: Epoch 225 
2023-10-08 15:56:15.011687: Current learning rate: 0.00795 
2023-10-08 15:58:11.269807: train_loss -0.7441 
2023-10-08 15:58:11.278304: val_loss -0.7539 
2023-10-08 15:58:11.282680: Pseudo dice [0.9632, 0.9519, 0.9338, 0.8238] 
2023-10-08 15:58:11.286610: Epoch time: 116.27 s 
2023-10-08 15:58:12.821039:  
2023-10-08 15:58:12.825469: Epoch 226 
2023-10-08 15:58:12.830026: Current learning rate: 0.00794 
2023-10-08 16:00:11.762669: train_loss -0.7702 
2023-10-08 16:00:11.770096: val_loss -0.7746 
2023-10-08 16:00:11.773931: Pseudo dice [0.9547, 0.9602, 0.9182, 0.8471] 
2023-10-08 16:00:11.777783: Epoch time: 118.95 s 
2023-10-08 16:00:13.169052:  
2023-10-08 16:00:13.173416: Epoch 227 
2023-10-08 16:00:13.177203: Current learning rate: 0.00793 
2023-10-08 16:02:13.933418: train_loss -0.7504 
2023-10-08 16:02:13.943434: val_loss -0.7733 
2023-10-08 16:02:13.947662: Pseudo dice [0.9688, 0.9586, 0.9431, 0.8233] 
2023-10-08 16:02:13.951725: Epoch time: 120.77 s 
2023-10-08 16:02:15.319230:  
2023-10-08 16:02:15.323824: Epoch 228 
2023-10-08 16:02:15.327712: Current learning rate: 0.00792 
2023-10-08 16:04:10.874612: train_loss -0.7593 
2023-10-08 16:04:10.882431: val_loss -0.8065 
2023-10-08 16:04:10.890725: Pseudo dice [0.9717, 0.9587, 0.9605, 0.8378] 
2023-10-08 16:04:10.894778: Epoch time: 115.56 s 
2023-10-08 16:04:10.898814: Yayy! New best EMA pseudo Dice: 0.9165 
2023-10-08 16:04:13.067295:  
2023-10-08 16:04:13.072087: Epoch 229 
2023-10-08 16:04:13.076139: Current learning rate: 0.00791 
2023-10-08 16:06:12.223466: train_loss -0.7649 
2023-10-08 16:06:12.230819: val_loss -0.8076 
2023-10-08 16:06:12.234948: Pseudo dice [0.9684, 0.9556, 0.9543, 0.8407] 
2023-10-08 16:06:12.238806: Epoch time: 119.16 s 
2023-10-08 16:06:12.242431: Yayy! New best EMA pseudo Dice: 0.9178 
2023-10-08 16:06:14.444899:  
2023-10-08 16:06:14.449750: Epoch 230 
2023-10-08 16:06:14.453566: Current learning rate: 0.0079 
2023-10-08 16:08:10.103563: train_loss -0.7381 
2023-10-08 16:08:10.111874: val_loss -0.7659 
2023-10-08 16:08:10.116073: Pseudo dice [0.9656, 0.96, 0.9558, 0.8146] 
2023-10-08 16:08:10.120023: Epoch time: 115.66 s 
2023-10-08 16:08:10.124296: Yayy! New best EMA pseudo Dice: 0.9184 
2023-10-08 16:08:12.461118:  
2023-10-08 16:08:12.465456: Epoch 231 
2023-10-08 16:08:12.469605: Current learning rate: 0.00789 
2023-10-08 16:10:04.388792: train_loss -0.7594 
2023-10-08 16:10:04.396678: val_loss -0.7668 
2023-10-08 16:10:04.400877: Pseudo dice [0.9541, 0.923, 0.9639, 0.8158] 
2023-10-08 16:10:04.404896: Epoch time: 111.93 s 
2023-10-08 16:10:05.814615:  
2023-10-08 16:10:05.820555: Epoch 232 
2023-10-08 16:10:05.825421: Current learning rate: 0.00789 
2023-10-08 16:12:01.951981: train_loss -0.7521 
2023-10-08 16:12:01.959265: val_loss -0.7308 
2023-10-08 16:12:01.962747: Pseudo dice [0.9644, 0.9453, 0.9011, 0.7812] 
2023-10-08 16:12:01.966525: Epoch time: 116.14 s 
2023-10-08 16:12:03.305702:  
2023-10-08 16:12:03.310448: Epoch 233 
2023-10-08 16:12:03.315017: Current learning rate: 0.00788 
2023-10-08 16:13:57.878143: train_loss -0.7547 
2023-10-08 16:13:57.886190: val_loss -0.7883 
2023-10-08 16:13:57.890226: Pseudo dice [0.9595, 0.961, 0.9476, 0.7958] 
2023-10-08 16:13:57.894405: Epoch time: 114.58 s 
2023-10-08 16:13:59.267003:  
2023-10-08 16:13:59.272508: Epoch 234 
2023-10-08 16:13:59.277168: Current learning rate: 0.00787 
2023-10-08 16:15:56.988635: train_loss -0.7547 
2023-10-08 16:15:56.995987: val_loss -0.7658 
2023-10-08 16:15:56.999210: Pseudo dice [0.9687, 0.9447, 0.9391, 0.7968] 
2023-10-08 16:15:57.002849: Epoch time: 117.72 s 
2023-10-08 16:15:58.385752:  
2023-10-08 16:15:58.391516: Epoch 235 
2023-10-08 16:15:58.395257: Current learning rate: 0.00786 
2023-10-08 16:17:58.870122: train_loss -0.7558 
2023-10-08 16:17:58.878308: val_loss -0.7932 
2023-10-08 16:17:58.882434: Pseudo dice [0.9616, 0.9579, 0.9466, 0.7978] 
2023-10-08 16:17:58.886335: Epoch time: 120.49 s 
2023-10-08 16:18:00.209656:  
2023-10-08 16:18:00.215175: Epoch 236 
2023-10-08 16:18:00.219662: Current learning rate: 0.00785 
2023-10-08 16:19:56.723594: train_loss -0.7705 
2023-10-08 16:19:56.731286: val_loss -0.7932 
2023-10-08 16:19:56.735248: Pseudo dice [0.9755, 0.941, 0.964, 0.8317] 
2023-10-08 16:19:56.738642: Epoch time: 116.52 s 
2023-10-08 16:19:58.358844:  
2023-10-08 16:19:58.363110: Epoch 237 
2023-10-08 16:19:58.368080: Current learning rate: 0.00784 
2023-10-08 16:21:55.464149: train_loss -0.7556 
2023-10-08 16:21:55.471359: val_loss -0.7885 
2023-10-08 16:21:55.474972: Pseudo dice [0.9649, 0.9564, 0.9451, 0.7696] 
2023-10-08 16:21:55.478720: Epoch time: 117.11 s 
2023-10-08 16:21:56.826340:  
2023-10-08 16:21:56.831729: Epoch 238 
2023-10-08 16:21:56.835648: Current learning rate: 0.00783 
2023-10-08 16:23:53.991331: train_loss -0.7595 
2023-10-08 16:23:53.999283: val_loss -0.7899 
2023-10-08 16:23:54.005163: Pseudo dice [0.9695, 0.9508, 0.9547, 0.7994] 
2023-10-08 16:23:54.008402: Epoch time: 117.17 s 
2023-10-08 16:23:55.371476:  
2023-10-08 16:23:55.376019: Epoch 239 
2023-10-08 16:23:55.380049: Current learning rate: 0.00782 
2023-10-08 16:25:48.802230: train_loss -0.7463 
2023-10-08 16:25:48.810364: val_loss -0.7672 
2023-10-08 16:25:48.814306: Pseudo dice [0.9655, 0.9386, 0.9573, 0.7852] 
2023-10-08 16:25:48.820041: Epoch time: 113.43 s 
2023-10-08 16:25:50.181691:  
2023-10-08 16:25:50.186029: Epoch 240 
2023-10-08 16:25:50.190413: Current learning rate: 0.00781 
2023-10-08 16:27:47.379116: train_loss -0.7533 
2023-10-08 16:27:47.386808: val_loss -0.7554 
2023-10-08 16:27:47.390593: Pseudo dice [0.9736, 0.9536, 0.9607, 0.7649] 
2023-10-08 16:27:47.394251: Epoch time: 117.2 s 
2023-10-08 16:27:48.759551:  
2023-10-08 16:27:48.764937: Epoch 241 
2023-10-08 16:27:48.769391: Current learning rate: 0.0078 
2023-10-08 16:29:43.187105: train_loss -0.7623 
2023-10-08 16:29:43.194783: val_loss -0.756 
2023-10-08 16:29:43.198431: Pseudo dice [0.9624, 0.8951, 0.9645, 0.8093] 
2023-10-08 16:29:43.203295: Epoch time: 114.43 s 
2023-10-08 16:29:44.585642:  
2023-10-08 16:29:44.589814: Epoch 242 
2023-10-08 16:29:44.593821: Current learning rate: 0.00779 
2023-10-08 16:31:43.433722: train_loss -0.7647 
2023-10-08 16:31:43.447616: val_loss -0.796 
2023-10-08 16:31:43.451494: Pseudo dice [0.9621, 0.9507, 0.9667, 0.7814] 
2023-10-08 16:31:43.455421: Epoch time: 118.85 s 
2023-10-08 16:31:44.985619:  
2023-10-08 16:31:44.990340: Epoch 243 
2023-10-08 16:31:44.994470: Current learning rate: 0.00778 
2023-10-08 16:33:40.070716: train_loss -0.7555 
2023-10-08 16:33:40.079060: val_loss -0.7421 
2023-10-08 16:33:40.083240: Pseudo dice [0.9626, 0.9159, 0.9491, 0.7501] 
2023-10-08 16:33:40.087311: Epoch time: 115.09 s 
2023-10-08 16:33:41.513108:  
2023-10-08 16:33:41.517160: Epoch 244 
2023-10-08 16:33:41.521138: Current learning rate: 0.00777 
2023-10-08 16:35:39.246127: train_loss -0.7738 
2023-10-08 16:35:39.253727: val_loss -0.7609 
2023-10-08 16:35:39.257505: Pseudo dice [0.9611, 0.9235, 0.9633, 0.8178] 
2023-10-08 16:35:39.261105: Epoch time: 117.74 s 
2023-10-08 16:35:40.627276:  
2023-10-08 16:35:40.632516: Epoch 245 
2023-10-08 16:35:40.637482: Current learning rate: 0.00777 
2023-10-08 16:37:35.123723: train_loss -0.738 
2023-10-08 16:37:35.131459: val_loss -0.7301 
2023-10-08 16:37:35.135673: Pseudo dice [0.9564, 0.9554, 0.9668, 0.8039] 
2023-10-08 16:37:35.140209: Epoch time: 114.5 s 
2023-10-08 16:37:36.515553:  
2023-10-08 16:37:36.520567: Epoch 246 
2023-10-08 16:37:36.525074: Current learning rate: 0.00776 
2023-10-08 16:39:32.214396: train_loss -0.772 
2023-10-08 16:39:32.222368: val_loss -0.7633 
2023-10-08 16:39:32.226432: Pseudo dice [0.9708, 0.9121, 0.9477, 0.7951] 
2023-10-08 16:39:32.230275: Epoch time: 115.7 s 
2023-10-08 16:39:33.607356:  
2023-10-08 16:39:33.611985: Epoch 247 
2023-10-08 16:39:33.615908: Current learning rate: 0.00775 
2023-10-08 16:41:28.183738: train_loss -0.7613 
2023-10-08 16:41:28.191454: val_loss -0.7984 
2023-10-08 16:41:28.195544: Pseudo dice [0.9706, 0.9539, 0.9614, 0.8221] 
2023-10-08 16:41:28.199498: Epoch time: 114.58 s 
2023-10-08 16:41:29.764318:  
2023-10-08 16:41:29.768768: Epoch 248 
2023-10-08 16:41:29.772820: Current learning rate: 0.00774 
2023-10-08 16:43:26.811723: train_loss -0.7552 
2023-10-08 16:43:26.819617: val_loss -0.7595 
2023-10-08 16:43:26.823346: Pseudo dice [0.9459, 0.9306, 0.966, 0.7818] 
2023-10-08 16:43:26.827214: Epoch time: 117.05 s 
2023-10-08 16:43:28.196146:  
2023-10-08 16:43:28.201844: Epoch 249 
2023-10-08 16:43:28.206248: Current learning rate: 0.00773 
2023-10-08 16:45:29.582956: train_loss -0.767 
2023-10-08 16:45:29.590942: val_loss -0.795 
2023-10-08 16:45:29.594701: Pseudo dice [0.9577, 0.9431, 0.9463, 0.8405] 
2023-10-08 16:45:29.598515: Epoch time: 121.39 s 
2023-10-08 16:45:31.665534:  
2023-10-08 16:45:31.672082: Epoch 250 
2023-10-08 16:45:31.676714: Current learning rate: 0.00772 
2023-10-08 16:47:25.975022: train_loss -0.7547 
2023-10-08 16:47:25.983921: val_loss -0.7352 
2023-10-08 16:47:25.988042: Pseudo dice [0.9577, 0.948, 0.9144, 0.8063] 
2023-10-08 16:47:25.991975: Epoch time: 114.31 s 
2023-10-08 16:47:27.394461:  
2023-10-08 16:47:27.400825: Epoch 251 
2023-10-08 16:47:27.405582: Current learning rate: 0.00771 
2023-10-08 16:49:25.420407: train_loss -0.7552 
2023-10-08 16:49:25.428805: val_loss -0.7955 
2023-10-08 16:49:25.432472: Pseudo dice [0.9775, 0.9505, 0.9669, 0.8265] 
2023-10-08 16:49:25.436604: Epoch time: 118.03 s 
2023-10-08 16:49:26.790687:  
2023-10-08 16:49:26.795805: Epoch 252 
2023-10-08 16:49:26.800256: Current learning rate: 0.0077 
2023-10-08 16:51:29.195406: train_loss -0.7717 
2023-10-08 16:51:29.202745: val_loss -0.7755 
2023-10-08 16:51:29.206552: Pseudo dice [0.9678, 0.957, 0.9588, 0.8122] 
2023-10-08 16:51:29.210113: Epoch time: 122.41 s 
2023-10-08 16:51:30.563088:  
2023-10-08 16:51:30.567722: Epoch 253 
2023-10-08 16:51:30.571957: Current learning rate: 0.00769 
2023-10-08 16:53:25.312446: train_loss -0.753 
2023-10-08 16:53:25.320642: val_loss -0.7427 
2023-10-08 16:53:25.327483: Pseudo dice [0.9736, 0.9471, 0.9568, 0.7468] 
2023-10-08 16:53:25.331623: Epoch time: 114.75 s 
2023-10-08 16:53:26.890985:  
2023-10-08 16:53:26.895708: Epoch 254 
2023-10-08 16:53:26.901776: Current learning rate: 0.00768 
2023-10-08 16:55:20.496452: train_loss -0.7254 
2023-10-08 16:55:20.504541: val_loss -0.8071 
2023-10-08 16:55:20.508605: Pseudo dice [0.9718, 0.9504, 0.9736, 0.8374] 
2023-10-08 16:55:20.512258: Epoch time: 113.61 s 
2023-10-08 16:55:21.867136:  
2023-10-08 16:55:21.872862: Epoch 255 
2023-10-08 16:55:21.877762: Current learning rate: 0.00767 
2023-10-08 16:57:22.541911: train_loss -0.776 
2023-10-08 16:57:22.549437: val_loss -0.7619 
2023-10-08 16:57:22.553190: Pseudo dice [0.9753, 0.9469, 0.9579, 0.7999] 
2023-10-08 16:57:22.556874: Epoch time: 120.68 s 
2023-10-08 16:57:23.937547:  
2023-10-08 16:57:23.941941: Epoch 256 
2023-10-08 16:57:23.949495: Current learning rate: 0.00766 
2023-10-08 16:59:20.915990: train_loss -0.7767 
2023-10-08 16:59:20.924778: val_loss -0.7747 
2023-10-08 16:59:20.931251: Pseudo dice [0.9586, 0.9447, 0.9464, 0.8343] 
2023-10-08 16:59:20.935110: Epoch time: 116.98 s 
2023-10-08 16:59:22.348706:  
2023-10-08 16:59:22.353683: Epoch 257 
2023-10-08 16:59:22.358298: Current learning rate: 0.00765 
2023-10-08 17:01:19.929952: train_loss -0.7654 
2023-10-08 17:01:19.937616: val_loss -0.7866 
2023-10-08 17:01:19.941505: Pseudo dice [0.9687, 0.9516, 0.9615, 0.8033] 
2023-10-08 17:01:19.945188: Epoch time: 117.58 s 
2023-10-08 17:01:21.311368:  
2023-10-08 17:01:21.315933: Epoch 258 
2023-10-08 17:01:21.319863: Current learning rate: 0.00764 
2023-10-08 17:03:18.726381: train_loss -0.7481 
2023-10-08 17:03:18.733926: val_loss -0.7768 
2023-10-08 17:03:18.738577: Pseudo dice [0.9562, 0.9616, 0.9352, 0.7922] 
2023-10-08 17:03:18.742381: Epoch time: 117.42 s 
2023-10-08 17:03:20.309567:  
2023-10-08 17:03:20.313941: Epoch 259 
2023-10-08 17:03:20.318110: Current learning rate: 0.00764 
2023-10-08 17:05:17.754951: train_loss -0.7546 
2023-10-08 17:05:17.763090: val_loss -0.7776 
2023-10-08 17:05:17.767222: Pseudo dice [0.9666, 0.9466, 0.9496, 0.8141] 
2023-10-08 17:05:17.771242: Epoch time: 117.45 s 
2023-10-08 17:05:19.176182:  
2023-10-08 17:05:19.181331: Epoch 260 
2023-10-08 17:05:19.185731: Current learning rate: 0.00763 
2023-10-08 17:07:13.749032: train_loss -0.7644 
2023-10-08 17:07:13.756231: val_loss -0.7889 
2023-10-08 17:07:13.759915: Pseudo dice [0.9738, 0.9613, 0.9554, 0.8109] 
2023-10-08 17:07:13.765262: Epoch time: 114.58 s 
2023-10-08 17:07:15.111925:  
2023-10-08 17:07:15.116658: Epoch 261 
2023-10-08 17:07:15.120603: Current learning rate: 0.00762 
2023-10-08 17:09:10.091699: train_loss -0.7808 
2023-10-08 17:09:10.100177: val_loss -0.774 
2023-10-08 17:09:10.104221: Pseudo dice [0.9548, 0.9195, 0.9433, 0.8202] 
2023-10-08 17:09:10.108217: Epoch time: 114.98 s 
2023-10-08 17:09:11.469523:  
2023-10-08 17:09:11.474070: Epoch 262 
2023-10-08 17:09:11.478245: Current learning rate: 0.00761 
2023-10-08 17:11:07.737467: train_loss -0.7816 
2023-10-08 17:11:07.745505: val_loss -0.7184 
2023-10-08 17:11:07.749516: Pseudo dice [0.9462, 0.9299, 0.8969, 0.8018] 
2023-10-08 17:11:07.753297: Epoch time: 116.27 s 
2023-10-08 17:11:09.136707:  
2023-10-08 17:11:09.141720: Epoch 263 
2023-10-08 17:11:09.146122: Current learning rate: 0.0076 
2023-10-08 17:13:06.484668: train_loss -0.7626 
2023-10-08 17:13:06.492167: val_loss -0.7911 
2023-10-08 17:13:06.496541: Pseudo dice [0.977, 0.9575, 0.9533, 0.8159] 
2023-10-08 17:13:06.500532: Epoch time: 117.35 s 
2023-10-08 17:13:07.869300:  
2023-10-08 17:13:07.874589: Epoch 264 
2023-10-08 17:13:07.879381: Current learning rate: 0.00759 
2023-10-08 17:15:05.521647: train_loss -0.7517 
2023-10-08 17:15:05.529534: val_loss -0.7817 
2023-10-08 17:15:05.533365: Pseudo dice [0.9683, 0.9502, 0.9464, 0.8243] 
2023-10-08 17:15:05.536844: Epoch time: 117.66 s 
2023-10-08 17:15:07.090193:  
2023-10-08 17:15:07.094963: Epoch 265 
2023-10-08 17:15:07.098868: Current learning rate: 0.00758 
2023-10-08 17:17:11.447133: train_loss -0.7773 
2023-10-08 17:17:11.455547: val_loss -0.7696 
2023-10-08 17:17:11.459476: Pseudo dice [0.98, 0.9575, 0.9733, 0.8221] 
2023-10-08 17:17:11.463406: Epoch time: 124.36 s 
2023-10-08 17:17:11.467456: Yayy! New best EMA pseudo Dice: 0.9184 
2023-10-08 17:17:13.581605:  
2023-10-08 17:17:13.586376: Epoch 266 
2023-10-08 17:17:13.591062: Current learning rate: 0.00757 
2023-10-08 17:19:15.603296: train_loss -0.7745 
2023-10-08 17:19:15.611213: val_loss -0.7864 
2023-10-08 17:19:15.615212: Pseudo dice [0.9706, 0.949, 0.962, 0.812] 
2023-10-08 17:19:15.619010: Epoch time: 122.03 s 
2023-10-08 17:19:15.622660: Yayy! New best EMA pseudo Dice: 0.9189 
2023-10-08 17:19:17.693761:  
2023-10-08 17:19:17.698497: Epoch 267 
2023-10-08 17:19:17.702960: Current learning rate: 0.00756 
2023-10-08 17:21:10.502256: train_loss -0.7758 
2023-10-08 17:21:10.510333: val_loss -0.7559 
2023-10-08 17:21:10.514597: Pseudo dice [0.9576, 0.9486, 0.8905, 0.8273] 
2023-10-08 17:21:10.518643: Epoch time: 112.81 s 
2023-10-08 17:21:11.886446:  
2023-10-08 17:21:11.891448: Epoch 268 
2023-10-08 17:21:11.895594: Current learning rate: 0.00755 
2023-10-08 17:23:09.838099: train_loss -0.7646 
2023-10-08 17:23:09.846172: val_loss -0.8165 
2023-10-08 17:23:09.853746: Pseudo dice [0.9665, 0.9566, 0.9682, 0.8103] 
2023-10-08 17:23:09.860421: Epoch time: 117.95 s 
2023-10-08 17:23:11.191648:  
2023-10-08 17:23:11.197314: Epoch 269 
2023-10-08 17:23:11.201456: Current learning rate: 0.00754 
2023-10-08 17:25:09.036177: train_loss -0.7879 
2023-10-08 17:25:09.044398: val_loss -0.7543 
2023-10-08 17:25:09.048945: Pseudo dice [0.9562, 0.9181, 0.9285, 0.8023] 
2023-10-08 17:25:09.053258: Epoch time: 117.85 s 
2023-10-08 17:25:10.629736:  
2023-10-08 17:25:10.634604: Epoch 270 
2023-10-08 17:25:10.638817: Current learning rate: 0.00753 
2023-10-08 17:27:13.112851: train_loss -0.7526 
2023-10-08 17:27:13.121447: val_loss -0.7719 
2023-10-08 17:27:13.125692: Pseudo dice [0.9657, 0.9566, 0.9518, 0.784] 
2023-10-08 17:27:13.129238: Epoch time: 122.49 s 
2023-10-08 17:27:14.513474:  
2023-10-08 17:27:14.517744: Epoch 271 
2023-10-08 17:27:14.521801: Current learning rate: 0.00752 
2023-10-08 17:29:12.500448: train_loss -0.757 
2023-10-08 17:29:12.508012: val_loss -0.8277 
2023-10-08 17:29:12.511767: Pseudo dice [0.9749, 0.9639, 0.9715, 0.8365] 
2023-10-08 17:29:12.515683: Epoch time: 117.99 s 
2023-10-08 17:29:13.894043:  
2023-10-08 17:29:13.900559: Epoch 272 
2023-10-08 17:29:13.905903: Current learning rate: 0.00751 
2023-10-08 17:31:09.834648: train_loss -0.7436 
2023-10-08 17:31:09.842625: val_loss -0.7614 
2023-10-08 17:31:09.846664: Pseudo dice [0.9474, 0.9225, 0.9623, 0.8025] 
2023-10-08 17:31:09.850255: Epoch time: 115.94 s 
2023-10-08 17:31:11.252357:  
2023-10-08 17:31:11.257192: Epoch 273 
2023-10-08 17:31:11.261410: Current learning rate: 0.00751 
2023-10-08 17:33:08.553994: train_loss -0.7684 
2023-10-08 17:33:08.561724: val_loss -0.7789 
2023-10-08 17:33:08.565526: Pseudo dice [0.9701, 0.9481, 0.952, 0.7761] 
2023-10-08 17:33:08.569235: Epoch time: 117.3 s 
2023-10-08 17:33:09.903260:  
2023-10-08 17:33:09.907740: Epoch 274 
2023-10-08 17:33:09.910741: Current learning rate: 0.0075 
2023-10-08 17:35:09.551377: train_loss -0.7622 
2023-10-08 17:35:09.559389: val_loss -0.7692 
2023-10-08 17:35:09.562881: Pseudo dice [0.9526, 0.9298, 0.9437, 0.7533] 
2023-10-08 17:35:09.566633: Epoch time: 119.65 s 
2023-10-08 17:35:10.945825:  
2023-10-08 17:35:10.950317: Epoch 275 
2023-10-08 17:35:10.954363: Current learning rate: 0.00749 
2023-10-08 17:37:04.668401: train_loss -0.7693 
2023-10-08 17:37:04.676837: val_loss -0.8079 
2023-10-08 17:37:04.680911: Pseudo dice [0.9676, 0.9415, 0.9626, 0.8603] 
2023-10-08 17:37:04.684815: Epoch time: 113.73 s 
2023-10-08 17:37:06.244811:  
2023-10-08 17:37:06.249338: Epoch 276 
2023-10-08 17:37:06.253399: Current learning rate: 0.00748 
2023-10-08 17:39:03.092018: train_loss -0.751 
2023-10-08 17:39:03.099519: val_loss -0.799 
2023-10-08 17:39:03.103165: Pseudo dice [0.9646, 0.9584, 0.9391, 0.8356] 
2023-10-08 17:39:03.106784: Epoch time: 116.85 s 
2023-10-08 17:39:04.464309:  
2023-10-08 17:39:04.469216: Epoch 277 
2023-10-08 17:39:04.473622: Current learning rate: 0.00747 
2023-10-08 17:41:04.477556: train_loss -0.7746 
2023-10-08 17:41:04.486250: val_loss -0.7852 
2023-10-08 17:41:04.489963: Pseudo dice [0.9695, 0.9532, 0.9547, 0.7908] 
2023-10-08 17:41:04.493723: Epoch time: 120.02 s 
2023-10-08 17:41:05.909097:  
2023-10-08 17:41:05.913515: Epoch 278 
2023-10-08 17:41:05.917399: Current learning rate: 0.00746 
2023-10-08 17:43:01.699912: train_loss -0.7816 
2023-10-08 17:43:01.708760: val_loss -0.7468 
2023-10-08 17:43:01.712975: Pseudo dice [0.9551, 0.927, 0.936, 0.7917] 
2023-10-08 17:43:01.717378: Epoch time: 115.79 s 
2023-10-08 17:43:03.181359:  
2023-10-08 17:43:03.185955: Epoch 279 
2023-10-08 17:43:03.190643: Current learning rate: 0.00745 
2023-10-08 17:45:00.425340: train_loss -0.7754 
2023-10-08 17:45:00.434371: val_loss -0.7961 
2023-10-08 17:45:00.438640: Pseudo dice [0.9649, 0.9568, 0.9441, 0.8093] 
2023-10-08 17:45:00.442588: Epoch time: 117.25 s 
2023-10-08 17:45:01.807607:  
2023-10-08 17:45:01.812877: Epoch 280 
2023-10-08 17:45:01.817305: Current learning rate: 0.00744 
2023-10-08 17:46:57.176044: train_loss -0.7594 
2023-10-08 17:46:57.184025: val_loss -0.7696 
2023-10-08 17:46:57.188432: Pseudo dice [0.9574, 0.9555, 0.9531, 0.7743] 
2023-10-08 17:46:57.192950: Epoch time: 115.37 s 
2023-10-08 17:46:58.735149:  
2023-10-08 17:46:58.741754: Epoch 281 
2023-10-08 17:46:58.746149: Current learning rate: 0.00743 
2023-10-08 17:48:54.833883: train_loss -0.7514 
2023-10-08 17:48:54.842118: val_loss -0.749 
2023-10-08 17:48:54.846044: Pseudo dice [0.9557, 0.9488, 0.9615, 0.7781] 
2023-10-08 17:48:54.850306: Epoch time: 116.1 s 
2023-10-08 17:48:56.291200:  
2023-10-08 17:48:56.295561: Epoch 282 
2023-10-08 17:48:56.300035: Current learning rate: 0.00742 
2023-10-08 17:50:55.182022: train_loss -0.7391 
2023-10-08 17:50:55.189896: val_loss -0.7409 
2023-10-08 17:50:55.193737: Pseudo dice [0.9479, 0.8948, 0.9541, 0.7447] 
2023-10-08 17:50:55.197644: Epoch time: 118.89 s 
2023-10-08 17:50:56.571598:  
2023-10-08 17:50:56.577415: Epoch 283 
2023-10-08 17:50:56.581609: Current learning rate: 0.00741 
2023-10-08 17:52:48.571167: train_loss -0.759 
2023-10-08 17:52:48.579574: val_loss -0.758 
2023-10-08 17:52:48.583695: Pseudo dice [0.9685, 0.9504, 0.9674, 0.7728] 
2023-10-08 17:52:48.588090: Epoch time: 112.0 s 
2023-10-08 17:52:49.993156:  
2023-10-08 17:52:49.997852: Epoch 284 
2023-10-08 17:52:50.002580: Current learning rate: 0.0074 
2023-10-08 17:54:45.039855: train_loss -0.751 
2023-10-08 17:54:45.048460: val_loss -0.7558 
2023-10-08 17:54:45.052706: Pseudo dice [0.9662, 0.9512, 0.9401, 0.8115] 
2023-10-08 17:54:45.056943: Epoch time: 115.05 s 
2023-10-08 17:54:46.449235:  
2023-10-08 17:54:46.456210: Epoch 285 
2023-10-08 17:54:46.462535: Current learning rate: 0.00739 
2023-10-08 17:56:42.439741: train_loss -0.7604 
2023-10-08 17:56:42.447517: val_loss -0.7748 
2023-10-08 17:56:42.451521: Pseudo dice [0.9699, 0.9571, 0.9433, 0.7953] 
2023-10-08 17:56:42.455587: Epoch time: 115.99 s 
2023-10-08 17:56:43.893757:  
2023-10-08 17:56:43.898161: Epoch 286 
2023-10-08 17:56:43.902124: Current learning rate: 0.00738 
2023-10-08 17:58:43.451397: train_loss -0.7433 
2023-10-08 17:58:43.459441: val_loss -0.781 
2023-10-08 17:58:43.463176: Pseudo dice [0.9625, 0.9498, 0.9456, 0.7732] 
2023-10-08 17:58:43.467020: Epoch time: 119.56 s 
2023-10-08 17:58:45.049408:  
2023-10-08 17:58:45.054010: Epoch 287 
2023-10-08 17:58:45.057969: Current learning rate: 0.00738 
2023-10-08 18:00:42.755568: train_loss -0.7572 
2023-10-08 18:00:42.763840: val_loss -0.7677 
2023-10-08 18:00:42.767694: Pseudo dice [0.9722, 0.9404, 0.9577, 0.8239] 
2023-10-08 18:00:42.771575: Epoch time: 117.71 s 
2023-10-08 18:00:44.154512:  
2023-10-08 18:00:44.158591: Epoch 288 
2023-10-08 18:00:44.162241: Current learning rate: 0.00737 
2023-10-08 18:02:41.561805: train_loss -0.7813 
2023-10-08 18:02:41.570469: val_loss -0.7631 
2023-10-08 18:02:41.574640: Pseudo dice [0.9633, 0.9546, 0.9573, 0.7552] 
2023-10-08 18:02:41.579290: Epoch time: 117.41 s 
2023-10-08 18:02:42.980494:  
2023-10-08 18:02:42.985536: Epoch 289 
2023-10-08 18:02:42.989713: Current learning rate: 0.00736 
2023-10-08 18:04:42.198703: train_loss -0.7663 
2023-10-08 18:04:42.206677: val_loss -0.6802 
2023-10-08 18:04:42.210241: Pseudo dice [0.9363, 0.9291, 0.9111, 0.7096] 
2023-10-08 18:04:42.213944: Epoch time: 119.22 s 
2023-10-08 18:04:43.601910:  
2023-10-08 18:04:43.606304: Epoch 290 
2023-10-08 18:04:43.610374: Current learning rate: 0.00735 
2023-10-08 18:06:38.307195: train_loss -0.7544 
2023-10-08 18:06:38.315420: val_loss -0.7345 
2023-10-08 18:06:38.319117: Pseudo dice [0.9567, 0.9538, 0.9047, 0.7813] 
2023-10-08 18:06:38.323979: Epoch time: 114.71 s 
2023-10-08 18:06:39.704702:  
2023-10-08 18:06:39.710047: Epoch 291 
2023-10-08 18:06:39.714038: Current learning rate: 0.00734 
2023-10-08 18:08:33.827624: train_loss -0.7558 
2023-10-08 18:08:33.836423: val_loss -0.7918 
2023-10-08 18:08:33.840692: Pseudo dice [0.9681, 0.9613, 0.9474, 0.812] 
2023-10-08 18:08:33.844776: Epoch time: 114.13 s 
2023-10-08 18:08:35.409466:  
2023-10-08 18:08:35.414795: Epoch 292 
2023-10-08 18:08:35.419529: Current learning rate: 0.00733 
2023-10-08 18:10:30.240914: train_loss -0.773 
2023-10-08 18:10:30.249052: val_loss -0.7498 
2023-10-08 18:10:30.253103: Pseudo dice [0.9564, 0.9471, 0.9401, 0.7463] 
2023-10-08 18:10:30.259455: Epoch time: 114.83 s 
2023-10-08 18:10:31.649495:  
2023-10-08 18:10:31.654257: Epoch 293 
2023-10-08 18:10:31.658583: Current learning rate: 0.00732 
2023-10-08 18:12:30.866418: train_loss -0.7705 
2023-10-08 18:12:30.875287: val_loss -0.7829 
2023-10-08 18:12:30.879621: Pseudo dice [0.9632, 0.9484, 0.9319, 0.8267] 
2023-10-08 18:12:30.883469: Epoch time: 119.22 s 
2023-10-08 18:12:32.265868:  
2023-10-08 18:12:32.270658: Epoch 294 
2023-10-08 18:12:32.275079: Current learning rate: 0.00731 
2023-10-08 18:14:30.368916: train_loss -0.783 
2023-10-08 18:14:30.377681: val_loss -0.7526 
2023-10-08 18:14:30.382102: Pseudo dice [0.9698, 0.8999, 0.9618, 0.8144] 
2023-10-08 18:14:30.385931: Epoch time: 118.11 s 
2023-10-08 18:14:31.772917:  
2023-10-08 18:14:31.778330: Epoch 295 
2023-10-08 18:14:31.783123: Current learning rate: 0.0073 
2023-10-08 18:16:23.716026: train_loss -0.755 
2023-10-08 18:16:23.724228: val_loss -0.7943 
2023-10-08 18:16:23.728262: Pseudo dice [0.9739, 0.9476, 0.9699, 0.7862] 
2023-10-08 18:16:23.732277: Epoch time: 111.95 s 
2023-10-08 18:16:25.137744:  
2023-10-08 18:16:25.142841: Epoch 296 
2023-10-08 18:16:25.147961: Current learning rate: 0.00729 
2023-10-08 18:18:21.745679: train_loss -0.7821 
2023-10-08 18:18:21.753984: val_loss -0.8034 
2023-10-08 18:18:21.757771: Pseudo dice [0.9665, 0.9607, 0.9398, 0.8473] 
2023-10-08 18:18:21.764259: Epoch time: 116.61 s 
2023-10-08 18:18:23.368988:  
2023-10-08 18:18:23.373375: Epoch 297 
2023-10-08 18:18:23.377440: Current learning rate: 0.00728 
2023-10-08 18:20:18.734060: train_loss -0.783 
2023-10-08 18:20:18.741718: val_loss -0.8066 
2023-10-08 18:20:18.745567: Pseudo dice [0.9728, 0.9553, 0.9686, 0.7969] 
2023-10-08 18:20:18.749627: Epoch time: 115.37 s 
2023-10-08 18:20:20.191479:  
2023-10-08 18:20:20.195952: Epoch 298 
2023-10-08 18:20:20.199574: Current learning rate: 0.00727 
2023-10-08 18:22:15.312843: train_loss -0.7836 
2023-10-08 18:22:15.320974: val_loss -0.8238 
2023-10-08 18:22:15.324894: Pseudo dice [0.9701, 0.9556, 0.9648, 0.8424] 
2023-10-08 18:22:15.328993: Epoch time: 115.12 s 
2023-10-08 18:22:16.739455:  
2023-10-08 18:22:16.745492: Epoch 299 
2023-10-08 18:22:16.749741: Current learning rate: 0.00726 
2023-10-08 18:24:12.149465: train_loss -0.758 
2023-10-08 18:24:12.157771: val_loss -0.7464 
2023-10-08 18:24:12.161535: Pseudo dice [0.9605, 0.9317, 0.9398, 0.8332] 
2023-10-08 18:24:12.165537: Epoch time: 115.41 s 
2023-10-08 18:24:14.277178:  
2023-10-08 18:24:14.281581: Epoch 300 
2023-10-08 18:24:14.285763: Current learning rate: 0.00725 
2023-10-08 18:26:06.848746: train_loss -0.7758 
2023-10-08 18:26:06.856884: val_loss -0.8002 
2023-10-08 18:26:06.861081: Pseudo dice [0.9694, 0.9634, 0.9592, 0.8052] 
2023-10-08 18:26:06.864994: Epoch time: 112.58 s 
2023-10-08 18:26:08.273866:  
2023-10-08 18:26:08.277960: Epoch 301 
2023-10-08 18:26:08.281719: Current learning rate: 0.00724 
2023-10-08 18:28:09.394938: train_loss -0.7877 
2023-10-08 18:28:09.402889: val_loss -0.8052 
2023-10-08 18:28:09.406819: Pseudo dice [0.9667, 0.9603, 0.9613, 0.8357] 
2023-10-08 18:28:09.410655: Epoch time: 121.12 s 
2023-10-08 18:28:10.781698:  
2023-10-08 18:28:10.786644: Epoch 302 
2023-10-08 18:28:10.790771: Current learning rate: 0.00724 
2023-10-08 18:30:05.646287: train_loss -0.7874 
2023-10-08 18:30:05.654655: val_loss -0.773 
2023-10-08 18:30:05.658445: Pseudo dice [0.9687, 0.9555, 0.9531, 0.8304] 
2023-10-08 18:30:05.662476: Epoch time: 114.87 s 
2023-10-08 18:30:07.248883:  
2023-10-08 18:30:07.252964: Epoch 303 
2023-10-08 18:30:07.257518: Current learning rate: 0.00723 
2023-10-08 18:32:03.445715: train_loss -0.7707 
2023-10-08 18:32:03.453617: val_loss -0.8101 
2023-10-08 18:32:03.457575: Pseudo dice [0.9709, 0.9558, 0.9565, 0.8359] 
2023-10-08 18:32:03.461293: Epoch time: 116.2 s 
2023-10-08 18:32:03.464878: Yayy! New best EMA pseudo Dice: 0.9198 
2023-10-08 18:32:05.585536:  
2023-10-08 18:32:05.590181: Epoch 304 
2023-10-08 18:32:05.593978: Current learning rate: 0.00722 
2023-10-08 18:34:06.576780: train_loss -0.76 
2023-10-08 18:34:06.584858: val_loss -0.7807 
2023-10-08 18:34:06.588773: Pseudo dice [0.9584, 0.9622, 0.9382, 0.8151] 
2023-10-08 18:34:06.592539: Epoch time: 120.99 s 
2023-10-08 18:34:07.989858:  
2023-10-08 18:34:07.994557: Epoch 305 
2023-10-08 18:34:07.999297: Current learning rate: 0.00721 
2023-10-08 18:36:03.922502: train_loss -0.7832 
2023-10-08 18:36:03.930672: val_loss -0.7746 
2023-10-08 18:36:03.934850: Pseudo dice [0.963, 0.9591, 0.9504, 0.7606] 
2023-10-08 18:36:03.938916: Epoch time: 115.94 s 
2023-10-08 18:36:05.346195:  
2023-10-08 18:36:05.350670: Epoch 306 
2023-10-08 18:36:05.355673: Current learning rate: 0.0072 
2023-10-08 18:38:05.145761: train_loss -0.7674 
2023-10-08 18:38:05.154650: val_loss -0.7669 
2023-10-08 18:38:05.158626: Pseudo dice [0.9675, 0.9566, 0.9259, 0.8009] 
2023-10-08 18:38:05.162473: Epoch time: 119.8 s 
2023-10-08 18:38:06.544806:  
2023-10-08 18:38:06.549730: Epoch 307 
2023-10-08 18:38:06.554030: Current learning rate: 0.00719 
2023-10-08 18:40:01.251473: train_loss -0.7794 
2023-10-08 18:40:01.258885: val_loss -0.7886 
2023-10-08 18:40:01.262673: Pseudo dice [0.9713, 0.9609, 0.9592, 0.769] 
2023-10-08 18:40:01.266323: Epoch time: 114.71 s 
2023-10-08 18:40:02.824388:  
2023-10-08 18:40:02.828327: Epoch 308 
2023-10-08 18:40:02.832162: Current learning rate: 0.00718 
2023-10-08 18:42:03.206267: train_loss -0.7859 
2023-10-08 18:42:03.213932: val_loss -0.7804 
2023-10-08 18:42:03.217803: Pseudo dice [0.9755, 0.9481, 0.9624, 0.826] 
2023-10-08 18:42:03.225415: Epoch time: 120.38 s 
2023-10-08 18:42:04.659238:  
2023-10-08 18:42:04.664005: Epoch 309 
2023-10-08 18:42:04.667819: Current learning rate: 0.00717 
2023-10-08 18:44:01.907772: train_loss -0.7751 
2023-10-08 18:44:01.916145: val_loss -0.7977 
2023-10-08 18:44:01.920008: Pseudo dice [0.9763, 0.9607, 0.9523, 0.824] 
2023-10-08 18:44:01.923911: Epoch time: 117.25 s 
2023-10-08 18:44:03.337213:  
2023-10-08 18:44:03.341549: Epoch 310 
2023-10-08 18:44:03.345739: Current learning rate: 0.00716 
2023-10-08 18:45:59.768137: train_loss -0.7852 
2023-10-08 18:45:59.776160: val_loss -0.8159 
2023-10-08 18:45:59.780148: Pseudo dice [0.9752, 0.9622, 0.9682, 0.8303] 
2023-10-08 18:45:59.784324: Epoch time: 116.43 s 
2023-10-08 18:45:59.788193: Yayy! New best EMA pseudo Dice: 0.9211 
2023-10-08 18:46:01.927154:  
2023-10-08 18:46:01.931596: Epoch 311 
2023-10-08 18:46:01.935688: Current learning rate: 0.00715 
2023-10-08 18:48:01.057560: train_loss -0.7768 
2023-10-08 18:48:01.066966: val_loss -0.7841 
2023-10-08 18:48:01.071684: Pseudo dice [0.9625, 0.9461, 0.9684, 0.7741] 
2023-10-08 18:48:01.075435: Epoch time: 119.13 s 
2023-10-08 18:48:02.513574:  
2023-10-08 18:48:02.517869: Epoch 312 
2023-10-08 18:48:02.521818: Current learning rate: 0.00714 
2023-10-08 18:50:01.365566: train_loss -0.7805 
2023-10-08 18:50:01.373655: val_loss -0.7208 
2023-10-08 18:50:01.377611: Pseudo dice [0.9597, 0.9044, 0.9035, 0.8365] 
2023-10-08 18:50:01.382237: Epoch time: 118.86 s 
2023-10-08 18:50:03.014151:  
2023-10-08 18:50:03.019422: Epoch 313 
2023-10-08 18:50:03.023597: Current learning rate: 0.00713 
2023-10-08 18:52:05.772467: train_loss -0.7583 
2023-10-08 18:52:05.780066: val_loss -0.8063 
2023-10-08 18:52:05.784003: Pseudo dice [0.9662, 0.9492, 0.9705, 0.8385] 
2023-10-08 18:52:05.787867: Epoch time: 122.76 s 
2023-10-08 18:52:07.231608:  
2023-10-08 18:52:07.236531: Epoch 314 
2023-10-08 18:52:07.240541: Current learning rate: 0.00712 
2023-10-08 18:53:59.540463: train_loss -0.7751 
2023-10-08 18:53:59.549273: val_loss -0.7409 
2023-10-08 18:53:59.553795: Pseudo dice [0.9572, 0.9484, 0.9267, 0.7742] 
2023-10-08 18:53:59.557790: Epoch time: 112.31 s 
2023-10-08 18:54:00.954401:  
2023-10-08 18:54:00.959281: Epoch 315 
2023-10-08 18:54:00.964011: Current learning rate: 0.00711 
2023-10-08 18:55:57.948262: train_loss -0.7761 
2023-10-08 18:55:57.955737: val_loss -0.7917 
2023-10-08 18:55:57.959703: Pseudo dice [0.9753, 0.937, 0.9538, 0.8278] 
2023-10-08 18:55:57.963866: Epoch time: 117.0 s 
2023-10-08 18:55:59.357851:  
2023-10-08 18:55:59.361952: Epoch 316 
2023-10-08 18:55:59.365429: Current learning rate: 0.0071 
2023-10-08 18:57:52.051291: train_loss -0.7731 
2023-10-08 18:57:52.059052: val_loss -0.7424 
2023-10-08 18:57:52.062728: Pseudo dice [0.954, 0.9511, 0.9614, 0.7328] 
2023-10-08 18:57:52.066581: Epoch time: 112.7 s 
2023-10-08 18:57:53.458788:  
2023-10-08 18:57:53.463422: Epoch 317 
2023-10-08 18:57:53.467527: Current learning rate: 0.0071 
2023-10-08 18:59:51.676347: train_loss -0.7587 
2023-10-08 18:59:51.684073: val_loss -0.7555 
2023-10-08 18:59:51.688253: Pseudo dice [0.9626, 0.9556, 0.9344, 0.7849] 
2023-10-08 18:59:51.691971: Epoch time: 118.22 s 
2023-10-08 18:59:53.101318:  
2023-10-08 18:59:53.106091: Epoch 318 
2023-10-08 18:59:53.110528: Current learning rate: 0.00709 
2023-10-08 19:01:48.378598: train_loss -0.7564 
2023-10-08 19:01:48.386737: val_loss -0.7925 
2023-10-08 19:01:48.390957: Pseudo dice [0.9762, 0.9598, 0.9677, 0.8459] 
2023-10-08 19:01:48.395177: Epoch time: 115.28 s 
2023-10-08 19:01:50.066590:  
2023-10-08 19:01:50.070167: Epoch 319 
2023-10-08 19:01:50.073424: Current learning rate: 0.00708 
2023-10-08 19:03:48.147357: train_loss -0.7734 
2023-10-08 19:03:48.155295: val_loss -0.7738 
2023-10-08 19:03:48.159040: Pseudo dice [0.9624, 0.956, 0.936, 0.7662] 
2023-10-08 19:03:48.163098: Epoch time: 118.08 s 
2023-10-08 19:03:49.570073:  
2023-10-08 19:03:49.574544: Epoch 320 
2023-10-08 19:03:49.578893: Current learning rate: 0.00707 
2023-10-08 19:05:54.123415: train_loss -0.7738 
2023-10-08 19:05:54.131446: val_loss -0.7542 
2023-10-08 19:05:54.135288: Pseudo dice [0.9574, 0.9593, 0.9345, 0.7544] 
2023-10-08 19:05:54.139397: Epoch time: 124.56 s 
2023-10-08 19:05:55.542451:  
2023-10-08 19:05:55.546994: Epoch 321 
2023-10-08 19:05:55.551035: Current learning rate: 0.00706 
2023-10-08 19:07:51.572119: train_loss -0.7789 
2023-10-08 19:07:51.580541: val_loss -0.7928 
2023-10-08 19:07:51.584764: Pseudo dice [0.9718, 0.9449, 0.9537, 0.8131] 
2023-10-08 19:07:51.588877: Epoch time: 116.03 s 
2023-10-08 19:07:52.979851:  
2023-10-08 19:07:52.985299: Epoch 322 
2023-10-08 19:07:52.990253: Current learning rate: 0.00705 
2023-10-08 19:09:47.162949: train_loss -0.7833 
2023-10-08 19:09:47.170717: val_loss -0.7821 
2023-10-08 19:09:47.176560: Pseudo dice [0.9748, 0.9407, 0.9688, 0.8218] 
2023-10-08 19:09:47.180716: Epoch time: 114.19 s 
2023-10-08 19:09:48.637716:  
2023-10-08 19:09:48.642030: Epoch 323 
2023-10-08 19:09:48.646165: Current learning rate: 0.00704 
2023-10-08 19:11:48.948788: train_loss -0.7805 
2023-10-08 19:11:48.956131: val_loss -0.8361 
2023-10-08 19:11:48.960321: Pseudo dice [0.9686, 0.9611, 0.9525, 0.8391] 
2023-10-08 19:11:48.963482: Epoch time: 120.31 s 
2023-10-08 19:11:50.545432:  
2023-10-08 19:11:50.550734: Epoch 324 
2023-10-08 19:11:50.554916: Current learning rate: 0.00703 
2023-10-08 19:13:47.590101: train_loss -0.7566 
2023-10-08 19:13:47.597676: val_loss -0.7803 
2023-10-08 19:13:47.601321: Pseudo dice [0.9676, 0.9395, 0.952, 0.7729] 
2023-10-08 19:13:47.605449: Epoch time: 117.05 s 
2023-10-08 19:13:49.001059:  
2023-10-08 19:13:49.005346: Epoch 325 
2023-10-08 19:13:49.009313: Current learning rate: 0.00702 
2023-10-08 19:15:51.009940: train_loss -0.7748 
2023-10-08 19:15:51.017572: val_loss -0.8454 
2023-10-08 19:15:51.021402: Pseudo dice [0.9694, 0.9552, 0.9514, 0.8468] 
2023-10-08 19:15:51.025933: Epoch time: 122.01 s 
2023-10-08 19:15:52.444072:  
2023-10-08 19:15:52.452966: Epoch 326 
2023-10-08 19:15:52.458197: Current learning rate: 0.00701 
2023-10-08 19:17:50.246615: train_loss -0.7621 
2023-10-08 19:17:50.255427: val_loss -0.7745 
2023-10-08 19:17:50.259295: Pseudo dice [0.9667, 0.9416, 0.9399, 0.7872] 
2023-10-08 19:17:50.262790: Epoch time: 117.81 s 
2023-10-08 19:17:51.676892:  
2023-10-08 19:17:51.681535: Epoch 327 
2023-10-08 19:17:51.688475: Current learning rate: 0.007 
2023-10-08 19:19:46.338029: train_loss -0.7817 
2023-10-08 19:19:46.346718: val_loss -0.756 
2023-10-08 19:19:46.351225: Pseudo dice [0.9631, 0.9268, 0.953, 0.803] 
2023-10-08 19:19:46.360252: Epoch time: 114.67 s 
2023-10-08 19:19:47.756036:  
2023-10-08 19:19:47.760551: Epoch 328 
2023-10-08 19:19:47.764920: Current learning rate: 0.00699 
2023-10-08 19:21:40.245784: train_loss -0.7889 
2023-10-08 19:21:40.254115: val_loss -0.7897 
2023-10-08 19:21:40.257916: Pseudo dice [0.9513, 0.9337, 0.9367, 0.7836] 
2023-10-08 19:21:40.265693: Epoch time: 112.49 s 
2023-10-08 19:21:41.886587:  
2023-10-08 19:21:41.891075: Epoch 329 
2023-10-08 19:21:41.895699: Current learning rate: 0.00698 
2023-10-08 19:23:41.078360: train_loss -0.7679 
2023-10-08 19:23:41.086179: val_loss -0.7987 
2023-10-08 19:23:41.090530: Pseudo dice [0.9757, 0.9584, 0.9698, 0.7964] 
2023-10-08 19:23:41.094654: Epoch time: 119.19 s 
2023-10-08 19:23:42.473001:  
2023-10-08 19:23:42.478474: Epoch 330 
2023-10-08 19:23:42.483659: Current learning rate: 0.00697 
2023-10-08 19:25:38.498820: train_loss -0.7807 
2023-10-08 19:25:38.506572: val_loss -0.7571 
2023-10-08 19:25:38.510594: Pseudo dice [0.9625, 0.9138, 0.9515, 0.7365] 
2023-10-08 19:25:38.514104: Epoch time: 116.03 s 
2023-10-08 19:25:39.920295:  
2023-10-08 19:25:39.925051: Epoch 331 
2023-10-08 19:25:39.929822: Current learning rate: 0.00696 
2023-10-08 19:27:31.651060: train_loss -0.767 
2023-10-08 19:27:31.658988: val_loss -0.7936 
2023-10-08 19:27:31.663063: Pseudo dice [0.9628, 0.9554, 0.9338, 0.833] 
2023-10-08 19:27:31.667069: Epoch time: 111.73 s 
2023-10-08 19:27:33.078677:  
2023-10-08 19:27:33.083449: Epoch 332 
2023-10-08 19:27:33.087924: Current learning rate: 0.00696 
2023-10-08 19:29:29.415010: train_loss -0.7804 
2023-10-08 19:29:29.422571: val_loss -0.7968 
2023-10-08 19:29:29.426672: Pseudo dice [0.9721, 0.9595, 0.9658, 0.8203] 
2023-10-08 19:29:29.430686: Epoch time: 116.34 s 
2023-10-08 19:29:30.877405:  
2023-10-08 19:29:30.882206: Epoch 333 
2023-10-08 19:29:30.886195: Current learning rate: 0.00695 
2023-10-08 19:31:33.255191: train_loss -0.7835 
2023-10-08 19:31:33.263097: val_loss -0.7919 
2023-10-08 19:31:33.267442: Pseudo dice [0.9757, 0.9495, 0.9686, 0.8113] 
2023-10-08 19:31:33.271452: Epoch time: 122.38 s 
2023-10-08 19:31:34.696718:  
2023-10-08 19:31:34.701456: Epoch 334 
2023-10-08 19:31:34.705571: Current learning rate: 0.00694 
2023-10-08 19:33:36.349818: train_loss -0.7789 
2023-10-08 19:33:36.366386: val_loss -0.7865 
2023-10-08 19:33:36.376010: Pseudo dice [0.9626, 0.9561, 0.9432, 0.8279] 
2023-10-08 19:33:36.383484: Epoch time: 121.66 s 
2023-10-08 19:33:37.862431:  
2023-10-08 19:33:37.868400: Epoch 335 
2023-10-08 19:33:37.878807: Current learning rate: 0.00693 
2023-10-08 19:35:33.350337: train_loss -0.7599 
2023-10-08 19:35:33.358378: val_loss -0.7274 
2023-10-08 19:35:33.362407: Pseudo dice [0.959, 0.9199, 0.9078, 0.7757] 
2023-10-08 19:35:33.366414: Epoch time: 115.49 s 
2023-10-08 19:35:34.790141:  
2023-10-08 19:35:34.795282: Epoch 336 
2023-10-08 19:35:34.799018: Current learning rate: 0.00692 
2023-10-08 19:37:33.783668: train_loss -0.7696 
2023-10-08 19:37:33.791416: val_loss -0.7661 
2023-10-08 19:37:33.795691: Pseudo dice [0.9701, 0.912, 0.9501, 0.7815] 
2023-10-08 19:37:33.799372: Epoch time: 119.0 s 
2023-10-08 19:37:35.227689:  
2023-10-08 19:37:35.232147: Epoch 337 
2023-10-08 19:37:35.236679: Current learning rate: 0.00691 
2023-10-08 19:39:39.135059: train_loss -0.759 
2023-10-08 19:39:39.142570: val_loss -0.7827 
2023-10-08 19:39:39.146416: Pseudo dice [0.9732, 0.9519, 0.9697, 0.7971] 
2023-10-08 19:39:39.150253: Epoch time: 123.91 s 
2023-10-08 19:39:40.602251:  
2023-10-08 19:39:40.607111: Epoch 338 
2023-10-08 19:39:40.610859: Current learning rate: 0.0069 
2023-10-08 19:41:39.564015: train_loss -0.7578 
2023-10-08 19:41:39.572635: val_loss -0.7955 
2023-10-08 19:41:39.576466: Pseudo dice [0.9592, 0.9554, 0.9415, 0.8299] 
2023-10-08 19:41:39.581795: Epoch time: 118.97 s 
2023-10-08 19:41:40.989804:  
2023-10-08 19:41:40.994243: Epoch 339 
2023-10-08 19:41:40.998250: Current learning rate: 0.00689 
2023-10-08 19:43:40.332882: train_loss -0.7537 
2023-10-08 19:43:40.341207: val_loss -0.7787 
2023-10-08 19:43:40.345221: Pseudo dice [0.972, 0.9582, 0.9559, 0.8145] 
2023-10-08 19:43:40.349029: Epoch time: 119.35 s 
2023-10-08 19:43:41.943671:  
2023-10-08 19:43:41.948296: Epoch 340 
2023-10-08 19:43:41.957468: Current learning rate: 0.00688 
2023-10-08 19:45:40.270742: train_loss -0.7533 
2023-10-08 19:45:40.278629: val_loss -0.7796 
2023-10-08 19:45:40.282569: Pseudo dice [0.9594, 0.9596, 0.9296, 0.8211] 
2023-10-08 19:45:40.286564: Epoch time: 118.33 s 
2023-10-08 19:45:41.769860:  
2023-10-08 19:45:41.774089: Epoch 341 
2023-10-08 19:45:41.778240: Current learning rate: 0.00687 
2023-10-08 19:47:42.816523: train_loss -0.7793 
2023-10-08 19:47:42.824320: val_loss -0.7746 
2023-10-08 19:47:42.828526: Pseudo dice [0.9581, 0.9297, 0.9063, 0.8451] 
2023-10-08 19:47:42.832432: Epoch time: 121.05 s 
2023-10-08 19:47:44.251829:  
2023-10-08 19:47:44.257567: Epoch 342 
2023-10-08 19:47:44.263589: Current learning rate: 0.00686 
2023-10-08 19:49:41.492702: train_loss -0.7949 
2023-10-08 19:49:41.501008: val_loss -0.7879 
2023-10-08 19:49:41.504717: Pseudo dice [0.9483, 0.9409, 0.9318, 0.824] 
2023-10-08 19:49:41.508680: Epoch time: 117.24 s 
2023-10-08 19:49:42.980994:  
2023-10-08 19:49:42.985568: Epoch 343 
2023-10-08 19:49:42.989647: Current learning rate: 0.00685 
2023-10-08 19:51:38.960826: train_loss -0.7685 
2023-10-08 19:51:38.969374: val_loss -0.7409 
2023-10-08 19:51:38.972796: Pseudo dice [0.9592, 0.9185, 0.9274, 0.7932] 
2023-10-08 19:51:38.976328: Epoch time: 115.98 s 
2023-10-08 19:51:40.385097:  
2023-10-08 19:51:40.389902: Epoch 344 
2023-10-08 19:51:40.393934: Current learning rate: 0.00684 
2023-10-08 19:53:40.999219: train_loss -0.7752 
2023-10-08 19:53:41.007175: val_loss -0.8088 
2023-10-08 19:53:41.010768: Pseudo dice [0.9671, 0.9549, 0.9705, 0.8264] 
2023-10-08 19:53:41.014822: Epoch time: 120.62 s 
2023-10-08 19:53:42.635733:  
2023-10-08 19:53:42.641096: Epoch 345 
2023-10-08 19:53:42.645706: Current learning rate: 0.00683 
2023-10-08 19:55:43.258798: train_loss -0.7732 
2023-10-08 19:55:43.266261: val_loss -0.7822 
2023-10-08 19:55:43.269748: Pseudo dice [0.9689, 0.9469, 0.9522, 0.7816] 
2023-10-08 19:55:43.273292: Epoch time: 120.63 s 
2023-10-08 19:55:44.708039:  
2023-10-08 19:55:44.713201: Epoch 346 
2023-10-08 19:55:44.717697: Current learning rate: 0.00682 
2023-10-08 19:57:37.859154: train_loss -0.7812 
2023-10-08 19:57:37.867242: val_loss -0.7601 
2023-10-08 19:57:37.871406: Pseudo dice [0.9589, 0.9282, 0.9441, 0.7368] 
2023-10-08 19:57:37.875149: Epoch time: 113.15 s 
2023-10-08 19:57:39.306756:  
2023-10-08 19:57:39.313312: Epoch 347 
2023-10-08 19:57:39.317719: Current learning rate: 0.00681 
2023-10-08 19:59:36.689708: train_loss -0.7883 
2023-10-08 19:59:36.698134: val_loss -0.8065 
2023-10-08 19:59:36.701838: Pseudo dice [0.9613, 0.918, 0.9668, 0.8252] 
2023-10-08 19:59:36.705935: Epoch time: 117.38 s 
2023-10-08 19:59:38.146166:  
2023-10-08 19:59:38.150552: Epoch 348 
2023-10-08 19:59:38.154358: Current learning rate: 0.0068 
2023-10-08 20:01:35.477452: train_loss -0.777 
2023-10-08 20:01:35.485687: val_loss -0.8104 
2023-10-08 20:01:35.489373: Pseudo dice [0.9722, 0.9601, 0.9676, 0.8325] 
2023-10-08 20:01:35.493404: Epoch time: 117.33 s 
2023-10-08 20:01:36.912272:  
2023-10-08 20:01:36.917244: Epoch 349 
2023-10-08 20:01:36.921328: Current learning rate: 0.0068 
2023-10-08 20:03:38.106107: train_loss -0.7783 
2023-10-08 20:03:38.113772: val_loss -0.796 
2023-10-08 20:03:38.117362: Pseudo dice [0.9737, 0.9299, 0.9687, 0.8166] 
2023-10-08 20:03:38.121222: Epoch time: 121.2 s 
2023-10-08 20:03:40.483374:  
2023-10-08 20:03:40.487785: Epoch 350 
2023-10-08 20:03:40.492008: Current learning rate: 0.00679 
2023-10-08 20:05:43.119459: train_loss -0.7931 
2023-10-08 20:05:43.127460: val_loss -0.7754 
2023-10-08 20:05:43.131014: Pseudo dice [0.9653, 0.9598, 0.9099, 0.8212] 
2023-10-08 20:05:43.134791: Epoch time: 122.64 s 
2023-10-08 20:05:44.546332:  
2023-10-08 20:05:44.551724: Epoch 351 
2023-10-08 20:05:44.555865: Current learning rate: 0.00678 
2023-10-08 20:07:42.919803: train_loss -0.7772 
2023-10-08 20:07:42.926969: val_loss -0.7206 
2023-10-08 20:07:42.930629: Pseudo dice [0.9639, 0.9374, 0.925, 0.7997] 
2023-10-08 20:07:42.936098: Epoch time: 118.38 s 
2023-10-08 20:07:44.437070:  
2023-10-08 20:07:44.442018: Epoch 352 
2023-10-08 20:07:44.445919: Current learning rate: 0.00677 
2023-10-08 20:09:38.896895: train_loss -0.7684 
2023-10-08 20:09:38.906389: val_loss -0.8116 
2023-10-08 20:09:38.910349: Pseudo dice [0.9719, 0.9587, 0.9592, 0.832] 
2023-10-08 20:09:38.914349: Epoch time: 114.46 s 
2023-10-08 20:09:40.354561:  
2023-10-08 20:09:40.358581: Epoch 353 
2023-10-08 20:09:40.362051: Current learning rate: 0.00676 
2023-10-08 20:11:35.970147: train_loss -0.7926 
2023-10-08 20:11:35.977939: val_loss -0.7725 
2023-10-08 20:11:35.981680: Pseudo dice [0.9769, 0.9554, 0.9677, 0.8028] 
2023-10-08 20:11:35.985277: Epoch time: 115.62 s 
2023-10-08 20:11:37.417188:  
2023-10-08 20:11:37.421456: Epoch 354 
2023-10-08 20:11:37.426212: Current learning rate: 0.00675 
2023-10-08 20:13:36.045499: train_loss -0.7849 
2023-10-08 20:13:36.056493: val_loss -0.796 
2023-10-08 20:13:36.060425: Pseudo dice [0.9722, 0.9439, 0.9718, 0.8111] 
2023-10-08 20:13:36.063902: Epoch time: 118.63 s 
2023-10-08 20:13:37.687211:  
2023-10-08 20:13:37.691698: Epoch 355 
2023-10-08 20:13:37.696662: Current learning rate: 0.00674 
2023-10-08 20:15:36.477106: train_loss -0.7882 
2023-10-08 20:15:36.485081: val_loss -0.7916 
2023-10-08 20:15:36.489399: Pseudo dice [0.9723, 0.9583, 0.9608, 0.82] 
2023-10-08 20:15:36.493250: Epoch time: 118.79 s 
2023-10-08 20:15:37.926170:  
2023-10-08 20:15:37.931495: Epoch 356 
2023-10-08 20:15:37.936154: Current learning rate: 0.00673 
2023-10-08 20:17:33.087115: train_loss -0.7798 
2023-10-08 20:17:33.100451: val_loss -0.8053 
2023-10-08 20:17:33.104324: Pseudo dice [0.9708, 0.9637, 0.9639, 0.8329] 
2023-10-08 20:17:33.108204: Epoch time: 115.16 s 
2023-10-08 20:17:34.507067:  
2023-10-08 20:17:34.511374: Epoch 357 
2023-10-08 20:17:34.515333: Current learning rate: 0.00672 
2023-10-08 20:19:32.191388: train_loss -0.7782 
2023-10-08 20:19:32.199053: val_loss -0.7381 
2023-10-08 20:19:32.202935: Pseudo dice [0.9592, 0.9051, 0.9335, 0.78] 
2023-10-08 20:19:32.206772: Epoch time: 117.69 s 
2023-10-08 20:19:33.621500:  
2023-10-08 20:19:33.627297: Epoch 358 
2023-10-08 20:19:33.631349: Current learning rate: 0.00671 
2023-10-08 20:21:35.398335: train_loss -0.7482 
2023-10-08 20:21:35.406626: val_loss -0.7686 
2023-10-08 20:21:35.411993: Pseudo dice [0.9708, 0.9592, 0.9579, 0.8094] 
2023-10-08 20:21:35.417154: Epoch time: 121.78 s 
2023-10-08 20:21:36.877969:  
2023-10-08 20:21:36.882587: Epoch 359 
2023-10-08 20:21:36.887185: Current learning rate: 0.0067 
2023-10-08 20:23:31.501642: train_loss -0.7468 
2023-10-08 20:23:31.510545: val_loss -0.6819 
2023-10-08 20:23:31.515600: Pseudo dice [0.9449, 0.926, 0.8303, 0.7936] 
2023-10-08 20:23:31.519587: Epoch time: 114.63 s 
2023-10-08 20:23:32.972485:  
2023-10-08 20:23:32.977366: Epoch 360 
2023-10-08 20:23:32.981628: Current learning rate: 0.00669 
2023-10-08 20:25:30.231677: train_loss -0.785 
2023-10-08 20:25:30.240589: val_loss -0.7935 
2023-10-08 20:25:30.245044: Pseudo dice [0.9703, 0.9552, 0.9569, 0.8473] 
2023-10-08 20:25:30.249246: Epoch time: 117.26 s 
2023-10-08 20:25:31.887798:  
2023-10-08 20:25:31.892254: Epoch 361 
2023-10-08 20:25:31.896121: Current learning rate: 0.00668 
2023-10-08 20:27:26.868335: train_loss -0.8005 
2023-10-08 20:27:26.876951: val_loss -0.7822 
2023-10-08 20:27:26.881085: Pseudo dice [0.9724, 0.9564, 0.9528, 0.8362] 
2023-10-08 20:27:26.885208: Epoch time: 114.98 s 
2023-10-08 20:27:28.305394:  
2023-10-08 20:27:28.310426: Epoch 362 
2023-10-08 20:27:28.314848: Current learning rate: 0.00667 
2023-10-08 20:29:26.358810: train_loss -0.784 
2023-10-08 20:29:26.367754: val_loss -0.7576 
2023-10-08 20:29:26.371712: Pseudo dice [0.9716, 0.9595, 0.9356, 0.8277] 
2023-10-08 20:29:26.375451: Epoch time: 118.06 s 
2023-10-08 20:29:27.813042:  
2023-10-08 20:29:27.817687: Epoch 363 
2023-10-08 20:29:27.822051: Current learning rate: 0.00666 
2023-10-08 20:31:24.799774: train_loss -0.8002 
2023-10-08 20:31:24.808168: val_loss -0.7943 
2023-10-08 20:31:24.811510: Pseudo dice [0.9748, 0.9552, 0.9609, 0.8386] 
2023-10-08 20:31:24.815138: Epoch time: 116.99 s 
2023-10-08 20:31:26.308938:  
2023-10-08 20:31:26.313187: Epoch 364 
2023-10-08 20:31:26.317260: Current learning rate: 0.00665 
2023-10-08 20:33:21.913406: train_loss -0.7859 
2023-10-08 20:33:21.920766: val_loss -0.7786 
2023-10-08 20:33:21.924479: Pseudo dice [0.969, 0.9441, 0.9637, 0.8254] 
2023-10-08 20:33:21.928260: Epoch time: 115.61 s 
2023-10-08 20:33:23.362247:  
2023-10-08 20:33:23.366674: Epoch 365 
2023-10-08 20:33:23.370889: Current learning rate: 0.00665 
2023-10-08 20:35:14.906821: train_loss -0.7874 
2023-10-08 20:35:14.917331: val_loss -0.7839 
2023-10-08 20:35:14.921115: Pseudo dice [0.9734, 0.9269, 0.9621, 0.7764] 
2023-10-08 20:35:14.925140: Epoch time: 111.55 s 
2023-10-08 20:35:16.613782:  
2023-10-08 20:35:16.618648: Epoch 366 
2023-10-08 20:35:16.622782: Current learning rate: 0.00664 
2023-10-08 20:37:14.244954: train_loss -0.7802 
2023-10-08 20:37:14.254403: val_loss -0.771 
2023-10-08 20:37:14.258387: Pseudo dice [0.9643, 0.9334, 0.949, 0.8249] 
2023-10-08 20:37:14.261895: Epoch time: 117.63 s 
2023-10-08 20:37:15.757166:  
2023-10-08 20:37:15.761895: Epoch 367 
2023-10-08 20:37:15.765625: Current learning rate: 0.00663 
2023-10-08 20:39:14.814299: train_loss -0.7769 
2023-10-08 20:39:14.822548: val_loss -0.7814 
2023-10-08 20:39:14.827272: Pseudo dice [0.975, 0.96, 0.9578, 0.8313] 
2023-10-08 20:39:14.831167: Epoch time: 119.06 s 
2023-10-08 20:39:16.308757:  
2023-10-08 20:39:16.313684: Epoch 368 
2023-10-08 20:39:16.318843: Current learning rate: 0.00662 
2023-10-08 20:41:14.862529: train_loss -0.7898 
2023-10-08 20:41:14.869944: val_loss -0.8139 
2023-10-08 20:41:14.873722: Pseudo dice [0.9726, 0.9574, 0.9706, 0.843] 
2023-10-08 20:41:14.880453: Epoch time: 118.56 s 
2023-10-08 20:41:14.884348: Yayy! New best EMA pseudo Dice: 0.9216 
2023-10-08 20:41:17.047787:  
2023-10-08 20:41:17.052271: Epoch 369 
2023-10-08 20:41:17.058903: Current learning rate: 0.00661 
2023-10-08 20:43:17.253380: train_loss -0.8014 
2023-10-08 20:43:17.261169: val_loss -0.7933 
2023-10-08 20:43:17.264916: Pseudo dice [0.9588, 0.9306, 0.9628, 0.8262] 
2023-10-08 20:43:17.269019: Epoch time: 120.21 s 
2023-10-08 20:43:18.704343:  
2023-10-08 20:43:18.709230: Epoch 370 
2023-10-08 20:43:18.713289: Current learning rate: 0.0066 
2023-10-08 20:45:14.889370: train_loss -0.7846 
2023-10-08 20:45:14.897006: val_loss -0.8134 
2023-10-08 20:45:14.900995: Pseudo dice [0.9722, 0.9546, 0.9588, 0.8256] 
2023-10-08 20:45:14.904557: Epoch time: 116.19 s 
2023-10-08 20:45:14.907958: Yayy! New best EMA pseudo Dice: 0.922 
2023-10-08 20:45:17.207943:  
2023-10-08 20:45:17.212520: Epoch 371 
2023-10-08 20:45:17.216611: Current learning rate: 0.00659 
2023-10-08 20:47:13.630590: train_loss -0.7613 
2023-10-08 20:47:13.638325: val_loss -0.7517 
2023-10-08 20:47:13.642131: Pseudo dice [0.954, 0.9556, 0.9335, 0.8565] 
2023-10-08 20:47:13.645909: Epoch time: 116.43 s 
2023-10-08 20:47:13.649714: Yayy! New best EMA pseudo Dice: 0.9223 
2023-10-08 20:47:15.845020:  
2023-10-08 20:47:15.849642: Epoch 372 
2023-10-08 20:47:15.853775: Current learning rate: 0.00658 
2023-10-08 20:49:13.567146: train_loss -0.7639 
2023-10-08 20:49:13.575087: val_loss -0.7274 
2023-10-08 20:49:13.578645: Pseudo dice [0.9412, 0.9276, 0.9403, 0.7859] 
2023-10-08 20:49:13.582143: Epoch time: 117.72 s 
2023-10-08 20:49:15.009285:  
2023-10-08 20:49:15.013521: Epoch 373 
2023-10-08 20:49:15.017719: Current learning rate: 0.00657 
2023-10-08 20:51:15.387018: train_loss -0.7468 
2023-10-08 20:51:15.394509: val_loss -0.8009 
2023-10-08 20:51:15.398356: Pseudo dice [0.9737, 0.953, 0.9625, 0.7979] 
2023-10-08 20:51:15.402558: Epoch time: 120.38 s 
2023-10-08 20:51:16.840286:  
2023-10-08 20:51:16.844543: Epoch 374 
2023-10-08 20:51:16.848521: Current learning rate: 0.00656 
2023-10-08 20:53:15.172290: train_loss -0.7703 
2023-10-08 20:53:15.180238: val_loss -0.8074 
2023-10-08 20:53:15.184350: Pseudo dice [0.9694, 0.95, 0.9557, 0.8279] 
2023-10-08 20:53:15.188278: Epoch time: 118.34 s 
2023-10-08 20:53:16.825420:  
2023-10-08 20:53:16.830745: Epoch 375 
2023-10-08 20:53:16.835129: Current learning rate: 0.00655 
2023-10-08 20:55:11.221091: train_loss -0.7634 
2023-10-08 20:55:11.229232: val_loss -0.7602 
2023-10-08 20:55:11.233020: Pseudo dice [0.9672, 0.9539, 0.9437, 0.8123] 
2023-10-08 20:55:11.237163: Epoch time: 114.4 s 
2023-10-08 20:55:12.692256:  
2023-10-08 20:55:12.696723: Epoch 376 
2023-10-08 20:55:12.700715: Current learning rate: 0.00654 
2023-10-08 20:57:04.716313: train_loss -0.7688 
2023-10-08 20:57:04.724721: val_loss -0.7501 
2023-10-08 20:57:04.729213: Pseudo dice [0.9693, 0.9534, 0.9412, 0.8246] 
2023-10-08 20:57:04.733154: Epoch time: 112.03 s 
2023-10-08 20:57:06.170053:  
2023-10-08 20:57:06.175762: Epoch 377 
2023-10-08 20:57:06.181159: Current learning rate: 0.00653 
2023-10-08 20:59:02.701261: train_loss -0.776 
2023-10-08 20:59:02.709624: val_loss -0.8067 
2023-10-08 20:59:02.714355: Pseudo dice [0.9767, 0.9569, 0.9611, 0.8458] 
2023-10-08 20:59:02.718208: Epoch time: 116.53 s 
2023-10-08 20:59:04.120892:  
2023-10-08 20:59:04.125296: Epoch 378 
2023-10-08 20:59:04.130266: Current learning rate: 0.00652 
2023-10-08 21:01:05.923365: train_loss -0.7881 
2023-10-08 21:01:05.931701: val_loss -0.8016 
2023-10-08 21:01:05.935731: Pseudo dice [0.9647, 0.9294, 0.9711, 0.8644] 
2023-10-08 21:01:05.940354: Epoch time: 121.81 s 
2023-10-08 21:01:05.944441: Yayy! New best EMA pseudo Dice: 0.9232 
2023-10-08 21:01:08.210268:  
2023-10-08 21:01:08.215738: Epoch 379 
2023-10-08 21:01:08.219626: Current learning rate: 0.00651 
2023-10-08 21:03:09.045729: train_loss -0.7942 
2023-10-08 21:03:09.053232: val_loss -0.8038 
2023-10-08 21:03:09.057231: Pseudo dice [0.9767, 0.9427, 0.9608, 0.8254] 
2023-10-08 21:03:09.061401: Epoch time: 120.84 s 
2023-10-08 21:03:09.065223: Yayy! New best EMA pseudo Dice: 0.9235 
2023-10-08 21:03:11.371077:  
2023-10-08 21:03:11.375695: Epoch 380 
2023-10-08 21:03:11.380582: Current learning rate: 0.0065 
2023-10-08 21:05:09.033792: train_loss -0.7792 
2023-10-08 21:05:09.042332: val_loss -0.7731 
2023-10-08 21:05:09.046648: Pseudo dice [0.9744, 0.9601, 0.9567, 0.8145] 
2023-10-08 21:05:09.050368: Epoch time: 117.67 s 
2023-10-08 21:05:09.054387: Yayy! New best EMA pseudo Dice: 0.9238 
2023-10-08 21:05:11.208001:  
2023-10-08 21:05:11.212785: Epoch 381 
2023-10-08 21:05:11.217144: Current learning rate: 0.00649 
2023-10-08 21:07:09.802366: train_loss -0.7639 
2023-10-08 21:07:09.809751: val_loss -0.8177 
2023-10-08 21:07:09.813631: Pseudo dice [0.9801, 0.9555, 0.9703, 0.843] 
2023-10-08 21:07:09.817622: Epoch time: 118.6 s 
2023-10-08 21:07:09.821617: Yayy! New best EMA pseudo Dice: 0.9251 
2023-10-08 21:07:11.981621:  
2023-10-08 21:07:11.990741: Epoch 382 
2023-10-08 21:07:11.995297: Current learning rate: 0.00648 
2023-10-08 21:09:03.945400: train_loss -0.7866 
2023-10-08 21:09:03.953372: val_loss -0.7791 
2023-10-08 21:09:03.957534: Pseudo dice [0.9602, 0.9528, 0.9039, 0.8294] 
2023-10-08 21:09:03.961195: Epoch time: 111.97 s 
2023-10-08 21:09:05.410892:  
2023-10-08 21:09:05.416283: Epoch 383 
2023-10-08 21:09:05.421912: Current learning rate: 0.00648 
2023-10-08 21:11:02.837774: train_loss -0.7863 
2023-10-08 21:11:02.847190: val_loss -0.8031 
2023-10-08 21:11:02.851023: Pseudo dice [0.9728, 0.9545, 0.9663, 0.8135] 
2023-10-08 21:11:02.854733: Epoch time: 117.43 s 
2023-10-08 21:11:04.339327:  
2023-10-08 21:11:04.344084: Epoch 384 
2023-10-08 21:11:04.348413: Current learning rate: 0.00647 
2023-10-08 21:13:00.386752: train_loss -0.7724 
2023-10-08 21:13:00.394768: val_loss -0.763 
2023-10-08 21:13:00.398699: Pseudo dice [0.9706, 0.9496, 0.9583, 0.7589] 
2023-10-08 21:13:00.402641: Epoch time: 116.05 s 
2023-10-08 21:13:02.122402:  
2023-10-08 21:13:02.126743: Epoch 385 
2023-10-08 21:13:02.130218: Current learning rate: 0.00646 
2023-10-08 21:14:56.676366: train_loss -0.7892 
2023-10-08 21:14:56.685226: val_loss -0.7916 
2023-10-08 21:14:56.689551: Pseudo dice [0.9734, 0.959, 0.9526, 0.8062] 
2023-10-08 21:14:56.693867: Epoch time: 114.56 s 
2023-10-08 21:14:58.156526:  
2023-10-08 21:14:58.160813: Epoch 386 
2023-10-08 21:14:58.164980: Current learning rate: 0.00645 
2023-10-08 21:16:55.336038: train_loss -0.7615 
2023-10-08 21:16:55.343616: val_loss -0.7606 
2023-10-08 21:16:55.351226: Pseudo dice [0.9747, 0.9604, 0.9418, 0.792] 
2023-10-08 21:16:55.354990: Epoch time: 117.18 s 
2023-10-08 21:16:56.833901:  
2023-10-08 21:16:56.838121: Epoch 387 
2023-10-08 21:16:56.842144: Current learning rate: 0.00644 
2023-10-08 21:18:54.112915: train_loss -0.7675 
2023-10-08 21:18:54.120955: val_loss -0.7996 
2023-10-08 21:18:54.124979: Pseudo dice [0.9699, 0.9451, 0.9655, 0.7962] 
2023-10-08 21:18:54.129243: Epoch time: 117.28 s 
2023-10-08 21:18:55.572747:  
2023-10-08 21:18:55.577551: Epoch 388 
2023-10-08 21:18:55.581706: Current learning rate: 0.00643 
2023-10-08 21:20:50.813550: train_loss -0.7768 
2023-10-08 21:20:50.821661: val_loss -0.7779 
2023-10-08 21:20:50.825682: Pseudo dice [0.9711, 0.946, 0.9487, 0.8447] 
2023-10-08 21:20:50.829798: Epoch time: 115.24 s 
2023-10-08 21:20:52.265262:  
2023-10-08 21:20:52.269797: Epoch 389 
2023-10-08 21:20:52.273064: Current learning rate: 0.00642 
2023-10-08 21:22:48.074287: train_loss -0.7785 
2023-10-08 21:22:48.081926: val_loss -0.7686 
2023-10-08 21:22:48.089411: Pseudo dice [0.9606, 0.9343, 0.9509, 0.8366] 
2023-10-08 21:22:48.093639: Epoch time: 115.81 s 
2023-10-08 21:22:49.732431:  
2023-10-08 21:22:49.737572: Epoch 390 
2023-10-08 21:22:49.742123: Current learning rate: 0.00641 
2023-10-08 21:24:45.434030: train_loss -0.7666 
2023-10-08 21:24:45.441453: val_loss -0.7564 
2023-10-08 21:24:45.445323: Pseudo dice [0.9629, 0.9421, 0.9503, 0.7493] 
2023-10-08 21:24:45.449058: Epoch time: 115.71 s 
2023-10-08 21:24:46.974827:  
2023-10-08 21:24:46.980205: Epoch 391 
2023-10-08 21:24:46.984451: Current learning rate: 0.0064 
2023-10-08 21:26:45.310198: train_loss -0.7411 
2023-10-08 21:26:45.317701: val_loss -0.7663 
2023-10-08 21:26:45.321572: Pseudo dice [0.9663, 0.9571, 0.9553, 0.8254] 
2023-10-08 21:26:45.325670: Epoch time: 118.34 s 
2023-10-08 21:26:46.808755:  
2023-10-08 21:26:46.813369: Epoch 392 
2023-10-08 21:26:46.818249: Current learning rate: 0.00639 
2023-10-08 21:28:43.594055: train_loss -0.7643 
2023-10-08 21:28:43.601632: val_loss -0.7709 
2023-10-08 21:28:43.605753: Pseudo dice [0.9617, 0.9257, 0.9543, 0.8113] 
2023-10-08 21:28:43.609405: Epoch time: 116.79 s 
2023-10-08 21:28:45.071307:  
2023-10-08 21:28:45.076759: Epoch 393 
2023-10-08 21:28:45.081195: Current learning rate: 0.00638 
2023-10-08 21:30:41.080326: train_loss -0.7802 
2023-10-08 21:30:41.088014: val_loss -0.7609 
2023-10-08 21:30:41.093449: Pseudo dice [0.9687, 0.9517, 0.9634, 0.7755] 
2023-10-08 21:30:41.097518: Epoch time: 116.01 s 
2023-10-08 21:30:42.583353:  
2023-10-08 21:30:42.588840: Epoch 394 
2023-10-08 21:30:42.593727: Current learning rate: 0.00637 
2023-10-08 21:32:41.591445: train_loss -0.7911 
2023-10-08 21:32:41.599844: val_loss -0.8105 
2023-10-08 21:32:41.603689: Pseudo dice [0.9743, 0.9591, 0.9623, 0.8292] 
2023-10-08 21:32:41.607464: Epoch time: 119.01 s 
2023-10-08 21:32:43.263877:  
2023-10-08 21:32:43.268353: Epoch 395 
2023-10-08 21:32:43.272335: Current learning rate: 0.00636 
2023-10-08 21:34:39.600864: train_loss -0.7782 
2023-10-08 21:34:39.608341: val_loss -0.7898 
2023-10-08 21:34:39.611582: Pseudo dice [0.9605, 0.923, 0.9655, 0.8378] 
2023-10-08 21:34:39.615131: Epoch time: 116.34 s 
2023-10-08 21:34:41.066571:  
2023-10-08 21:34:41.073642: Epoch 396 
2023-10-08 21:34:41.077888: Current learning rate: 0.00635 
2023-10-08 21:36:41.829876: train_loss -0.7699 
2023-10-08 21:36:41.837972: val_loss -0.7735 
2023-10-08 21:36:41.842033: Pseudo dice [0.9707, 0.9516, 0.9652, 0.798] 
2023-10-08 21:36:41.845873: Epoch time: 120.77 s 
2023-10-08 21:36:43.331293:  
2023-10-08 21:36:43.335505: Epoch 397 
2023-10-08 21:36:43.339344: Current learning rate: 0.00634 
2023-10-08 21:38:44.195572: train_loss -0.7633 
2023-10-08 21:38:44.203622: val_loss -0.7748 
2023-10-08 21:38:44.209522: Pseudo dice [0.9743, 0.9507, 0.9581, 0.7979] 
2023-10-08 21:38:44.214352: Epoch time: 120.87 s 
2023-10-08 21:38:45.671793:  
2023-10-08 21:38:45.677439: Epoch 398 
2023-10-08 21:38:45.681408: Current learning rate: 0.00633 
2023-10-08 21:40:46.078910: train_loss -0.7696 
2023-10-08 21:40:46.086917: val_loss -0.7665 
2023-10-08 21:40:46.090569: Pseudo dice [0.9572, 0.915, 0.9426, 0.815] 
2023-10-08 21:40:46.094226: Epoch time: 120.41 s 
2023-10-08 21:40:47.565632:  
2023-10-08 21:40:47.570162: Epoch 399 
2023-10-08 21:40:47.573730: Current learning rate: 0.00632 
2023-10-08 21:42:51.750255: train_loss -0.7716 
2023-10-08 21:42:51.757750: val_loss -0.7498 
2023-10-08 21:42:51.762568: Pseudo dice [0.9551, 0.9101, 0.9393, 0.8085] 
2023-10-08 21:42:51.766769: Epoch time: 124.19 s 
2023-10-08 21:42:54.120494:  
2023-10-08 21:42:54.124917: Epoch 400 
2023-10-08 21:42:54.129301: Current learning rate: 0.00631 
2023-10-08 21:44:50.825808: train_loss -0.7744 
2023-10-08 21:44:50.833316: val_loss -0.7355 
2023-10-08 21:44:50.836856: Pseudo dice [0.9701, 0.9234, 0.9439, 0.8184] 
2023-10-08 21:44:50.840785: Epoch time: 116.71 s 
2023-10-08 21:44:52.321819:  
2023-10-08 21:44:52.326761: Epoch 401 
2023-10-08 21:44:52.331366: Current learning rate: 0.0063 
2023-10-08 21:46:51.601180: train_loss -0.7835 
2023-10-08 21:46:51.608524: val_loss -0.7862 
2023-10-08 21:46:51.612364: Pseudo dice [0.9716, 0.9593, 0.9549, 0.838] 
2023-10-08 21:46:51.615948: Epoch time: 119.28 s 
2023-10-08 21:46:53.121689:  
2023-10-08 21:46:53.125866: Epoch 402 
2023-10-08 21:46:53.129798: Current learning rate: 0.0063 
2023-10-08 21:48:43.453225: train_loss -0.8009 
2023-10-08 21:48:43.461172: val_loss -0.8112 
2023-10-08 21:48:43.464859: Pseudo dice [0.9739, 0.9573, 0.962, 0.8542] 
2023-10-08 21:48:43.468967: Epoch time: 110.33 s 
2023-10-08 21:48:44.932253:  
2023-10-08 21:48:44.938550: Epoch 403 
2023-10-08 21:48:44.942737: Current learning rate: 0.00629 
2023-10-08 21:50:36.899525: train_loss -0.7797 
2023-10-08 21:50:36.907476: val_loss -0.7826 
2023-10-08 21:50:36.911655: Pseudo dice [0.9669, 0.9453, 0.9468, 0.805] 
2023-10-08 21:50:36.915240: Epoch time: 111.97 s 
2023-10-08 21:50:38.374304:  
2023-10-08 21:50:38.378087: Epoch 404 
2023-10-08 21:50:38.381407: Current learning rate: 0.00628 
2023-10-08 21:52:37.137897: train_loss -0.77 
2023-10-08 21:52:37.145772: val_loss -0.8042 
2023-10-08 21:52:37.149707: Pseudo dice [0.967, 0.9636, 0.9407, 0.8171] 
2023-10-08 21:52:37.153562: Epoch time: 118.77 s 
2023-10-08 21:52:38.856048:  
2023-10-08 21:52:38.860501: Epoch 405 
2023-10-08 21:52:38.864405: Current learning rate: 0.00627 
2023-10-08 21:54:37.328111: train_loss -0.7773 
2023-10-08 21:54:37.335986: val_loss -0.8074 
2023-10-08 21:54:37.339255: Pseudo dice [0.9709, 0.9561, 0.9537, 0.8342] 
2023-10-08 21:54:37.342714: Epoch time: 118.48 s 
2023-10-08 21:54:38.836812:  
2023-10-08 21:54:38.841308: Epoch 406 
2023-10-08 21:54:38.845103: Current learning rate: 0.00626 
2023-10-08 21:56:35.477611: train_loss -0.7911 
2023-10-08 21:56:35.485234: val_loss -0.7914 
2023-10-08 21:56:35.489230: Pseudo dice [0.9719, 0.9624, 0.9516, 0.8403] 
2023-10-08 21:56:35.493092: Epoch time: 116.64 s 
2023-10-08 21:56:36.936967:  
2023-10-08 21:56:36.941901: Epoch 407 
2023-10-08 21:56:36.946069: Current learning rate: 0.00625 
2023-10-08 21:58:35.082226: train_loss -0.8051 
2023-10-08 21:58:35.089424: val_loss -0.7879 
2023-10-08 21:58:35.093860: Pseudo dice [0.9744, 0.9428, 0.9697, 0.8161] 
2023-10-08 21:58:35.097821: Epoch time: 118.15 s 
2023-10-08 21:58:36.556231:  
2023-10-08 21:58:36.560596: Epoch 408 
2023-10-08 21:58:36.564415: Current learning rate: 0.00624 
2023-10-08 22:00:37.210340: train_loss -0.8052 
2023-10-08 22:00:37.218464: val_loss -0.8155 
2023-10-08 22:00:37.222405: Pseudo dice [0.9761, 0.9531, 0.9794, 0.841] 
2023-10-08 22:00:37.226041: Epoch time: 120.66 s 
2023-10-08 22:00:38.697270:  
2023-10-08 22:00:38.702383: Epoch 409 
2023-10-08 22:00:38.706030: Current learning rate: 0.00623 
2023-10-08 22:02:36.661004: train_loss -0.8016 
2023-10-08 22:02:36.671104: val_loss -0.8027 
2023-10-08 22:02:36.675580: Pseudo dice [0.979, 0.9548, 0.9748, 0.8503] 
2023-10-08 22:02:36.679554: Epoch time: 117.97 s 
2023-10-08 22:02:36.683369: Yayy! New best EMA pseudo Dice: 0.9256 
2023-10-08 22:02:39.063394:  
2023-10-08 22:02:39.067932: Epoch 410 
2023-10-08 22:02:39.077125: Current learning rate: 0.00622 
2023-10-08 22:04:34.708562: train_loss -0.7963 
2023-10-08 22:04:34.716559: val_loss -0.7895 
2023-10-08 22:04:34.720305: Pseudo dice [0.9743, 0.961, 0.9717, 0.8355] 
2023-10-08 22:04:34.724189: Epoch time: 115.65 s 
2023-10-08 22:04:34.727932: Yayy! New best EMA pseudo Dice: 0.9266 
2023-10-08 22:04:36.863577:  
2023-10-08 22:04:36.869176: Epoch 411 
2023-10-08 22:04:36.873433: Current learning rate: 0.00621 
2023-10-08 22:06:32.905740: train_loss -0.7752 
2023-10-08 22:06:32.914545: val_loss -0.7737 
2023-10-08 22:06:32.918770: Pseudo dice [0.9758, 0.9349, 0.9534, 0.8109] 
2023-10-08 22:06:32.922694: Epoch time: 116.05 s 
2023-10-08 22:06:34.285867:  
2023-10-08 22:06:34.292244: Epoch 412 
2023-10-08 22:06:34.297454: Current learning rate: 0.0062 
2023-10-08 22:08:31.808159: train_loss -0.7747 
2023-10-08 22:08:31.816814: val_loss -0.7806 
2023-10-08 22:08:31.820966: Pseudo dice [0.9709, 0.9391, 0.9336, 0.8281] 
2023-10-08 22:08:31.825336: Epoch time: 117.53 s 
2023-10-08 22:08:33.173321:  
2023-10-08 22:08:33.177599: Epoch 413 
2023-10-08 22:08:33.181736: Current learning rate: 0.00619 
2023-10-08 22:10:30.649716: train_loss -0.797 
2023-10-08 22:10:30.658251: val_loss -0.7544 
2023-10-08 22:10:30.662245: Pseudo dice [0.9742, 0.9323, 0.9504, 0.8592] 
2023-10-08 22:10:30.666067: Epoch time: 117.48 s 
2023-10-08 22:10:32.025666:  
2023-10-08 22:10:32.031728: Epoch 414 
2023-10-08 22:10:32.035935: Current learning rate: 0.00618 
2023-10-08 22:12:25.999832: train_loss -0.7652 
2023-10-08 22:12:26.007349: val_loss -0.7715 
2023-10-08 22:12:26.011424: Pseudo dice [0.9662, 0.9526, 0.9338, 0.7508] 
2023-10-08 22:12:26.015389: Epoch time: 113.98 s 
2023-10-08 22:12:27.369669:  
2023-10-08 22:12:27.375409: Epoch 415 
2023-10-08 22:12:27.379968: Current learning rate: 0.00617 
2023-10-08 22:14:25.969232: train_loss -0.7811 
2023-10-08 22:14:25.977484: val_loss -0.8007 
2023-10-08 22:14:25.983021: Pseudo dice [0.9672, 0.9521, 0.9558, 0.819] 
2023-10-08 22:14:25.986771: Epoch time: 118.6 s 
2023-10-08 22:14:27.573719:  
2023-10-08 22:14:27.578162: Epoch 416 
2023-10-08 22:14:27.581898: Current learning rate: 0.00616 
2023-10-08 22:16:24.011472: train_loss -0.7878 
2023-10-08 22:16:24.019508: val_loss -0.8009 
2023-10-08 22:16:24.023426: Pseudo dice [0.9749, 0.948, 0.9528, 0.8165] 
2023-10-08 22:16:24.027215: Epoch time: 116.44 s 
2023-10-08 22:16:25.377054:  
2023-10-08 22:16:25.381789: Epoch 417 
2023-10-08 22:16:25.385908: Current learning rate: 0.00615 
2023-10-08 22:18:22.749556: train_loss -0.7478 
2023-10-08 22:18:22.758500: val_loss -0.8078 
2023-10-08 22:18:22.762280: Pseudo dice [0.9725, 0.9589, 0.9643, 0.8293] 
2023-10-08 22:18:22.766590: Epoch time: 117.38 s 
2023-10-08 22:18:24.124958:  
2023-10-08 22:18:24.129588: Epoch 418 
2023-10-08 22:18:24.133867: Current learning rate: 0.00614 
2023-10-08 22:20:26.276829: train_loss -0.7843 
2023-10-08 22:20:26.284665: val_loss -0.7792 
2023-10-08 22:20:26.288872: Pseudo dice [0.973, 0.9471, 0.9603, 0.7871] 
2023-10-08 22:20:26.292875: Epoch time: 122.16 s 
2023-10-08 22:20:27.677812:  
2023-10-08 22:20:27.683239: Epoch 419 
2023-10-08 22:20:27.689955: Current learning rate: 0.00613 
2023-10-08 22:22:21.451242: train_loss -0.7634 
2023-10-08 22:22:21.458438: val_loss -0.7731 
2023-10-08 22:22:21.461837: Pseudo dice [0.9673, 0.9568, 0.971, 0.7809] 
2023-10-08 22:22:21.465384: Epoch time: 113.78 s 
2023-10-08 22:22:22.887437:  
2023-10-08 22:22:22.892921: Epoch 420 
2023-10-08 22:22:22.897582: Current learning rate: 0.00612 
2023-10-08 22:24:19.922871: train_loss -0.7908 
2023-10-08 22:24:19.931171: val_loss -0.7792 
2023-10-08 22:24:19.935947: Pseudo dice [0.9728, 0.9558, 0.9524, 0.8449] 
2023-10-08 22:24:19.940048: Epoch time: 117.04 s 
2023-10-08 22:24:21.478518:  
2023-10-08 22:24:21.482798: Epoch 421 
2023-10-08 22:24:21.486943: Current learning rate: 0.00612 
2023-10-08 22:26:18.142786: train_loss -0.7899 
2023-10-08 22:26:18.150261: val_loss -0.7899 
2023-10-08 22:26:18.153871: Pseudo dice [0.9545, 0.9467, 0.9116, 0.8366] 
2023-10-08 22:26:18.159997: Epoch time: 116.67 s 
2023-10-08 22:26:19.495724:  
2023-10-08 22:26:19.500039: Epoch 422 
2023-10-08 22:26:19.503758: Current learning rate: 0.00611 
2023-10-08 22:28:15.604023: train_loss -0.7934 
2023-10-08 22:28:15.612283: val_loss -0.8271 
2023-10-08 22:28:15.616433: Pseudo dice [0.9721, 0.9568, 0.9665, 0.8558] 
2023-10-08 22:28:15.620238: Epoch time: 116.11 s 
2023-10-08 22:28:17.009599:  
2023-10-08 22:28:17.016038: Epoch 423 
2023-10-08 22:28:17.020568: Current learning rate: 0.0061 
2023-10-08 22:30:13.365900: train_loss -0.794 
2023-10-08 22:30:13.373554: val_loss -0.7659 
2023-10-08 22:30:13.377361: Pseudo dice [0.9773, 0.9457, 0.9617, 0.8005] 
2023-10-08 22:30:13.381266: Epoch time: 116.36 s 
2023-10-08 22:30:14.752572:  
2023-10-08 22:30:14.756997: Epoch 424 
2023-10-08 22:30:14.761372: Current learning rate: 0.00609 
2023-10-08 22:32:14.391300: train_loss -0.8005 
2023-10-08 22:32:14.399402: val_loss -0.7523 
2023-10-08 22:32:14.404083: Pseudo dice [0.9674, 0.9237, 0.9438, 0.8022] 
2023-10-08 22:32:14.408621: Epoch time: 119.64 s 
2023-10-08 22:32:15.823311:  
2023-10-08 22:32:15.828198: Epoch 425 
2023-10-08 22:32:15.832184: Current learning rate: 0.00608 
2023-10-08 22:34:07.951381: train_loss -0.8008 
2023-10-08 22:34:07.959383: val_loss -0.7961 
2023-10-08 22:34:07.963753: Pseudo dice [0.9737, 0.9476, 0.973, 0.8399] 
2023-10-08 22:34:07.967495: Epoch time: 112.13 s 
2023-10-08 22:34:09.319227:  
2023-10-08 22:34:09.324224: Epoch 426 
2023-10-08 22:34:09.329120: Current learning rate: 0.00607 
2023-10-08 22:36:06.383733: train_loss -0.7694 
2023-10-08 22:36:06.391253: val_loss -0.798 
2023-10-08 22:36:06.394756: Pseudo dice [0.9722, 0.9514, 0.9594, 0.7926] 
2023-10-08 22:36:06.398751: Epoch time: 117.07 s 
2023-10-08 22:36:07.952506:  
2023-10-08 22:36:07.957174: Epoch 427 
2023-10-08 22:36:07.961819: Current learning rate: 0.00606 
2023-10-08 22:38:02.827003: train_loss -0.7652 
2023-10-08 22:38:02.834456: val_loss -0.7936 
2023-10-08 22:38:02.839255: Pseudo dice [0.969, 0.9221, 0.9535, 0.7809] 
2023-10-08 22:38:02.843045: Epoch time: 114.88 s 
2023-10-08 22:38:04.204477:  
2023-10-08 22:38:04.209869: Epoch 428 
2023-10-08 22:38:04.214401: Current learning rate: 0.00605 
2023-10-08 22:39:57.058347: train_loss -0.7869 
2023-10-08 22:39:57.066357: val_loss -0.7598 
2023-10-08 22:39:57.071157: Pseudo dice [0.9584, 0.8977, 0.9637, 0.7755] 
2023-10-08 22:39:57.074868: Epoch time: 112.86 s 
2023-10-08 22:39:58.404027:  
2023-10-08 22:39:58.408669: Epoch 429 
2023-10-08 22:39:58.412689: Current learning rate: 0.00604 
2023-10-08 22:41:53.768027: train_loss -0.7774 
2023-10-08 22:41:53.776105: val_loss -0.7722 
2023-10-08 22:41:53.779933: Pseudo dice [0.9619, 0.959, 0.9152, 0.8234] 
2023-10-08 22:41:53.783645: Epoch time: 115.37 s 
2023-10-08 22:41:55.135320:  
2023-10-08 22:41:55.140671: Epoch 430 
2023-10-08 22:41:55.144492: Current learning rate: 0.00603 
2023-10-08 22:43:56.180541: train_loss -0.8002 
2023-10-08 22:43:56.188924: val_loss -0.7725 
2023-10-08 22:43:56.193074: Pseudo dice [0.97, 0.9636, 0.9504, 0.8084] 
2023-10-08 22:43:56.196775: Epoch time: 121.05 s 
2023-10-08 22:43:57.551299:  
2023-10-08 22:43:57.556355: Epoch 431 
2023-10-08 22:43:57.560776: Current learning rate: 0.00602 
2023-10-08 22:45:52.417118: train_loss -0.7721 
2023-10-08 22:45:52.424838: val_loss -0.773 
2023-10-08 22:45:52.429358: Pseudo dice [0.9659, 0.9487, 0.9353, 0.7855] 
2023-10-08 22:45:52.433441: Epoch time: 114.87 s 
2023-10-08 22:45:54.046059:  
2023-10-08 22:45:54.049818: Epoch 432 
2023-10-08 22:45:54.053414: Current learning rate: 0.00601 
2023-10-08 22:47:47.310806: train_loss -0.7954 
2023-10-08 22:47:47.318303: val_loss -0.8159 
2023-10-08 22:47:47.321863: Pseudo dice [0.9776, 0.9533, 0.9735, 0.8434] 
2023-10-08 22:47:47.325692: Epoch time: 113.27 s 
2023-10-08 22:47:48.695144:  
2023-10-08 22:47:48.701017: Epoch 433 
2023-10-08 22:47:48.706030: Current learning rate: 0.006 
2023-10-08 22:49:44.861650: train_loss -0.8016 
2023-10-08 22:49:44.869703: val_loss -0.7998 
2023-10-08 22:49:44.874962: Pseudo dice [0.9735, 0.9616, 0.9575, 0.7718] 
2023-10-08 22:49:44.879464: Epoch time: 116.17 s 
2023-10-08 22:49:46.240533:  
2023-10-08 22:49:46.244575: Epoch 434 
2023-10-08 22:49:46.248856: Current learning rate: 0.00599 
2023-10-08 22:51:41.813322: train_loss -0.7916 
2023-10-08 22:51:41.821048: val_loss -0.8023 
2023-10-08 22:51:41.824939: Pseudo dice [0.9763, 0.9621, 0.9758, 0.8247] 
2023-10-08 22:51:41.828682: Epoch time: 115.57 s 
2023-10-08 22:51:43.210031:  
2023-10-08 22:51:43.214431: Epoch 435 
2023-10-08 22:51:43.218458: Current learning rate: 0.00598 
2023-10-08 22:53:44.659286: train_loss -0.7879 
2023-10-08 22:53:44.667631: val_loss -0.8045 
2023-10-08 22:53:44.671243: Pseudo dice [0.9728, 0.9453, 0.9718, 0.8327] 
2023-10-08 22:53:44.675247: Epoch time: 121.45 s 
2023-10-08 22:53:46.042047:  
2023-10-08 22:53:46.046443: Epoch 436 
2023-10-08 22:53:46.050722: Current learning rate: 0.00597 
2023-10-08 22:55:43.432914: train_loss -0.7942 
2023-10-08 22:55:43.441565: val_loss -0.798 
2023-10-08 22:55:43.445693: Pseudo dice [0.9693, 0.9598, 0.9663, 0.826] 
2023-10-08 22:55:43.449211: Epoch time: 117.39 s 
2023-10-08 22:55:44.844759:  
2023-10-08 22:55:44.850470: Epoch 437 
2023-10-08 22:55:44.854487: Current learning rate: 0.00596 
2023-10-08 22:57:44.103450: train_loss -0.7618 
2023-10-08 22:57:44.110922: val_loss -0.7859 
2023-10-08 22:57:44.114619: Pseudo dice [0.9705, 0.9557, 0.9422, 0.8258] 
2023-10-08 22:57:44.118499: Epoch time: 119.26 s 
2023-10-08 22:57:45.677518:  
2023-10-08 22:57:45.682117: Epoch 438 
2023-10-08 22:57:45.686340: Current learning rate: 0.00595 
2023-10-08 22:59:41.158338: train_loss -0.792 
2023-10-08 22:59:41.166543: val_loss -0.7526 
2023-10-08 22:59:41.173239: Pseudo dice [0.9461, 0.9488, 0.8964, 0.7743] 
2023-10-08 22:59:41.177259: Epoch time: 115.48 s 
2023-10-08 22:59:42.516417:  
2023-10-08 22:59:42.521093: Epoch 439 
2023-10-08 22:59:42.525400: Current learning rate: 0.00594 
2023-10-08 23:01:41.869391: train_loss -0.7912 
2023-10-08 23:01:41.877621: val_loss -0.7233 
2023-10-08 23:01:41.881076: Pseudo dice [0.9466, 0.9259, 0.9161, 0.7762] 
2023-10-08 23:01:41.884959: Epoch time: 119.35 s 
2023-10-08 23:01:43.292680:  
2023-10-08 23:01:43.297264: Epoch 440 
2023-10-08 23:01:43.301442: Current learning rate: 0.00593 
2023-10-08 23:03:39.993907: train_loss -0.7821 
2023-10-08 23:03:40.001610: val_loss -0.7664 
2023-10-08 23:03:40.005419: Pseudo dice [0.9576, 0.9398, 0.9726, 0.7415] 
2023-10-08 23:03:40.009736: Epoch time: 116.7 s 
2023-10-08 23:03:41.386143:  
2023-10-08 23:03:41.390409: Epoch 441 
2023-10-08 23:03:41.394352: Current learning rate: 0.00592 
2023-10-08 23:05:42.341155: train_loss -0.8001 
2023-10-08 23:05:42.349116: val_loss -0.8 
2023-10-08 23:05:42.353127: Pseudo dice [0.9762, 0.9482, 0.9674, 0.8123] 
2023-10-08 23:05:42.357214: Epoch time: 120.96 s 
2023-10-08 23:05:43.749876:  
2023-10-08 23:05:43.755865: Epoch 442 
2023-10-08 23:05:43.760436: Current learning rate: 0.00592 
2023-10-08 23:07:43.430598: train_loss -0.7932 
2023-10-08 23:07:43.438510: val_loss -0.8173 
2023-10-08 23:07:43.442126: Pseudo dice [0.9738, 0.9391, 0.9536, 0.8578] 
2023-10-08 23:07:43.445474: Epoch time: 119.68 s 
2023-10-08 23:07:45.077790:  
2023-10-08 23:07:45.081876: Epoch 443 
2023-10-08 23:07:45.085572: Current learning rate: 0.00591 
2023-10-08 23:09:41.180909: train_loss -0.7778 
2023-10-08 23:09:41.188489: val_loss -0.796 
2023-10-08 23:09:41.192308: Pseudo dice [0.9703, 0.9561, 0.9697, 0.8372] 
2023-10-08 23:09:41.196843: Epoch time: 116.11 s 
2023-10-08 23:09:42.517397:  
2023-10-08 23:09:42.521330: Epoch 444 
2023-10-08 23:09:42.525904: Current learning rate: 0.0059 
2023-10-08 23:11:42.592096: train_loss -0.7789 
2023-10-08 23:11:42.599617: val_loss -0.7536 
2023-10-08 23:11:42.605862: Pseudo dice [0.9691, 0.962, 0.9178, 0.8524] 
2023-10-08 23:11:42.609119: Epoch time: 120.08 s 
2023-10-08 23:11:43.961928:  
2023-10-08 23:11:43.968662: Epoch 445 
2023-10-08 23:11:43.973691: Current learning rate: 0.00589 
2023-10-08 23:13:41.419604: train_loss -0.7846 
2023-10-08 23:13:41.426594: val_loss -0.7774 
2023-10-08 23:13:41.430368: Pseudo dice [0.9611, 0.9584, 0.9546, 0.7616] 
2023-10-08 23:13:41.434168: Epoch time: 117.46 s 
2023-10-08 23:13:42.806683:  
2023-10-08 23:13:42.811529: Epoch 446 
2023-10-08 23:13:42.817528: Current learning rate: 0.00588 
2023-10-08 23:15:37.793127: train_loss -0.792 
2023-10-08 23:15:37.800818: val_loss -0.8191 
2023-10-08 23:15:37.804988: Pseudo dice [0.9764, 0.9547, 0.9638, 0.8427] 
2023-10-08 23:15:37.808995: Epoch time: 114.99 s 
2023-10-08 23:15:39.159420:  
2023-10-08 23:15:39.163816: Epoch 447 
2023-10-08 23:15:39.167777: Current learning rate: 0.00587 
2023-10-08 23:17:34.924080: train_loss -0.7824 
2023-10-08 23:17:34.932469: val_loss -0.7941 
2023-10-08 23:17:34.936851: Pseudo dice [0.9665, 0.9279, 0.9563, 0.7833] 
2023-10-08 23:17:34.940892: Epoch time: 115.77 s 
2023-10-08 23:17:36.295825:  
2023-10-08 23:17:36.301590: Epoch 448 
2023-10-08 23:17:36.305700: Current learning rate: 0.00586 
2023-10-08 23:19:33.777338: train_loss -0.7788 
2023-10-08 23:19:33.784987: val_loss -0.7962 
2023-10-08 23:19:33.789076: Pseudo dice [0.9676, 0.9526, 0.9298, 0.8081] 
2023-10-08 23:19:33.793068: Epoch time: 117.49 s 
2023-10-08 23:19:35.333833:  
2023-10-08 23:19:35.338015: Epoch 449 
2023-10-08 23:19:35.342161: Current learning rate: 0.00585 
2023-10-08 23:21:33.819264: train_loss -0.7905 
2023-10-08 23:21:33.827522: val_loss -0.808 
2023-10-08 23:21:33.831352: Pseudo dice [0.9655, 0.9555, 0.9488, 0.83] 
2023-10-08 23:21:33.835073: Epoch time: 118.49 s 
2023-10-08 23:21:35.949483:  
2023-10-08 23:21:35.953676: Epoch 450 
2023-10-08 23:21:35.957677: Current learning rate: 0.00584 
2023-10-08 23:23:32.898008: train_loss -0.7765 
2023-10-08 23:23:32.905251: val_loss -0.7919 
2023-10-08 23:23:32.909212: Pseudo dice [0.9728, 0.9358, 0.9499, 0.8224] 
2023-10-08 23:23:32.913024: Epoch time: 116.95 s 
2023-10-08 23:23:34.280125:  
2023-10-08 23:23:34.285836: Epoch 451 
2023-10-08 23:23:34.289902: Current learning rate: 0.00583 
2023-10-08 23:25:28.696429: train_loss -0.7981 
2023-10-08 23:25:28.704597: val_loss -0.7957 
2023-10-08 23:25:28.708681: Pseudo dice [0.9786, 0.9565, 0.9689, 0.8357] 
2023-10-08 23:25:28.712223: Epoch time: 114.42 s 
2023-10-08 23:25:30.100427:  
2023-10-08 23:25:30.104809: Epoch 452 
2023-10-08 23:25:30.108670: Current learning rate: 0.00582 
2023-10-08 23:27:23.190871: train_loss -0.7816 
2023-10-08 23:27:23.198038: val_loss -0.8033 
2023-10-08 23:27:23.201610: Pseudo dice [0.967, 0.9592, 0.9601, 0.828] 
2023-10-08 23:27:23.205173: Epoch time: 113.09 s 
2023-10-08 23:27:24.570731:  
2023-10-08 23:27:24.575174: Epoch 453 
2023-10-08 23:27:24.578883: Current learning rate: 0.00581 
2023-10-08 23:29:19.056351: train_loss -0.7766 
2023-10-08 23:29:19.065664: val_loss -0.8187 
2023-10-08 23:29:19.069654: Pseudo dice [0.9777, 0.959, 0.9686, 0.7828] 
2023-10-08 23:29:19.073313: Epoch time: 114.49 s 
2023-10-08 23:29:20.597769:  
2023-10-08 23:29:20.603491: Epoch 454 
2023-10-08 23:29:20.607994: Current learning rate: 0.0058 
2023-10-08 23:31:16.805605: train_loss -0.7922 
2023-10-08 23:31:16.814265: val_loss -0.8003 
2023-10-08 23:31:16.818280: Pseudo dice [0.9728, 0.9555, 0.9694, 0.7837] 
2023-10-08 23:31:16.822264: Epoch time: 116.21 s 
2023-10-08 23:31:18.180890:  
2023-10-08 23:31:18.185905: Epoch 455 
2023-10-08 23:31:18.191113: Current learning rate: 0.00579 
2023-10-08 23:33:15.226169: train_loss -0.7963 
2023-10-08 23:33:15.234365: val_loss -0.8293 
2023-10-08 23:33:15.238297: Pseudo dice [0.9763, 0.9643, 0.9689, 0.8369] 
2023-10-08 23:33:15.242030: Epoch time: 117.05 s 
2023-10-08 23:33:16.573726:  
2023-10-08 23:33:16.579967: Epoch 456 
2023-10-08 23:33:16.585592: Current learning rate: 0.00578 
2023-10-08 23:35:09.990053: train_loss -0.79 
2023-10-08 23:35:09.998589: val_loss -0.8152 
2023-10-08 23:35:10.002625: Pseudo dice [0.9737, 0.9587, 0.9709, 0.8541] 
2023-10-08 23:35:10.006499: Epoch time: 113.42 s 
2023-10-08 23:35:11.353604:  
2023-10-08 23:35:11.358402: Epoch 457 
2023-10-08 23:35:11.363422: Current learning rate: 0.00577 
2023-10-08 23:37:14.543298: train_loss -0.7929 
2023-10-08 23:37:14.551244: val_loss -0.7912 
2023-10-08 23:37:14.555029: Pseudo dice [0.9688, 0.9497, 0.966, 0.7512] 
2023-10-08 23:37:14.558812: Epoch time: 123.19 s 
2023-10-08 23:37:15.929234:  
2023-10-08 23:37:15.934974: Epoch 458 
2023-10-08 23:37:15.941558: Current learning rate: 0.00576 
2023-10-08 23:39:12.639892: train_loss -0.7981 
2023-10-08 23:39:12.647895: val_loss -0.8001 
2023-10-08 23:39:12.651829: Pseudo dice [0.9607, 0.9454, 0.9719, 0.7936] 
2023-10-08 23:39:12.655670: Epoch time: 116.71 s 
2023-10-08 23:39:14.017418:  
2023-10-08 23:39:14.021399: Epoch 459 
2023-10-08 23:39:14.024937: Current learning rate: 0.00575 
2023-10-08 23:41:06.914235: train_loss -0.7919 
2023-10-08 23:41:06.922318: val_loss -0.7919 
2023-10-08 23:41:06.925879: Pseudo dice [0.951, 0.966, 0.9245, 0.8329] 
2023-10-08 23:41:06.929911: Epoch time: 112.9 s 
2023-10-08 23:41:08.479937:  
2023-10-08 23:41:08.484690: Epoch 460 
2023-10-08 23:41:08.488507: Current learning rate: 0.00574 
2023-10-08 23:43:07.912288: train_loss -0.786 
2023-10-08 23:43:07.920448: val_loss -0.8093 
2023-10-08 23:43:07.924560: Pseudo dice [0.9724, 0.956, 0.9514, 0.8524] 
2023-10-08 23:43:07.928236: Epoch time: 119.44 s 
2023-10-08 23:43:09.369354:  
2023-10-08 23:43:09.374367: Epoch 461 
2023-10-08 23:43:09.380305: Current learning rate: 0.00573 
2023-10-08 23:45:12.647592: train_loss -0.7746 
2023-10-08 23:45:12.655531: val_loss -0.7965 
2023-10-08 23:45:12.659252: Pseudo dice [0.9748, 0.9609, 0.9715, 0.8325] 
2023-10-08 23:45:12.663101: Epoch time: 123.28 s 
2023-10-08 23:45:14.020059:  
2023-10-08 23:45:14.024092: Epoch 462 
2023-10-08 23:45:14.027619: Current learning rate: 0.00572 
2023-10-08 23:47:14.680867: train_loss -0.7881 
2023-10-08 23:47:14.688859: val_loss -0.7485 
2023-10-08 23:47:14.692756: Pseudo dice [0.9745, 0.9496, 0.9695, 0.816] 
2023-10-08 23:47:14.696486: Epoch time: 120.66 s 
2023-10-08 23:47:16.061990:  
2023-10-08 23:47:16.066796: Epoch 463 
2023-10-08 23:47:16.070718: Current learning rate: 0.00571 
2023-10-08 23:49:13.140581: train_loss -0.7756 
2023-10-08 23:49:13.148164: val_loss -0.8117 
2023-10-08 23:49:13.151595: Pseudo dice [0.9767, 0.9595, 0.9662, 0.8294] 
2023-10-08 23:49:13.156415: Epoch time: 117.08 s 
2023-10-08 23:49:14.479147:  
2023-10-08 23:49:14.483226: Epoch 464 
2023-10-08 23:49:14.486825: Current learning rate: 0.0057 
2023-10-08 23:51:12.035857: train_loss -0.7658 
2023-10-08 23:51:12.043964: val_loss -0.8171 
2023-10-08 23:51:12.047713: Pseudo dice [0.9656, 0.9545, 0.9616, 0.8136] 
2023-10-08 23:51:12.051574: Epoch time: 117.56 s 
2023-10-08 23:51:13.621303:  
2023-10-08 23:51:13.625790: Epoch 465 
2023-10-08 23:51:13.629539: Current learning rate: 0.0057 
2023-10-08 23:53:12.301946: train_loss -0.7827 
2023-10-08 23:53:12.310123: val_loss -0.8053 
2023-10-08 23:53:12.314046: Pseudo dice [0.971, 0.9561, 0.9513, 0.8482] 
2023-10-08 23:53:12.317834: Epoch time: 118.68 s 
2023-10-08 23:53:13.676446:  
2023-10-08 23:53:13.681661: Epoch 466 
2023-10-08 23:53:13.685947: Current learning rate: 0.00569 
2023-10-08 23:55:08.367702: train_loss -0.8142 
2023-10-08 23:55:08.375505: val_loss -0.8021 
2023-10-08 23:55:08.379294: Pseudo dice [0.966, 0.9474, 0.9313, 0.7966] 
2023-10-08 23:55:08.382970: Epoch time: 114.69 s 
2023-10-08 23:55:09.765625:  
2023-10-08 23:55:09.769841: Epoch 467 
2023-10-08 23:55:09.778957: Current learning rate: 0.00568 
2023-10-08 23:57:11.301525: train_loss -0.7989 
2023-10-08 23:57:11.309278: val_loss -0.7786 
2023-10-08 23:57:11.313302: Pseudo dice [0.9643, 0.9462, 0.9296, 0.8052] 
2023-10-08 23:57:11.317254: Epoch time: 121.54 s 
2023-10-08 23:57:12.718956:  
2023-10-08 23:57:12.723115: Epoch 468 
2023-10-08 23:57:12.726871: Current learning rate: 0.00567 
2023-10-08 23:59:07.504457: train_loss -0.7415 
2023-10-08 23:59:07.512577: val_loss -0.8132 
2023-10-08 23:59:07.516476: Pseudo dice [0.9793, 0.9549, 0.9735, 0.8122] 
2023-10-08 23:59:07.520561: Epoch time: 114.79 s 
2023-10-08 23:59:08.872059:  
2023-10-08 23:59:08.876724: Epoch 469 
2023-10-08 23:59:08.883086: Current learning rate: 0.00566 
2023-10-09 00:01:04.870448: train_loss -0.7925 
2023-10-09 00:01:04.878409: val_loss -0.7772 
2023-10-09 00:01:04.882460: Pseudo dice [0.9547, 0.913, 0.9609, 0.8226] 
2023-10-09 00:01:04.886645: Epoch time: 116.0 s 
2023-10-09 00:01:06.292825:  
2023-10-09 00:01:06.297675: Epoch 470 
2023-10-09 00:01:06.301819: Current learning rate: 0.00565 
2023-10-09 00:03:08.014108: train_loss -0.7997 
2023-10-09 00:03:08.021913: val_loss -0.7581 
2023-10-09 00:03:08.025692: Pseudo dice [0.9672, 0.9509, 0.9348, 0.7855] 
2023-10-09 00:03:08.029352: Epoch time: 121.72 s 
2023-10-09 00:03:09.569680:  
2023-10-09 00:03:09.574848: Epoch 471 
2023-10-09 00:03:09.579668: Current learning rate: 0.00564 
2023-10-09 00:05:04.917586: train_loss -0.79 
2023-10-09 00:05:04.928198: val_loss -0.7959 
2023-10-09 00:05:04.931705: Pseudo dice [0.9657, 0.9475, 0.9437, 0.8496] 
2023-10-09 00:05:04.935150: Epoch time: 115.35 s 
2023-10-09 00:05:06.326230:  
2023-10-09 00:05:06.331056: Epoch 472 
2023-10-09 00:05:06.335451: Current learning rate: 0.00563 
2023-10-09 00:07:00.079817: train_loss -0.7926 
2023-10-09 00:07:00.088493: val_loss -0.8117 
2023-10-09 00:07:00.095483: Pseudo dice [0.9649, 0.9586, 0.9704, 0.8412] 
2023-10-09 00:07:00.100808: Epoch time: 113.76 s 
2023-10-09 00:07:01.438245:  
2023-10-09 00:07:01.443401: Epoch 473 
2023-10-09 00:07:01.447064: Current learning rate: 0.00562 
2023-10-09 00:08:59.474432: train_loss -0.8197 
2023-10-09 00:08:59.482247: val_loss -0.815 
2023-10-09 00:08:59.485882: Pseudo dice [0.9742, 0.9594, 0.9674, 0.8446] 
2023-10-09 00:08:59.489494: Epoch time: 118.04 s 
2023-10-09 00:09:00.852272:  
2023-10-09 00:09:00.857100: Epoch 474 
2023-10-09 00:09:00.861693: Current learning rate: 0.00561 
2023-10-09 00:10:59.968673: train_loss -0.7877 
2023-10-09 00:10:59.977749: val_loss -0.7841 
2023-10-09 00:10:59.981746: Pseudo dice [0.9754, 0.962, 0.9503, 0.8194] 
2023-10-09 00:10:59.985616: Epoch time: 119.12 s 
2023-10-09 00:11:01.390913:  
2023-10-09 00:11:01.395707: Epoch 475 
2023-10-09 00:11:01.400437: Current learning rate: 0.0056 
2023-10-09 00:12:56.434396: train_loss -0.7877 
2023-10-09 00:12:56.442211: val_loss -0.7628 
2023-10-09 00:12:56.446121: Pseudo dice [0.9552, 0.961, 0.9187, 0.76] 
2023-10-09 00:12:56.450145: Epoch time: 115.05 s 
2023-10-09 00:12:57.834654:  
2023-10-09 00:12:57.839436: Epoch 476 
2023-10-09 00:12:57.843468: Current learning rate: 0.00559 
2023-10-09 00:14:55.566348: train_loss -0.7763 
2023-10-09 00:14:55.574782: val_loss -0.8264 
2023-10-09 00:14:55.578960: Pseudo dice [0.9726, 0.9579, 0.9446, 0.8522] 
2023-10-09 00:14:55.583513: Epoch time: 117.74 s 
2023-10-09 00:14:57.119503:  
2023-10-09 00:14:57.123981: Epoch 477 
2023-10-09 00:14:57.127802: Current learning rate: 0.00558 
2023-10-09 00:16:55.074832: train_loss -0.7929 
2023-10-09 00:16:55.084363: val_loss -0.8219 
2023-10-09 00:16:55.089119: Pseudo dice [0.9716, 0.9484, 0.9692, 0.855] 
2023-10-09 00:16:55.092922: Epoch time: 117.96 s 
2023-10-09 00:16:56.473983:  
2023-10-09 00:16:56.480007: Epoch 478 
2023-10-09 00:16:56.484764: Current learning rate: 0.00557 
2023-10-09 00:18:51.815388: train_loss -0.7894 
2023-10-09 00:18:51.823690: val_loss -0.8016 
2023-10-09 00:18:51.827401: Pseudo dice [0.9798, 0.96, 0.9682, 0.8196] 
2023-10-09 00:18:51.831399: Epoch time: 115.34 s 
2023-10-09 00:18:53.207647:  
2023-10-09 00:18:53.212419: Epoch 479 
2023-10-09 00:18:53.216167: Current learning rate: 0.00556 
2023-10-09 00:20:55.756607: train_loss -0.8151 
2023-10-09 00:20:55.764511: val_loss -0.8217 
2023-10-09 00:20:55.769212: Pseudo dice [0.98, 0.9566, 0.9754, 0.8212] 
2023-10-09 00:20:55.773436: Epoch time: 122.55 s 
2023-10-09 00:20:57.169495:  
2023-10-09 00:20:57.175225: Epoch 480 
2023-10-09 00:20:57.180100: Current learning rate: 0.00555 
2023-10-09 00:22:50.116323: train_loss -0.8031 
2023-10-09 00:22:50.125013: val_loss -0.7852 
2023-10-09 00:22:50.129291: Pseudo dice [0.9774, 0.9559, 0.973, 0.8223] 
2023-10-09 00:22:50.133390: Epoch time: 112.95 s 
2023-10-09 00:22:51.507836:  
2023-10-09 00:22:51.512402: Epoch 481 
2023-10-09 00:22:51.516125: Current learning rate: 0.00554 
2023-10-09 00:24:49.331922: train_loss -0.8125 
2023-10-09 00:24:49.343262: val_loss -0.8016 
2023-10-09 00:24:49.347328: Pseudo dice [0.9777, 0.9548, 0.9703, 0.8181] 
2023-10-09 00:24:49.351820: Epoch time: 117.83 s 
2023-10-09 00:24:49.355882: Yayy! New best EMA pseudo Dice: 0.9269 
2023-10-09 00:24:51.670878:  
2023-10-09 00:24:51.675375: Epoch 482 
2023-10-09 00:24:51.679653: Current learning rate: 0.00553 
2023-10-09 00:26:51.533606: train_loss -0.7846 
2023-10-09 00:26:51.542522: val_loss -0.826 
2023-10-09 00:26:51.547224: Pseudo dice [0.972, 0.9469, 0.9727, 0.8287] 
2023-10-09 00:26:51.551264: Epoch time: 119.87 s 
2023-10-09 00:26:51.555307: Yayy! New best EMA pseudo Dice: 0.9272 
2023-10-09 00:26:53.649646:  
2023-10-09 00:26:53.654277: Epoch 483 
2023-10-09 00:26:53.657869: Current learning rate: 0.00552 
2023-10-09 00:28:46.657053: train_loss -0.816 
2023-10-09 00:28:46.665416: val_loss -0.8105 
2023-10-09 00:28:46.668622: Pseudo dice [0.9681, 0.961, 0.9411, 0.8424] 
2023-10-09 00:28:46.671293: Epoch time: 113.01 s 
2023-10-09 00:28:46.674011: Yayy! New best EMA pseudo Dice: 0.9273 
2023-10-09 00:28:48.778059:  
2023-10-09 00:28:48.782359: Epoch 484 
2023-10-09 00:28:48.786277: Current learning rate: 0.00551 
2023-10-09 00:30:47.242259: train_loss -0.7893 
2023-10-09 00:30:47.250144: val_loss -0.8014 
2023-10-09 00:30:47.254194: Pseudo dice [0.968, 0.9247, 0.9617, 0.8547] 
2023-10-09 00:30:47.257934: Epoch time: 118.47 s 
2023-10-09 00:30:48.635248:  
2023-10-09 00:30:48.639612: Epoch 485 
2023-10-09 00:30:48.644745: Current learning rate: 0.0055 
2023-10-09 00:32:47.431372: train_loss -0.7982 
2023-10-09 00:32:47.439706: val_loss -0.7526 
2023-10-09 00:32:47.443633: Pseudo dice [0.9614, 0.9547, 0.9418, 0.7841] 
2023-10-09 00:32:47.447388: Epoch time: 118.8 s 
2023-10-09 00:32:48.817243:  
2023-10-09 00:32:48.821534: Epoch 486 
2023-10-09 00:32:48.825498: Current learning rate: 0.00549 
2023-10-09 00:34:50.460638: train_loss -0.8044 
2023-10-09 00:34:50.467859: val_loss -0.8187 
2023-10-09 00:34:50.471256: Pseudo dice [0.9753, 0.9617, 0.9589, 0.8522] 
2023-10-09 00:34:50.474532: Epoch time: 121.65 s 
2023-10-09 00:34:51.879210:  
2023-10-09 00:34:51.883757: Epoch 487 
2023-10-09 00:34:51.887436: Current learning rate: 0.00548 
2023-10-09 00:36:49.027686: train_loss -0.7803 
2023-10-09 00:36:49.035483: val_loss -0.8315 
2023-10-09 00:36:49.039512: Pseudo dice [0.9735, 0.951, 0.9671, 0.8082] 
2023-10-09 00:36:49.043525: Epoch time: 117.15 s 
2023-10-09 00:36:50.589766:  
2023-10-09 00:36:50.594392: Epoch 488 
2023-10-09 00:36:50.598659: Current learning rate: 0.00547 
2023-10-09 00:38:49.417061: train_loss -0.7985 
2023-10-09 00:38:49.425643: val_loss -0.8561 
2023-10-09 00:38:49.429895: Pseudo dice [0.9733, 0.9625, 0.9715, 0.8496] 
2023-10-09 00:38:49.433732: Epoch time: 118.83 s 
2023-10-09 00:38:49.437557: Yayy! New best EMA pseudo Dice: 0.9279 
2023-10-09 00:38:51.541792:  
2023-10-09 00:38:51.547760: Epoch 489 
2023-10-09 00:38:51.551978: Current learning rate: 0.00546 
2023-10-09 00:40:50.558614: train_loss -0.8069 
2023-10-09 00:40:50.567667: val_loss -0.7985 
2023-10-09 00:40:50.571665: Pseudo dice [0.9648, 0.9562, 0.9524, 0.8378] 
2023-10-09 00:40:50.578576: Epoch time: 119.02 s 
2023-10-09 00:40:51.926258:  
2023-10-09 00:40:51.933318: Epoch 490 
2023-10-09 00:40:51.937836: Current learning rate: 0.00546 
2023-10-09 00:42:51.194725: train_loss -0.7763 
2023-10-09 00:42:51.202560: val_loss -0.8026 
2023-10-09 00:42:51.206188: Pseudo dice [0.9753, 0.9573, 0.9496, 0.8313] 
2023-10-09 00:42:51.210089: Epoch time: 119.27 s 
2023-10-09 00:42:51.213844: Yayy! New best EMA pseudo Dice: 0.9279 
2023-10-09 00:42:53.308377:  
2023-10-09 00:42:53.312815: Epoch 491 
2023-10-09 00:42:53.317253: Current learning rate: 0.00545 
2023-10-09 00:44:49.685777: train_loss -0.7946 
2023-10-09 00:44:49.693351: val_loss -0.787 
2023-10-09 00:44:49.696794: Pseudo dice [0.9743, 0.9476, 0.9664, 0.8527] 
2023-10-09 00:44:49.700252: Epoch time: 116.38 s 
2023-10-09 00:44:49.703659: Yayy! New best EMA pseudo Dice: 0.9286 
2023-10-09 00:44:51.862874:  
2023-10-09 00:44:51.867534: Epoch 492 
2023-10-09 00:44:51.872262: Current learning rate: 0.00544 
2023-10-09 00:46:52.099001: train_loss -0.8039 
2023-10-09 00:46:52.107511: val_loss -0.8011 
2023-10-09 00:46:52.111664: Pseudo dice [0.9735, 0.9604, 0.9657, 0.8097] 
2023-10-09 00:46:52.116696: Epoch time: 120.24 s 
2023-10-09 00:46:53.487005:  
2023-10-09 00:46:53.493839: Epoch 493 
2023-10-09 00:46:53.497858: Current learning rate: 0.00543 
2023-10-09 00:48:52.067490: train_loss -0.8107 
2023-10-09 00:48:52.075857: val_loss -0.8238 
2023-10-09 00:48:52.079757: Pseudo dice [0.9716, 0.958, 0.9431, 0.8475] 
2023-10-09 00:48:52.084470: Epoch time: 118.58 s 
2023-10-09 00:48:52.088231: Yayy! New best EMA pseudo Dice: 0.9287 
2023-10-09 00:48:54.268283:  
2023-10-09 00:48:54.273472: Epoch 494 
2023-10-09 00:48:54.277617: Current learning rate: 0.00542 
2023-10-09 00:50:53.257519: train_loss -0.787 
2023-10-09 00:50:53.265828: val_loss -0.8327 
2023-10-09 00:50:53.277584: Pseudo dice [0.9782, 0.948, 0.9674, 0.8449] 
2023-10-09 00:50:53.284495: Epoch time: 118.99 s 
2023-10-09 00:50:53.288543: Yayy! New best EMA pseudo Dice: 0.9293 
2023-10-09 00:50:55.381570:  
2023-10-09 00:50:55.387056: Epoch 495 
2023-10-09 00:50:55.392035: Current learning rate: 0.00541 
2023-10-09 00:52:53.788876: train_loss -0.7622 
2023-10-09 00:52:53.796367: val_loss -0.791 
2023-10-09 00:52:53.800353: Pseudo dice [0.9721, 0.9544, 0.9328, 0.8215] 
2023-10-09 00:52:53.803912: Epoch time: 118.41 s 
2023-10-09 00:52:55.243634:  
2023-10-09 00:52:55.248785: Epoch 496 
2023-10-09 00:52:55.252990: Current learning rate: 0.0054 
2023-10-09 00:54:51.569191: train_loss -0.7878 
2023-10-09 00:54:51.575938: val_loss -0.7866 
2023-10-09 00:54:51.579156: Pseudo dice [0.9722, 0.9599, 0.9551, 0.7799] 
2023-10-09 00:54:51.582524: Epoch time: 116.33 s 
2023-10-09 00:54:52.941431:  
2023-10-09 00:54:52.945500: Epoch 497 
2023-10-09 00:54:52.949493: Current learning rate: 0.00539 
2023-10-09 00:56:48.281022: train_loss -0.79 
2023-10-09 00:56:48.288634: val_loss -0.7783 
2023-10-09 00:56:48.292196: Pseudo dice [0.968, 0.9453, 0.9286, 0.8353] 
2023-10-09 00:56:48.296034: Epoch time: 115.34 s 
2023-10-09 00:56:49.708033:  
2023-10-09 00:56:49.712937: Epoch 498 
2023-10-09 00:56:49.717513: Current learning rate: 0.00538 
2023-10-09 00:58:50.493521: train_loss -0.7867 
2023-10-09 00:58:50.502031: val_loss -0.8154 
2023-10-09 00:58:50.506197: Pseudo dice [0.9714, 0.9427, 0.9643, 0.826] 
2023-10-09 00:58:50.510283: Epoch time: 120.79 s 
2023-10-09 00:58:51.913623:  
2023-10-09 00:58:51.918039: Epoch 499 
2023-10-09 00:58:51.922443: Current learning rate: 0.00537 
2023-10-09 01:00:46.912729: train_loss -0.7886 
2023-10-09 01:00:46.920549: val_loss -0.8033 
2023-10-09 01:00:46.924222: Pseudo dice [0.9668, 0.9373, 0.9735, 0.851] 
2023-10-09 01:00:46.927766: Epoch time: 115.0 s 
2023-10-09 01:00:49.109142:  
2023-10-09 01:00:49.114164: Epoch 500 
2023-10-09 01:00:49.119072: Current learning rate: 0.00536 
2023-10-09 01:02:45.939352: train_loss -0.7757 
2023-10-09 01:02:45.947326: val_loss -0.8058 
2023-10-09 01:02:45.951231: Pseudo dice [0.9642, 0.9475, 0.9759, 0.8423] 
2023-10-09 01:02:45.955339: Epoch time: 116.83 s 
2023-10-09 01:02:47.324128:  
2023-10-09 01:02:47.329087: Epoch 501 
2023-10-09 01:02:47.333725: Current learning rate: 0.00535 
2023-10-09 01:04:44.798523: train_loss -0.8004 
2023-10-09 01:04:44.807028: val_loss -0.7858 
2023-10-09 01:04:44.811047: Pseudo dice [0.9667, 0.9553, 0.9274, 0.8125] 
2023-10-09 01:04:44.814520: Epoch time: 117.48 s 
2023-10-09 01:04:46.189209:  
2023-10-09 01:04:46.193738: Epoch 502 
2023-10-09 01:04:46.198114: Current learning rate: 0.00534 
2023-10-09 01:06:40.924419: train_loss -0.785 
2023-10-09 01:06:40.932487: val_loss -0.8205 
2023-10-09 01:06:40.936190: Pseudo dice [0.9655, 0.9603, 0.9628, 0.8345] 
2023-10-09 01:06:40.940289: Epoch time: 114.74 s 
2023-10-09 01:06:42.525402:  
2023-10-09 01:06:42.529563: Epoch 503 
2023-10-09 01:06:42.533602: Current learning rate: 0.00533 
2023-10-09 01:08:37.474233: train_loss -0.8021 
2023-10-09 01:08:37.484068: val_loss -0.8135 
2023-10-09 01:08:37.487895: Pseudo dice [0.9721, 0.9651, 0.9513, 0.8441] 
2023-10-09 01:08:37.491346: Epoch time: 114.95 s 
2023-10-09 01:08:38.852484:  
2023-10-09 01:08:38.857303: Epoch 504 
2023-10-09 01:08:38.861206: Current learning rate: 0.00532 
2023-10-09 01:10:37.163844: train_loss -0.7848 
2023-10-09 01:10:37.171833: val_loss -0.8367 
2023-10-09 01:10:37.175578: Pseudo dice [0.9769, 0.9589, 0.965, 0.8391] 
2023-10-09 01:10:37.179548: Epoch time: 118.31 s 
2023-10-09 01:10:38.572563:  
2023-10-09 01:10:38.576852: Epoch 505 
2023-10-09 01:10:38.581335: Current learning rate: 0.00531 
2023-10-09 01:12:40.266007: train_loss -0.7899 
2023-10-09 01:12:40.273880: val_loss -0.7893 
2023-10-09 01:12:40.277867: Pseudo dice [0.9628, 0.9369, 0.9332, 0.8647] 
2023-10-09 01:12:40.281681: Epoch time: 121.7 s 
2023-10-09 01:12:41.696527:  
2023-10-09 01:12:41.701704: Epoch 506 
2023-10-09 01:12:41.706045: Current learning rate: 0.0053 
2023-10-09 01:14:37.508894: train_loss -0.7945 
2023-10-09 01:14:37.517149: val_loss -0.7209 
2023-10-09 01:14:37.521405: Pseudo dice [0.9646, 0.8906, 0.9398, 0.8506] 
2023-10-09 01:14:37.525384: Epoch time: 115.82 s 
2023-10-09 01:14:38.881283:  
2023-10-09 01:14:38.886218: Epoch 507 
2023-10-09 01:14:38.890487: Current learning rate: 0.00529 
2023-10-09 01:16:32.377545: train_loss -0.7923 
2023-10-09 01:16:32.385400: val_loss -0.8014 
2023-10-09 01:16:32.389340: Pseudo dice [0.9738, 0.9577, 0.9722, 0.8254] 
2023-10-09 01:16:32.393685: Epoch time: 113.5 s 
2023-10-09 01:16:33.974176:  
2023-10-09 01:16:33.979217: Epoch 508 
2023-10-09 01:16:33.983945: Current learning rate: 0.00528 
2023-10-09 01:18:31.014549: train_loss -0.7772 
2023-10-09 01:18:31.023500: val_loss -0.8154 
2023-10-09 01:18:31.027884: Pseudo dice [0.9725, 0.9596, 0.9717, 0.8389] 
2023-10-09 01:18:31.031654: Epoch time: 117.04 s 
2023-10-09 01:18:32.428702:  
2023-10-09 01:18:32.432873: Epoch 509 
2023-10-09 01:18:32.437169: Current learning rate: 0.00527 
2023-10-09 01:20:34.242499: train_loss -0.7985 
2023-10-09 01:20:34.253406: val_loss -0.7598 
2023-10-09 01:20:34.258161: Pseudo dice [0.9635, 0.9499, 0.9611, 0.7341] 
2023-10-09 01:20:34.261891: Epoch time: 121.82 s 
2023-10-09 01:20:35.649402:  
2023-10-09 01:20:35.655551: Epoch 510 
2023-10-09 01:20:35.660311: Current learning rate: 0.00526 
2023-10-09 01:22:34.253931: train_loss -0.7981 
2023-10-09 01:22:34.262882: val_loss -0.783 
2023-10-09 01:22:34.266623: Pseudo dice [0.9762, 0.96, 0.9682, 0.7917] 
2023-10-09 01:22:34.270454: Epoch time: 118.61 s 
2023-10-09 01:22:35.649989:  
2023-10-09 01:22:35.655333: Epoch 511 
2023-10-09 01:22:35.660260: Current learning rate: 0.00525 
